{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Download and chunk the data**\n",
    "\n",
    "We are going to use the following docs as our knowledge base:\n",
    "1. Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People (PDF)\n",
    "2. National Institute of Standards and Technology (NIST) Artificial Intelligent Risk Management Framework \n",
    "\n",
    "Let's start with a simple fixed chunking strategy as a baseline, and later evaluate parent-doc retrieval if we have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.0 in ./.conda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: langchain_community==0.3.0 in ./.conda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: pymupdf in ./.conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.24.10)\n",
      "Requirement already satisfied: openai in ./.conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.46.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (0.1.121)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.12/site-packages (from langchain==0.3.0->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.conda/lib/python3.12/site-packages (from langchain_community==0.3.0->-r requirements.txt (line 2)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.conda/lib/python3.12/site-packages (from langchain_community==0.3.0->-r requirements.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.10 in ./.conda/lib/python3.12/site-packages (from pymupdf->-r requirements.txt (line 3)) (1.24.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.conda/lib/python3.12/site-packages (from openai->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0->-r requirements.txt (line 1)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0->-r requirements.txt (line 1)) (1.11.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.0->-r requirements.txt (line 2)) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.0->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 4)) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0->-r requirements.txt (line 1)) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0->-r requirements.txt (line 1)) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.0->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.0->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.0->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.0->-r requirements.txt (line 2)) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU -r requirements.txt \n",
    "!pip install -qU langchain-openai langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "CHUNK_SIZE = 1500\n",
    "OVERLAP = 150\n",
    "\n",
    "PDFS = [\n",
    "    \"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\",\n",
    "    \"https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from getpass import getpass\n",
    "\n",
    "# collect OpenAI key\n",
    "openai.api_key = getpass(\"OpenAI API Key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'chunk_and_load' from '/Users/Angela/Desktop/ai_makerspace/code/ai-risk-bot/chunk_and_load.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import chunk_and_load\n",
    "\n",
    "importlib.reload(chunk_and_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf...\n",
      "Chunking...\n",
      "Loading https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf...\n",
      "Chunking...\n",
      "Loaded 338 chunks\n"
     ]
    }
   ],
   "source": [
    "# Load and chunk our pdfs\n",
    "chunks = []\n",
    "for pdf in PDFS:\n",
    "    chunks.extend(chunk_and_load.load_and_chunk_pdf(pdf,CHUNK_SIZE,OVERLAP))\n",
    "\n",
    "print(f\"Loaded {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='correcting data. Entities should conduct regular, independent audits and take prompt corrective measures to \n",
      "maintain accurate, timely, and complete data. \n",
      "Limit access to sensitive data and derived data. Sensitive data and derived data should not be sold, \n",
      "shared, or made public as part of data brokerage or other agreements. Sensitive data includes data that can be \n",
      "used to infer sensitive information; even systems that are not directly marketed as sensitive domain technologies \n",
      "are expected to keep sensitive data private. Access to such data should be limited based on necessity and based \n",
      "on a principle of local control, such that those individuals closest to the data subject have more access while \n",
      "those who are less proximate do not (e.g., a teacher has access to their students’ daily progress data while a \n",
      "superintendent does not). \n",
      "Reporting. In addition to the reporting on data privacy (as listed above for non-sensitive data), entities devel-\n",
      "oping technologies related to a sensitive domain and those collecting, using, storing, or sharing sensitive data \n",
      "should, whenever appropriate, regularly provide public reports describing: any data security lapses or breaches \n",
      "that resulted in sensitive data leaks; the number, type, and outcomes of ethical pre-reviews undertaken; a \n",
      "description of any data sold, shared, or made public, and how that data was assessed to determine it did not pres-'\n"
     ]
    }
   ],
   "source": [
    "print(chunks[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created qdrant client\n",
      "populated vector db\n",
      "created chain\n"
     ]
    }
   ],
   "source": [
    "import vanilla_rag\n",
    "importlib.reload(vanilla_rag)\n",
    "\n",
    "rag_chain = await vanilla_rag.vanilla_rag(chunks, openai.api_key, \"AI-Risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': AIMessage(content='Some key risks associated with modern LLMs include:\\n\\n1. **Dangerous or Violent Recommendations**: LLMs have been reported to generate content that incites violence or provides dangerous recommendations.\\n\\n2. **Confabulations of Falsehoods**: LLMs can produce incorrect information or logical steps that mislead users, potentially leading to harmful decisions, especially in critical areas like healthcare.\\n\\n3. **Deceptive Outputs**: LLMs may falsely assert human-like traits, deceiving users into believing they are interacting with a human.\\n\\n4. **Facilitation of Dangerous Knowledge**: LLMs could assist individuals without formal training in analyzing or synthesizing information related to chemical and biological threats.\\n\\n5. **Generation of Hateful Content**: LLMs can produce content that glorifies violence or promotes radicalization.\\n\\n6. **Trust Issues**: The potential for users to be misled by confabulated logic or citations can undermine trust in LLM outputs, particularly in consequential decision-making contexts. \\n\\nThese risks highlight the need for careful oversight and governance in the deployment of LLM technologies.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 225, 'prompt_tokens': 1154, 'total_tokens': 1379, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ab79dfc6-9f34-4efe-a295-90917e18ffb6-0', usage_metadata={'input_tokens': 1154, 'output_tokens': 225, 'total_tokens': 1379}), 'context': [Document(metadata={'_id': 'f64096d0519141c6809de5556145db2d', '_collection_name': 'AI-Risk'}, page_content='with greater ease and scale than other technologies. LLMs have been reported to generate dangerous or \\nviolent recommendations, and some models have generated actionable instructions for dangerous or \\n \\n \\n9 Confabulations of falsehoods are most commonly a problem for text-based outputs; for audio, image, or video \\ncontent, creative generation of non-factual content can be a desired behavior.  \\n10 For example, legal confabulations have been shown to be pervasive in current state-of-the-art LLMs. See also, \\ne.g.,'), Document(metadata={'_id': '2b63eba3dfc14d1b8a94f63ed541bb78', '_collection_name': 'AI-Risk'}, page_content='development, production, or use of CBRN weapons or other dangerous materials or agents. While \\nrelevant biological and chemical threat knowledge and information is often publicly accessible, LLMs \\ncould facilitate its analysis or synthesis, particularly by individuals without formal scientiﬁc training or \\nexpertise.  \\nRecent research on this topic found that LLM outputs regarding biological threat creation and attack \\nplanning provided minimal assistance beyond traditional search engine queries, suggesting that state-of-\\nthe-art LLMs at the time these studies were conducted do not substantially increase the operational \\nlikelihood of such an attack. The physical synthesis development, production, and use of chemical or \\nbiological agents will continue to require both applicable expertise and supporting materials and \\ninfrastructure. The impact of GAI on chemical or biological agent misuse will depend on what the key \\nbarriers for malicious actors are (e.g., whether information access is one such barrier), and how well GAI \\ncan help actors address those barriers.  \\nFurthermore, chemical and biological design tools (BDTs) – highly specialized AI systems trained on \\nscientiﬁc data that aid in chemical and biological design – may augment design capabilities in chemistry \\nand biology beyond what text-based LLMs are able to provide. As these models become more \\neﬃcacious, including for beneﬁcial uses, it will be important to assess their potential to be used for'), Document(metadata={'_id': 'e3637fe28d7246e2b4becb5a7f00e2d2', '_collection_name': 'AI-Risk'}, page_content='information reports could cause doctors to make incorrect diagnoses and/or recommend the wrong \\ntreatments. Risks of confabulated content may be especially important to monitor when integrating GAI \\ninto applications involving consequential decision making. \\nGAI outputs may also include confabulated logic or citations that purport to justify or explain the \\nsystem’s answer, which may further mislead humans into inappropriately trusting the system’s output. \\nFor instance, LLMs sometimes provide logical steps for how they arrived at an answer even when the \\nanswer itself is incorrect. Similarly, an LLM could falsely assert that it is human or has human traits, \\npotentially deceiving humans into believing they are speaking with another human. \\nThe extent to which humans can be deceived by LLMs, the mechanisms by which this may occur, and the \\npotential risks from adversarial prompting of such behavior are emerging areas of study. Given the wide \\nrange of downstream impacts of GAI, it is diﬃcult to estimate the downstream scale and impact of \\nconfabulations. \\nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Valid and Reliable, Explainable \\nand Interpretable \\n2.3. Dangerous, Violent, or Hateful Content \\nGAI systems can produce content that is inciting, radicalizing, or threatening, or that gloriﬁes violence, \\nwith greater ease and scale than other technologies. LLMs have been reported to generate dangerous or'), Document(metadata={'_id': '2912edf97ff7404eb1e151114d5333ab', '_collection_name': 'AI-Risk'}, page_content='burden of oversight and efficiency from employers to workers, schools to students, and landlords to tenants, in \\nways that diminish and encroach on equality of opportunity; assessment of these technologies should include \\nwhether they are genuinely helpful in solving an identified problem. \\nIn discussion of technical and governance interventions that that are needed to protect against the harms of \\nthese technologies, panelists individually described the importance of: receiving community input into the \\ndesign and use of technologies, public reporting on crucial elements of these systems, better notice and consent \\nprocedures that ensure privacy based on context and use case, ability to opt-out of using these systems and \\nreceive a fallback to a human process, providing explanations of decisions and how these systems work, the \\nneed for governance including training in using these systems, ensuring the technological use cases are \\ngenuinely related to the goal task and are locally validated to work, and the need for institution and protection \\nof third party audits to ensure systems continue to be accountable and valid. \\n57')]}\n"
     ]
    }
   ],
   "source": [
    "response = await rag_chain.ainvoke({\"input\":\"What are some key risks associated with modern LLMs?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
