{"questions": {"6c46a68a-0f2a-43eb-8541-73b33b844a93": "What are some of the key considerations organizations must take into account when using GAI systems to manage risks effectively?", "7b660a16-98e7-441b-8318-e2d601005b92": "How does the varied output of AI technology influence the interaction of different AI Actors with GAI systems?", "098fca0a-e877-49c2-936e-2e01e380fe44": "What are some applications and contexts of use for AI mentioned in the provided context?", "37aea982-5d89-41e1-895f-8bde5749ecb0": "In what settings can the activities related to AI applications take place?", "92abe1ab-064b-4914-8622-7f21cec52c8f": "What are some governance tools and protocols that can be applied to GAI systems?", "dfdd562d-45ed-4fc1-a318-a7c15bf2e2dd": "How can organizations ensure alignment of GAI systems to their values?", "d20207d8-a126-45ac-899a-4e3004d2b3a0": "What are some key practices mentioned for ensuring secure software development?", "048135f0-2e21-4bbe-9e21-32e294029779": "How does the context address the importance of stakeholder engagement in data protection?", "12828b22-28f1-4f0d-80ad-3c422365adb8": "What are the potential risks associated with the misuse of GAI in human-AI teaming settings?", "07736c04-8a96-4f76-8e6e-e644d88dec4a": "How can existing governance protocols be adapted for GAI contexts to ensure effective use?", "35df9196-92b0-4dec-bcc1-d648a48fe7c9": "What are some potential implications of using third-party GAI models and systems for an organization?", "cceff065-001a-4bb1-b573-ac97efd4b9b1": "Which functions within an organization may be affected by the use of open-source or proprietary GAI tools?", "8959a172-6292-4053-a93d-1d7483a7522d": "What are some potential risks associated with third-party GAI integrations mentioned in the context?", "aed7d76e-9807-4e38-9c0e-7395b71861e1": "Why is there a need for clear guidelines regarding the collection and use of third-party data for model inputs?", "1d347f03-0628-478d-afff-a52ab5b9ce47": "What types of models are mentioned in the context regarding controls and processes?", "2216bedc-1d41-43af-92ac-b2e94304b577": "How can organizations apply risk controls to GAI technologies and service providers?", "5ffcbbf3-f4ee-4399-8293-b6345341e93f": "What are the challenges associated with risk mapping and pre-deployment measurement efforts for GAI systems?", "615c500e-682e-4b14-90f9-acf726447c44": "How do materials such as SBOMs and SLAs contribute to third-party transparency and risk management in GAI systems?", "df0b2b5e-af00-4d01-b4cd-5982ae95711d": "What are the TEVV processes mentioned in the context, and how can they be applied in the AI lifecycle?", "746f3a7e-981e-4ae5-993d-bb3ad71e6f66": "Who are the representative AI Actors referenced in the context, and what role do they play in the TEVV processes?", "bef44915-66b1-42a3-b5f3-8bab290ca646": "What are the key aspects measured during pre-deployment testing practices for GAI according to the context?", "fe9feb3c-c309-42b3-b509-ce83d496059b": "How does the context describe the limitations of current pre-deployment test approaches?", "65dfc70d-3acb-42f0-b560-17768e54025c": "What are some potential issues with the current pre-deployment TEVV processes for GAI applications?", "db88e486-a3bd-4483-b328-25912f78c5d1": "Why might testing GAI systems using video games or human-designed standardized tests be problematic?", "242ffe07-bff4-485a-8e20-11d13502f974": "What are the potential risks associated with jailbreaking or prompt engineering tests in assessing validity or reliability?", "023a79c5-f247-4015-ab52-e6ff09421faa": "How do measurement gaps occur between laboratory settings and real-world applications in the context of GAI impacts?", "9c914738-eced-45a4-b80e-3a6d079a6730": "What challenges do current measurement gaps for GAI present in estimating its potential risks and impacts?", "bf12dcf3-7101-470f-925a-03739b01c1f5": "How can structured public feedback contribute to the evaluation of GAI systems' performance?", "9ff4e68f-8a2e-4305-ae09-8fa77887551e": "What are some examples of participatory engagement methods used to solicit feedback from communities?", "360c71f2-0d81-4403-8216-a64c58544625": "How does field testing contribute to understanding user interactions with products or services?", "11d146e1-94af-4a49-9e92-049df8603b9b": "What is the purpose of AI Red-teaming in the context of AI systems?", "3c29e388-7d88-4444-95dd-9344849ff0e2": "How can structured public feedback influence the design and deployment of AI systems?", "a824014c-3825-41e0-a099-a275a14627c7": "What purposes can the results and insights from approval, maintenance, or decommissioning decisions serve?", "a6372889-8ea3-4f84-a7b2-8f55fe1832fa": "What best practices should organizations follow when implementing feedback activities related to human subjects research?", "62fd5402-5c9d-4976-8e51-98c9907191e7": "What are some methods organizations can use to engage external stakeholders in product development?", "3732e55a-0c9e-4baa-9ce0-6cdfbe662221": "How can focus groups contribute to the feedback process in product development?", "915fca6f-1816-4eaa-a4b4-d9a68ce40dfe": "What are the key differences between engagement methods and field testing in the context of AI development?", "88e0b81f-24aa-43ef-b739-30eecb46d35a": "How can field testing be adapted to focus on AI risks and impacts?", "f43cd12b-0216-41ad-b5c1-6f043a6db21c": "What types of feedback can organizations collect from users in the production environment after a model has been released?", "c20aa06e-5f94-4278-ae71-58203f09ef39": "Why is it important for organizations to adhere to human subject standards such as informed consent and compensation?", "354948e2-2479-4f94-8589-67590e7edefa": "What are the best practices mentioned for conducting research involving subjects in feedback activities?", "733c51df-561d-415e-a48a-7568c60ead0b": "How does AI red-teaming contribute to identifying potential adverse behaviors in generative AI models?", "d923317f-c3f7-4de5-b7a0-8de177cb96a5": "What is the focus of the section regarding red-teaming in relation to AI models or systems?", "1d883d1d-f4ae-4dbe-b371-3fde94b0c49a": "How does the background and expertise of an AI red team influence the quality of red-teaming outputs?", "39db9caf-2a7f-4575-8726-f60b79cfce5e": "What factors should be considered when analyzing AI red-teaming results before incorporating them into organizational governance?", "d7e4bc38-1cf5-4be0-8d23-61cb0a2ce795": "Who can perform AI red-teaming for the general public, and what expertise is required?", "1b8e7edc-22ef-4a4d-9a14-8b2e411fab80": "What role do lived experiences and perspectives play in the task of AI red-teaming?", "6d9c350c-6307-452b-ac97-60dd51a66f10": "How can the effectiveness of AI red-teaming exercises be enhanced?", "3a192727-ce28-4d7a-a836-373e575257e4": "In what scenarios might AI red-teaming exercises be utilized to address challenges in identifying and recruiting specialists?", "9c9a5e00-8ca2-41ee-aba7-442e94499866": "How can AI red-teaming exercises benefit from the combination of expert and contextual expertise?", "74862eb8-24b1-43cc-9cec-d1c3462e8f4b": "What role do expert AI red-teamers play in modifying or verifying prompts written by general public AI red-teamers?", "fdac8807-5d02-4d51-8fc4-4f857ef89c89": "How does GAI-led red-teaming compare in cost-effectiveness to traditional human red-teamers?", "521c94eb-b005-4aad-a409-7c4ff45b1cd4": "What are some applications of GAI technologies mentioned in the context?", "efc2e543-3d6f-47d8-8155-091348c5abef": "How can digital transparency mechanisms help in managing the risks associated with AI-generated synthetic content?", "12f159d1-368e-4734-9a89-3c2aa63a5de5": "How can provenance data tracking enhance users' understanding of the trustworthiness of AI systems?", "a929fd68-4942-4f27-8317-45c566066cc5": "In what ways do digital content transparency approaches contribute to organizational accountability?", "d9fd0575-51b2-43b2-9649-f9700699f790": "What types of information can provenance metadata include regarding GAI content?", "b371687c-2f22-4c0f-bdac-8ebadc8f38e2": "How do provenance data tracking and synthetic content detection mechanisms assist in GAI risk management efforts?", "60eb8c4f-b1bf-4106-9e2c-b6ed328dc34a": "What are some techniques used for provenance data tracking in digital content?", "d2a3ce04-a171-43c5-aff2-4ec508ee14a9": "How can provenance data tracking techniques help in assessing the integrity of digital content?", "c76c651a-6696-410c-8caf-994e6abaa54c": "What are the main components of provenance data tracking techniques for GAI systems?", "112f823f-e4f1-4f3b-98ed-4f757729e02b": "How does provenance data tracking contribute to determining the authenticity of digital content?", "04fd9c6b-8cc1-4793-bf44-330a7cfa2f82": "What role do metadata and digital watermarking techniques play in tracking the provenance of input data?", "a7fbfd88-6ee9-4d9b-b05f-54b75c230aa9": "How can provenance data assist AI Actors in managing early-stage model decisions and their impacts on performance?", "59838b41-827c-4f53-afdb-15d51f6066b6": "What are the two organizational risk management efforts mentioned for enhancing content provenance in GAI systems?", "87673298-2cf3-4202-9f5f-9f6aaca76875": "How might an AI actor inadvertently affect the computational complexity of watermarking?", "7c2f4893-90b0-4d35-9564-3ae2b0f43ab6": "What are the key aspects of monitoring system capabilities and limitations in deployment through TEVV processes?", "b15f53b3-dce0-4a11-9ffc-c48683bcdb41": "How do humans engage with and adapt to GAI content in decision-making tasks, and what is the impact of applied provenance techniques?", "118e08f8-00ce-4dcb-b1f2-30b716c610e3": "What role do watermarking techniques play in the context of GAI systems used for content creation?", "b4118949-cb59-46f2-8253-941e7b6b3486": "How can organizations benefit from narrowing GAI task definitions to include provenance data?", "40bbc314-868a-4ec8-b846-4be6469897dc": "What are the limitations of indirect feedback methods like automated error collection systems in enhancing content provenance?", "ae13632b-762a-4b2d-bc9c-ebf929af426e": "How can organizations utilize feedback approaches from the Pre-Deployment Testing section to improve content provenance?", "bbf5b45f-d2cc-4543-bfe3-8c1897dd3f0c": "How can integrating external feedback into the monitoring process for GAI models enhance awareness of performance changes?", "b73c010d-1e1f-4ecb-9258-f027278aa723": "What are some methods to capture user feedback before and after the deployment of GAI systems?", "edeab073-c298-47e8-a154-89b92e9907d2": "What are the potential impacts of adversarial threats on authentication techniques?", "e0422e3c-4d4c-4a8c-a0f7-9cc055e23ee1": "How can organizations utilize content provenance approaches to address performance issues in GAI systems?", "163132cb-de1f-4696-bfd5-cb738615699a": "What are the potential harms associated with AI incidents as defined in the context?", "fad6a6b1-8edf-4aa2-8f48-114e70c7bc7c": "How can AI incidents affect the management and operation of critical infrastructure?", "857ab15e-dae8-44b0-9984-32c9cdcb397b": "What types of rights are mentioned as being potentially breached by AI incidents in the context provided?", "193cee68-4a55-4e2c-938f-4890fa15ec73": "How can AI incidents manifest according to the context, and what are the two types of occurrences described?"}, "relevant_contexts": {"6c46a68a-0f2a-43eb-8541-73b33b844a93": ["ec919ddd-b319-4067-8a13-efeab849aec4"], "7b660a16-98e7-441b-8318-e2d601005b92": ["ec919ddd-b319-4067-8a13-efeab849aec4"], "098fca0a-e877-49c2-936e-2e01e380fe44": ["2068ce50-76a9-462a-bab2-dfae525f3981"], "37aea982-5d89-41e1-895f-8bde5749ecb0": ["2068ce50-76a9-462a-bab2-dfae525f3981"], "92abe1ab-064b-4914-8622-7f21cec52c8f": ["6eaa8414-3cfc-4ffd-afdc-97c49548b2af"], "dfdd562d-45ed-4fc1-a318-a7c15bf2e2dd": ["6eaa8414-3cfc-4ffd-afdc-97c49548b2af"], "d20207d8-a126-45ac-899a-4e3004d2b3a0": ["2818493e-9e1a-4e64-8e19-927598469703"], "048135f0-2e21-4bbe-9e21-32e294029779": ["2818493e-9e1a-4e64-8e19-927598469703"], "12828b22-28f1-4f0d-80ad-3c422365adb8": ["02d9e158-bdf0-4f82-91ed-8b2f3bd541c2"], "07736c04-8a96-4f76-8e6e-e644d88dec4a": ["02d9e158-bdf0-4f82-91ed-8b2f3bd541c2"], "35df9196-92b0-4dec-bcc1-d648a48fe7c9": ["d78baa20-65a8-4f86-87bf-8c46fd2683db"], "cceff065-001a-4bb1-b573-ac97efd4b9b1": ["d78baa20-65a8-4f86-87bf-8c46fd2683db"], "8959a172-6292-4053-a93d-1d7483a7522d": ["1f50bddf-61a2-49a2-b06a-151e7874fb30"], "aed7d76e-9807-4e38-9c0e-7395b71861e1": ["1f50bddf-61a2-49a2-b06a-151e7874fb30"], "1d347f03-0628-478d-afff-a52ab5b9ce47": ["051d1e7c-fe53-4e04-9ff7-0d54934eb46a"], "2216bedc-1d41-43af-92ac-b2e94304b577": ["051d1e7c-fe53-4e04-9ff7-0d54934eb46a"], "5ffcbbf3-f4ee-4399-8293-b6345341e93f": ["6df7fcd6-0b8c-4b98-b52b-493da7240738"], "615c500e-682e-4b14-90f9-acf726447c44": ["6df7fcd6-0b8c-4b98-b52b-493da7240738"], "df0b2b5e-af00-4d01-b4cd-5982ae95711d": ["29fb8dde-ea72-4f56-9081-14efd190fc51"], "746f3a7e-981e-4ae5-993d-bb3ad71e6f66": ["29fb8dde-ea72-4f56-9081-14efd190fc51"], "bef44915-66b1-42a3-b5f3-8bab290ca646": ["f66770cb-5297-434c-9e8f-83cd6f4b12cb"], "fe9feb3c-c309-42b3-b509-ce83d496059b": ["f66770cb-5297-434c-9e8f-83cd6f4b12cb"], "65dfc70d-3acb-42f0-b560-17768e54025c": ["852228c8-7e38-4ed0-b94e-c310321ea45d"], "db88e486-a3bd-4483-b328-25912f78c5d1": ["852228c8-7e38-4ed0-b94e-c310321ea45d"], "242ffe07-bff4-485a-8e20-11d13502f974": ["a04da9fe-7f2f-4794-85da-d9253f674176"], "023a79c5-f247-4015-ab52-e6ff09421faa": ["a04da9fe-7f2f-4794-85da-d9253f674176"], "9c914738-eced-45a4-b80e-3a6d079a6730": ["8961db49-0fee-4f9b-9022-519df3164f39"], "bf12dcf3-7101-470f-925a-03739b01c1f5": ["8961db49-0fee-4f9b-9022-519df3164f39"], "9ff4e68f-8a2e-4305-ae09-8fa77887551e": ["46a97884-a6c6-4f15-90a7-3456efe97e0f"], "360c71f2-0d81-4403-8216-a64c58544625": ["46a97884-a6c6-4f15-90a7-3456efe97e0f"], "11d146e1-94af-4a49-9e92-049df8603b9b": ["92a41c35-538f-4476-bbfa-fbd775e46b19"], "3c29e388-7d88-4444-95dd-9344849ff0e2": ["92a41c35-538f-4476-bbfa-fbd775e46b19"], "a824014c-3825-41e0-a099-a275a14627c7": ["6813284b-dcb0-44b0-b53b-0bfaff454658"], "a6372889-8ea3-4f84-a7b2-8f55fe1832fa": ["6813284b-dcb0-44b0-b53b-0bfaff454658"], "62fd5402-5c9d-4976-8e51-98c9907191e7": ["dc0b7278-a540-469b-aa9e-c57eadc1cf41"], "3732e55a-0c9e-4baa-9ce0-6cdfbe662221": ["dc0b7278-a540-469b-aa9e-c57eadc1cf41"], "915fca6f-1816-4eaa-a4b4-d9a68ce40dfe": ["5967b5bc-94f6-46dd-a1a7-12b2ce189ac5"], "88e0b81f-24aa-43ef-b739-30eecb46d35a": ["5967b5bc-94f6-46dd-a1a7-12b2ce189ac5"], "f43cd12b-0216-41ad-b5c1-6f043a6db21c": ["df7713b5-a055-4b8c-adf4-c2513482e3f0"], "c20aa06e-5f94-4278-ae71-58203f09ef39": ["df7713b5-a055-4b8c-adf4-c2513482e3f0"], "354948e2-2479-4f94-8589-67590e7edefa": ["d778939c-f8df-47df-bd83-48354ab528f6"], "733c51df-561d-415e-a48a-7568c60ead0b": ["d778939c-f8df-47df-bd83-48354ab528f6"], "d923317f-c3f7-4de5-b7a0-8de177cb96a5": ["16b2bdd5-3eff-4775-a57b-1e9e913f12de"], "1d883d1d-f4ae-4dbe-b371-3fde94b0c49a": ["16b2bdd5-3eff-4775-a57b-1e9e913f12de"], "39db9caf-2a7f-4575-8726-f60b79cfce5e": ["7d62233b-b253-4019-83c1-d78818e50a3a"], "d7e4bc38-1cf5-4be0-8d23-61cb0a2ce795": ["7d62233b-b253-4019-83c1-d78818e50a3a"], "1b8e7edc-22ef-4a4d-9a14-8b2e411fab80": ["42c7dd25-7b68-42e9-b55b-832a5f9516a0"], "6d9c350c-6307-452b-ac97-60dd51a66f10": ["42c7dd25-7b68-42e9-b55b-832a5f9516a0"], "3a192727-ce28-4d7a-a836-373e575257e4": ["ece86741-7d27-4b50-957d-3a010c492f01"], "9c9a5e00-8ca2-41ee-aba7-442e94499866": ["ece86741-7d27-4b50-957d-3a010c492f01"], "74862eb8-24b1-43cc-9cec-d1c3462e8f4b": ["6eb76816-9c39-4861-b89e-c50c7fe2d7ed"], "fdac8807-5d02-4d51-8fc4-4f857ef89c89": ["6eb76816-9c39-4861-b89e-c50c7fe2d7ed"], "521c94eb-b005-4aad-a409-7c4ff45b1cd4": ["cdc6510e-7d36-4931-9be7-1485e6922e8d"], "efc2e543-3d6f-47d8-8155-091348c5abef": ["cdc6510e-7d36-4931-9be7-1485e6922e8d"], "12f159d1-368e-4734-9a89-3c2aa63a5de5": ["1711d484-6254-4bad-ad5b-19a664dcfc88"], "a929fd68-4942-4f27-8317-45c566066cc5": ["1711d484-6254-4bad-ad5b-19a664dcfc88"], "d9fd0575-51b2-43b2-9649-f9700699f790": ["b7825a3b-3336-4ead-95ed-e7902f2df32a"], "b371687c-2f22-4c0f-bdac-8ebadc8f38e2": ["b7825a3b-3336-4ead-95ed-e7902f2df32a"], "60eb8c4f-b1bf-4106-9e2c-b6ed328dc34a": ["93b8c098-90c8-46d0-aae5-ffdcfb8e351e"], "d2a3ce04-a171-43c5-aff2-4ec508ee14a9": ["93b8c098-90c8-46d0-aae5-ffdcfb8e351e"], "c76c651a-6696-410c-8caf-994e6abaa54c": ["7ba71db4-8983-404a-b7d5-d4f2256601f6"], "112f823f-e4f1-4f3b-98ed-4f757729e02b": ["7ba71db4-8983-404a-b7d5-d4f2256601f6"], "04fd9c6b-8cc1-4793-bf44-330a7cfa2f82": ["e4dfd6bc-937f-47af-a4d6-36782a2222a3"], "a7fbfd88-6ee9-4d9b-b05f-54b75c230aa9": ["e4dfd6bc-937f-47af-a4d6-36782a2222a3"], "59838b41-827c-4f53-afdb-15d51f6066b6": ["19021a23-06c7-41fa-83bb-bf38febbc138"], "87673298-2cf3-4202-9f5f-9f6aaca76875": ["19021a23-06c7-41fa-83bb-bf38febbc138"], "7c2f4893-90b0-4d35-9564-3ae2b0f43ab6": ["bc8fc58d-85e7-4f51-86d8-21f1bba9ceb4"], "b15f53b3-dce0-4a11-9ffc-c48683bcdb41": ["bc8fc58d-85e7-4f51-86d8-21f1bba9ceb4"], "118e08f8-00ce-4dcb-b1f2-30b716c610e3": ["833118da-c51d-4d8a-b8e7-eb544acd8cd5"], "b4118949-cb59-46f2-8253-941e7b6b3486": ["833118da-c51d-4d8a-b8e7-eb544acd8cd5"], "40bbc314-868a-4ec8-b846-4be6469897dc": ["871d7597-f0e8-4fa6-9a06-ac55a591be1a"], "ae13632b-762a-4b2d-bc9c-ebf929af426e": ["871d7597-f0e8-4fa6-9a06-ac55a591be1a"], "bbf5b45f-d2cc-4543-bfe3-8c1897dd3f0c": ["c1660719-50a9-4b37-b8ef-6e8aa0be29f0"], "b73c010d-1e1f-4ecb-9258-f027278aa723": ["c1660719-50a9-4b37-b8ef-6e8aa0be29f0"], "edeab073-c298-47e8-a154-89b92e9907d2": ["505e7a63-64db-489a-93cc-db5dbafdc99a"], "e0422e3c-4d4c-4a8c-a0f7-9cc055e23ee1": ["505e7a63-64db-489a-93cc-db5dbafdc99a"], "163132cb-de1f-4696-bfd5-cb738615699a": ["ad224552-7834-4c9a-afed-b69462204eca"], "fad6a6b1-8edf-4aa2-8f48-114e70c7bc7c": ["ad224552-7834-4c9a-afed-b69462204eca"], "857ab15e-dae8-44b0-9984-32c9cdcb397b": ["1d09e04d-9879-46f9-a0a4-da6c6494e1cd"], "193cee68-4a55-4e2c-938f-4890fa15ec73": ["1d09e04d-9879-46f9-a0a4-da6c6494e1cd"]}, "corpus": {"ec919ddd-b319-4067-8a13-efeab849aec4": "con\ufb01gurations in order to manage their risks e\ufb00ectively. Organizations\u2019 use of GAI systems may also \nwarrant additional human review, tracking and documentation, and greater management oversight.  \nAI technology can produce varied outputs in multiple modalities and present many classes of user \ninterfaces. This leads to a broader set of AI Actors interacting with GAI systems for widely di\ufb00ering", "2068ce50-76a9-462a-bab2-dfae525f3981": "applications and contexts of use. These can include data labeling and preparation, development of GAI \nmodels, content moderation, code generation and review, text generation and editing, image and video \ngeneration, summarization, search, and chat. These activities can take place within organizational \nsettings or in the public domain. \nOrganizations can restrict AI applications that cause harm, exceed stated risk tolerances, or that con\ufb02ict", "6eaa8414-3cfc-4ffd-afdc-97c49548b2af": "with their tolerances or values. Governance tools and protocols that are applied to other types of AI \nsystems can be applied to GAI systems. These plans and actions include: \n\u2022 Accessibility and reasonable \naccommodations \n\u2022 AI actor credentials and quali\ufb01cations  \n\u2022 Alignment to organizational values \n\u2022 Auditing and assessment \n\u2022 Change-management controls \n\u2022 Commercial use \n\u2022 Data provenance", "2818493e-9e1a-4e64-8e19-927598469703": "48 \n\u2022 Data protection \n\u2022 Data retention  \n\u2022 Consistency in use of de\ufb01ning key terms \n\u2022 Decommissioning \n\u2022 Discouraging anonymous use \n\u2022 Education  \n\u2022 Impact assessments  \n\u2022 Incident response \n\u2022 Monitoring \n\u2022 Opt-outs  \n\u2022 Risk-based controls \n\u2022 Risk mapping and measurement \n\u2022 Science-backed TEVV practices \n\u2022 Secure software development practices \n\u2022 Stakeholder engagement \n\u2022 Synthetic content detection and \nlabeling tools and techniques \n\u2022 Whistleblower protections \n\u2022 Workforce diversity and", "02d9e158-bdf0-4f82-91ed-8b2f3bd541c2": "\u2022 Workforce diversity and \ninterdisciplinary teams\nEstablishing acceptable use policies and guidance for the use of GAI in formal human-AI teaming settings \nas well as di\ufb00erent levels of human-AI con\ufb01gurations can help to decrease risks arising from misuse, \nabuse, inappropriate repurpose, and misalignment between systems and users. These practices are just \none example of adapting existing governance protocols for GAI contexts.  \nA.1.3. Third-Party Considerations", "d78baa20-65a8-4f86-87bf-8c46fd2683db": "A.1.3. Third-Party Considerations \nOrganizations may seek to acquire, embed, incorporate, or use open-source or proprietary third-party \nGAI models, systems, or generated data for various applications across an enterprise. Use of these GAI \ntools and inputs has implications for all functions of the organization \u2013 including but not limited to \nacquisition, human resources, legal, compliance, and IT services \u2013 regardless of whether they are carried", "1f50bddf-61a2-49a2-b06a-151e7874fb30": "out by employees or third parties. Many of the actions cited above are relevant and options for \naddressing third-party considerations. \nThird party GAI integrations may give rise to increased intellectual property, data privacy, or information \nsecurity risks, pointing to the need for clear guidelines for transparency and risk management regarding \nthe collection and use of third-party data for model inputs. Organizations may consider varying risk", "051d1e7c-fe53-4e04-9ff7-0d54934eb46a": "controls for foundation models, \ufb01ne-tuned models, and embedded tools, enhanced processes for \ninteracting with external GAI technologies or service providers. Organizations can apply standard or \nexisting risk controls and processes to proprietary or open-source GAI technologies, data, and third-party \nservice providers, including acquisition and procurement due diligence, requests for software bills of", "6df7fcd6-0b8c-4b98-b52b-493da7240738": "materials (SBOMs), application of service level agreements (SLAs), and statement on standards for \nattestation engagement (SSAE) reports to help with third-party transparency and risk management for \nGAI systems. \nA.1.4. Pre-Deployment Testing \nOverview \nThe diverse ways and contexts in which GAI systems may be developed, used, and repurposed \ncomplicates risk mapping and pre-deployment measurement e\ufb00orts. Robust test, evaluation, validation,", "29fb8dde-ea72-4f56-9081-14efd190fc51": "and veri\ufb01cation (TEVV) processes can be iteratively applied \u2013 and documented \u2013 in early stages of the AI \nlifecycle and informed by representative AI Actors (see Figure 3 of the AI RMF). Until new and rigorous", "f66770cb-5297-434c-9e8f-83cd6f4b12cb": "49 \nearly lifecycle TEVV approaches are developed and matured for GAI, organizations may use \nrecommended \u201cpre-deployment testing\u201d practices to measure performance, capabilities, limits, risks, \nand impacts. This section describes risk measurement and estimation as part of pre-deployment TEVV, \nand examines the state of play for pre-deployment testing methodologies.  \nLimitations of Current Pre-deployment Test Approaches", "852228c8-7e38-4ed0-b94e-c310321ea45d": "Currently available pre-deployment TEVV processes used for GAI applications may be inadequate, non-\nsystematically applied, or fail to re\ufb02ect or mismatched to deployment contexts. For example, the \nanecdotal testing of GAI system capabilities through video games or standardized tests designed for \nhumans (e.g., intelligence tests, professional licensing exams) does not guarantee GAI system validity or", "a04da9fe-7f2f-4794-85da-d9253f674176": "reliability in those domains. Similarly, jailbreaking or prompt engineering tests may not systematically \nassess validity or reliability risks.  \nMeasurement gaps can arise from mismatches between laboratory and real-world settings. Current \ntesting approaches often remain focused on laboratory conditions or restricted to benchmark test \ndatasets and in silico techniques that may not extrapolate well to\u2014or directly assess GAI impacts in real-", "8961db49-0fee-4f9b-9022-519df3164f39": "world conditions. For example, current measurement gaps for GAI make it di\ufb03cult to precisely estimate \nits potential ecosystem-level or longitudinal risks and related political, social, and economic impacts. \nGaps between benchmarks and real-world use of GAI systems may likely be exacerbated due to prompt \nsensitivity and broad heterogeneity of contexts of use. \nA.1.5. Structured Public Feedback \nStructured public feedback can be used to evaluate whether GAI systems are performing as intended", "46a97884-a6c6-4f15-90a7-3456efe97e0f": "and to calibrate and verify traditional measurement methods. Examples of structured feedback include, \nbut are not limited to: \n\u2022 \nParticipatory Engagement Methods: Methods used to solicit feedback from civil society groups, \na\ufb00ected communities, and users, including focus groups, small user studies, and surveys. \n\u2022 \nField Testing: Methods used to determine how people interact with, consume, use, and make", "92a41c35-538f-4476-bbfa-fbd775e46b19": "sense of AI-generated information, and subsequent actions and e\ufb00ects, including UX, usability, \nand other structured, randomized experiments.  \n\u2022 \nAI Red-teaming: A structured testing exercise used to probe an AI system to \ufb01nd \ufb02aws and \nvulnerabilities such as inaccurate, harmful, or discriminatory outputs, often in a controlled \nenvironment and in collaboration with system developers. \nInformation gathered from structured public feedback can inform design, implementation, deployment", "6813284b-dcb0-44b0-b53b-0bfaff454658": "approval, maintenance, or decommissioning decisions. Results and insights gleaned from these exercises \ncan serve multiple purposes, including improving data quality and preprocessing, bolstering governance \ndecision making, and enhancing system documentation and debugging practices. When implementing \nfeedback activities, organizations should follow human subjects research requirements and best \npractices such as informed consent and subject compensation.", "dc0b7278-a540-469b-aa9e-c57eadc1cf41": "50 \nParticipatory Engagement Methods \nOn an ad hoc or more structured basis, organizations can design and use a variety of channels to engage \nexternal stakeholders in product development or review. Focus groups with select experts can provide \nfeedback on a range of issues. Small user studies can provide feedback from representative groups or \npopulations. Anonymous surveys can be used to poll or gauge reactions to speci\ufb01c features. Participatory", "5967b5bc-94f6-46dd-a1a7-12b2ce189ac5": "engagement methods are often less structured than \ufb01eld testing or red teaming, and are more \ncommonly used in early stages of AI or product development.  \nField Testing \nField testing involves structured settings to evaluate risks and impacts and to simulate the conditions \nunder which the GAI system will be deployed. Field style tests can be adapted from a focus on user \npreferences and experiences towards AI risks and impacts \u2013 both negative and positive. When carried", "df7713b5-a055-4b8c-adf4-c2513482e3f0": "out with large groups of users, these tests can provide estimations of the likelihood of risks and impacts \nin real world interactions. \nOrganizations may also collect feedback on outcomes, harms, and user experience directly from users in \nthe production environment after a model has been released, in accordance with human subject \nstandards such as informed consent and compensation. Organizations should follow applicable human", "d778939c-f8df-47df-bd83-48354ab528f6": "subjects research requirements, and best practices such as informed consent and subject compensation, \nwhen implementing feedback activities. \nAI Red-teaming \nAI red-teaming is an evolving practice that references exercises often conducted in a controlled \nenvironment and in collaboration with AI developers building AI models to identify potential adverse \nbehavior or outcomes of a GAI model or system, how they could occur, and stress test safeguards\u201d. AI", "16b2bdd5-3eff-4775-a57b-1e9e913f12de": "red-teaming can be performed before or after AI models or systems are made available to the broader \npublic; this section focuses on red-teaming in pre-deployment contexts.  \nThe quality of AI red-teaming outputs is related to the background and expertise of the AI red team \nitself. Demographically and interdisciplinarily diverse AI red teams can be used to identify \ufb02aws in the \nvarying contexts where GAI will be used. For best results, AI red teams should demonstrate domain", "7d62233b-b253-4019-83c1-d78818e50a3a": "expertise, and awareness of socio-cultural aspects within the deployment context. AI red-teaming results \nshould be given additional analysis before they are incorporated into organizational governance and \ndecision making, policy and procedural updates, and AI risk management e\ufb00orts. \nVarious types of AI red-teaming may be appropriate, depending on the use case: \n\u2022 \nGeneral Public: Performed by general users (not necessarily AI or technical experts) who are", "42c7dd25-7b68-42e9-b55b-832a5f9516a0": "expected to use the model or interact with its outputs, and who bring their own lived \nexperiences and perspectives to the task of AI red-teaming. These individuals may have been \nprovided instructions and material to complete tasks which may elicit harmful model behaviors. \nThis type of exercise can be more e\ufb00ective with large groups of AI red-teamers. \n\u2022 \nExpert: Performed by specialists with expertise in the domain or speci\ufb01c AI red-teaming context", "ece86741-7d27-4b50-957d-3a010c492f01": "of use (e.g., medicine, biotech, cybersecurity).  \n\u2022 \nCombination: In scenarios when it is di\ufb03cult to identify and recruit specialists with su\ufb03cient \ndomain and contextual expertise, AI red-teaming exercises may leverage both expert and", "6eb76816-9c39-4861-b89e-c50c7fe2d7ed": "51 \ngeneral public participants. For example, expert AI red-teamers could modify or verify the \nprompts written by general public AI red-teamers. These approaches may also expand coverage \nof the AI risk attack surface.  \n\u2022 \nHuman / AI: Performed by GAI in combination with specialist or non-specialist human teams. \nGAI-led red-teaming can be more cost e\ufb00ective than human red-teamers alone. Human or GAI-\nled AI red-teaming may be better suited for eliciting di\ufb00erent types of harms.", "cdc6510e-7d36-4931-9be7-1485e6922e8d": "A.1.6. Content Provenance \nOverview \nGAI technologies can be leveraged for many applications such as content generation and synthetic data. \nSome aspects of GAI outputs, such as the production of deepfake content, can challenge our ability to \ndistinguish human-generated content from AI-generated synthetic content. To help manage and mitigate \nthese risks, digital transparency mechanisms like provenance data tracking can trace the origin and", "1711d484-6254-4bad-ad5b-19a664dcfc88": "history of content. Provenance data tracking and synthetic content detection can help facilitate greater \ninformation access about both authentic and synthetic content to users, enabling better knowledge of \ntrustworthiness in AI systems. When combined with other organizational accountability mechanisms, \ndigital content transparency approaches can enable processes to trace negative outcomes back to their", "b7825a3b-3336-4ead-95ed-e7902f2df32a": "source, improve information integrity, and uphold public trust. Provenance data tracking and synthetic \ncontent detection mechanisms provide information about the origin and history of content to assist in \nGAI risk management e\ufb00orts. \nProvenance metadata can include information about GAI model developers or creators of GAI content, \ndate/time of creation, location, modi\ufb01cations, and sources. Metadata can be tracked for text, images,", "93b8c098-90c8-46d0-aae5-ffdcfb8e351e": "videos, audio, and underlying datasets. The implementation of provenance data tracking techniques can \nhelp assess the authenticity, integrity, intellectual property rights, and potential manipulations in digital \ncontent. Some well-known techniques for provenance data tracking include digital watermarking, \nmetadata recording, digital \ufb01ngerprinting, and human authentication, among others. \nProvenance Data Tracking Approaches", "7ba71db4-8983-404a-b7d5-d4f2256601f6": "Provenance Data Tracking Approaches \nProvenance data tracking techniques for GAI systems can be used to track the history and origin of data \ninputs, metadata, and synthetic content. Provenance data tracking records the origin and history for \ndigital content, allowing its authenticity to be determined. It consists of techniques to record metadata \nas well as overt and covert digital watermarks on content. Data provenance refers to tracking the origin", "e4dfd6bc-937f-47af-a4d6-36782a2222a3": "and history of input data through metadata and digital watermarking techniques. Provenance data \ntracking processes can include and assist AI Actors across the lifecycle who may not have full visibility or \ncontrol over the various trade-o\ufb00s and cascading impacts of early-stage model decisions on downstream \nperformance and synthetic outputs. For example, by selecting a watermarking model to prioritize", "19021a23-06c7-41fa-83bb-bf38febbc138": "robustness (the durability of a watermark), an AI actor may inadvertently diminish computational \ncomplexity (the resources required to implement watermarking). Organizational risk management \ne\ufb00orts for enhancing content provenance include:  \n\u2022 \nTracking provenance of training data and metadata for GAI systems; \n\u2022 \nDocumenting provenance data limitations within GAI systems;", "bc8fc58d-85e7-4f51-86d8-21f1bba9ceb4": "52 \n\u2022 \nMonitoring system capabilities and limitations in deployment through rigorous TEVV processes; \n\u2022 \nEvaluating how humans engage, interact with, or adapt to GAI content (especially in decision \nmaking tasks informed by GAI content), and how they react to applied provenance techniques \nsuch as overt disclosures. \nOrganizations can document and delineate GAI system objectives and limitations to identify gaps where", "833118da-c51d-4d8a-b8e7-eb544acd8cd5": "provenance data may be most useful. For instance, GAI systems used for content creation may require \nrobust watermarking techniques and corresponding detectors to identify the source of content or \nmetadata recording techniques and metadata management tools and repositories to trace content \norigins and modi\ufb01cations. Further narrowing of GAI task de\ufb01nitions to include provenance data can \nenable organizations to maximize the utility of provenance data and risk management e\ufb00orts.", "871d7597-f0e8-4fa6-9a06-ac55a591be1a": "A.1.7. Enhancing Content Provenance through Structured Public Feedback \nWhile indirect feedback methods such as automated error collection systems are useful, they often lack \nthe context and depth that direct input from end users can provide. Organizations can leverage feedback \napproaches described in the Pre-Deployment Testing section to capture input from external sources such \nas through AI red-teaming.", "c1660719-50a9-4b37-b8ef-6e8aa0be29f0": "as through AI red-teaming.  \nIntegrating pre- and post-deployment external feedback into the monitoring process for GAI models and \ncorresponding applications can help enhance awareness of performance changes and mitigate potential \nrisks and harms from outputs. There are many ways to capture and make use of user feedback \u2013 before \nand after GAI systems and digital content transparency approaches are deployed \u2013 to gain insights about", "505e7a63-64db-489a-93cc-db5dbafdc99a": "authentication e\ufb03cacy and vulnerabilities, impacts of adversarial threats on techniques, and unintended \nconsequences resulting from the utilization of content provenance approaches on users and \ncommunities. Furthermore, organizations can track and document the provenance of datasets to identify \ninstances in which AI-generated data is a potential root cause of performance issues with the GAI \nsystem. \nA.1.8. Incident Disclosure \nOverview", "ad224552-7834-4c9a-afed-b69462204eca": "system. \nA.1.8. Incident Disclosure \nOverview \nAI incidents can be de\ufb01ned as an \u201cevent, circumstance, or series of events where the development, use, \nor malfunction of one or more AI systems directly or indirectly contributes to one of the following harms: \ninjury or harm to the health of a person or groups of people (including psychological harms and harms to \nmental health); disruption of the management and operation of critical infrastructure; violations of", "1d09e04d-9879-46f9-a0a4-da6c6494e1cd": "human rights or a breach of obligations under applicable law intended to protect fundamental, labor, \nand intellectual property rights; or harm to property, communities, or the environment.\u201d AI incidents can \noccur in the aggregate (i.e., for systemic discrimination) or acutely (i.e., for one individual). \nState of AI Incident Tracking and Disclosure \nFormal channels do not currently exist to report and document AI incidents. However, a number of"}}