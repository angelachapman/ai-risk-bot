{"questions": {"7da4306b-07a5-40a2-a188-25437e45abaf": "What is the title of the publication related to Artificial Intelligence Risk Management by NIST?", "957125d2-fb67-48e3-8d1d-f4325a566484": "Where can the NIST AI 600-1 publication be accessed for free?", "f229f517-f23a-43f4-8a09-6b69e76b6783": "What is the title of the publication released by NIST in July 2024 regarding artificial intelligence?", "987aa119-fd53-436a-b9af-0c82aa68e598": "Who is the Secretary of the US Department of Commerce mentioned in the context?", "39bf9a10-3f3a-407f-847c-7aefe861beea": "What are the main goals of NIST in developing standards for artificial intelligence?", "79ca268f-4d35-4c4b-8ba5-4d56dfbc097d": "How does NIST aim to ensure that the benefits of AI are realized without harm to people or the planet?", "b602dc85-f613-4a50-b303-d85c312d07bc": "What is the purpose of the US AI Safety Institute established by NIST?", "3576faba-8c35-4382-a8d2-5469d48cfeba": "How does the AI Safety Institute Consortium relate to the 2023 Executive Order on Safe, Secure, and Trustworthy AI?", "89377f71-26fa-4d0b-a4c9-9e4df3c7d41b": "Who are some of the individuals involved in the NIST Generative AI Public Working Group?", "5684046a-0420-45c1-a81d-0c8bb0694783": "When was the NIST Technical Series Publication approved by the NIST Editorial Review Board?", "daa24cc1-9244-407a-a961-f7303f6660be": "What is the email address for inquiries related to the NIST AI Innovation Lab?", "9cb3088c-f196-453a-9d02-a860bbee0253": "Where can additional information about NIST AI publications be found?", "4e0aa1d2-d7a0-4e34-b962-31481fc60432": "What is the purpose of identifying entities, materials, or equipment in the context of an experimental procedure?", "51fa362a-a05c-4184-a255-b3310f8e96c9": "Does the identification of specific products imply a recommendation or endorsement by the National Institute of Standards and Technology?", "3a4f6df5-cbba-4b51-b226-3782f1c0f02b": "What is the purpose of the information provided in the context?", "9b1cf4f6-fbc2-4cec-a3c9-2313af798226": "Does the context imply any endorsement or recommendation by a US Government agency?", "f3aa3a80-0885-4502-bfdd-c775eb5c88bf": "What is the focus of the section titled \"Overview of Risks Unique to or Exacerbated by GAI\"?", "35c630e9-3e88-450b-bcca-da30efbbf0c0": "What does the section \"Suggested Actions to Manage GAI Risks\" propose?", "618cc897-0c43-438e-a3ce-0b98cacc93ce": "What is the title of Appendix A in the document?", "80f50aec-d0ad-47c9-8d27-87587a841504": "On which page can Appendix B be found?", "c2baf0f1-b816-4678-b4bc-95a4533e7f2a": "What is the purpose of the AI Risk Management Framework (AI RMF 10) for Generative AI?", "3782a589-e437-4c5d-9861-7c9eaa8c03df": "When was the AI RMF released, and what executive order does it relate to?", "e5a6107e-1fe9-455a-861e-3d6556ca8bdc": "What is the purpose of AI RMF profiles in the context of Generative AI?", "1f0b83a8-8467-432a-a2b3-4c822fc21647": "How do AI RMF profiles assist organizations in their decision-making processes regarding AI products and services?", "43c6a76a-e065-4717-84fc-86b86faefb71": "How can organizations best manage AI risks while aligning with their goals and legal requirements?", "bc3edda3-22fa-4376-be8a-911a9972f247": "What insights does the AI RMF profile provide regarding risk management across the AI lifecycle?", "b0dbee88-053c-43a2-8a68-4331ad22336e": "What are cross-sectoral profiles used for in relation to activities or business processes?", "10732235-3d5a-488b-9540-70a86aa2c2e1": "What types of risks does the document define that are associated with the use of GAI?", "d30764e4-985c-445d-b4da-f08dcc74b273": "What does EO 14110 define as Generative AI?", "f3cef27e-3b55-4ea0-9f2f-74d95a6733f0": "What types of digital content can Generative AI generate according to the provided context?", "eddf8984-d9cd-4159-91d7-09e566302725": "What is the definition of \"dual-use foundation models\" according to EO 14110?", "bc648d2f-5f5f-4c1c-abfd-0702bff16ec1": "How many parameters must a model contain to be classified as a dual-use foundation model?", "14d14675-62cb-44bd-8e92-11c0e45b358a": "What is the purpose of the companion resource NIST AI 100\u20131 being developed by the Director of the National Institute of Standards and Technology (NIST)?", "31c1c6cf-78ca-4d9c-b3e1-ffc6e96d50ec": "What does AI RMF stand for in the context of the development of NIST AI 100\u20131?", "d0aced1d-fee9-4cc5-8b60-e2e10bdcee5e": "What was the purpose of the NIST\u2019s Generative AI Public Working Group (GAI PWG)?", "6ce560e2-4d54-47fa-86b0-853619d9a656": "What were the four primary considerations relevant to GAI that the GAI PWG focused on?", "c536f25b-1a69-4d08-867d-84f025515d2d": "What are the main considerations addressed in the document regarding Provenance, Pre-deployment Testing, and Incident Disclosure?", "ce384c85-10e9-4f62-8168-5eb908e1df1e": "How will future revisions of the profile incorporate additional AI RMF subcategories and risks?", "909cad34-8791-499a-a8ad-a377a07386d7": "What is the purpose of the glossary of terms being developed for GAI risk management?", "eb5ba597-f014-483c-894c-5d2a4b622299": "How was the document informed in relation to public input?", "f42ee69a-19d0-47e1-9500-f8de76d9607f": "How can the likelihood of risks be assessed in a given context?", "b5f2314e-384b-4741-b504-1706514bdbb5": "In what ways can GAI exacerbate existing AI risks?", "4c5d9c86-c124-4918-b863-0cb5a84b94c3": "What are the different stages of the AI lifecycle where risks can arise?", "42755778-5835-470c-af7f-f51714e1e985": "How do risks associated with GAI vary in terms of scope?", "d5df1217-f07f-4e89-8819-dc703cde3421": "What are some potential sources of risk associated with the design and operation of GAI models?", "ea233e4e-9056-45c8-a3bd-0a943d521fe6": "How can human behavior contribute to the risks associated with GAI systems?", "a9e62eb7-6203-45ed-8f86-a2cbc240be51": "What are the potential risks associated with \"algorithmic monocultures\" in decision-making settings?", "f43cb85e-c8bb-4ec3-89d7-6a04ba3745dc": "How have studies addressed the impact of AI on the workforce compared to its effects on labor markets?", "eac2900f-8d7e-43a7-89b0-79d3b4a14378": "What are some concerns that employees and employers have regarding the impact of GAI on the labor market?", "79900a50-d876-4f30-906f-f5038d13fa40": "How are industry surveys reflecting the thoughts of employees and employers about the disruption caused by GAI?", "df61f92a-d1db-4ed1-84e0-537eca8f9021": "What are some examples of immediate risks associated with the misuse of AI systems?", "775126fc-70fb-4b34-a2a8-b4ea8bff3d31": "How can the long-term effects of disinformation from AI impact societal trust in public institutions?", "cfc775c0-3e34-4c9b-a9ed-f0007d6d791b": "What factors influence the level of trust in public institutions regarding GAI models and systems?", "193fe9a9-38bc-4fe8-9b6c-e7e96a5da0e9": "How do the characteristics of a GAI model affect the associated risks in its application or use case?", "56971afe-1ebc-405e-a79d-19ef239d63f7": "How can organizations tailor their measurement of GAI risks based on specific characteristics?", "99f43c2f-128b-4a39-b2a5-783943abd1b1": "What factors should organizations consider when allocating risk management resources for GAI risks?", "f812fb0a-3483-4cc0-acf9-e65f21bcd9b4": "What are some challenges associated with estimating risks related to GAI due to the diversity of stakeholders and uses?", "067d80a4-97c9-4cae-8833-921a4a09620b": "Why are some GAI risks considered unknown, and how does this uncertainty impact their evaluation?", "1c5cfb3c-d909-4a34-b409-de538296c990": "What types of risks does the document focus on regarding AI measurement and safety?", "3d6f0601-221a-44bc-9629-52e98ca7887f": "Are speculative risks related to future GAI systems included in the current profile?", "9fec5fe0-43f6-42b8-860e-d59c7b3efda4": "What are the different categories of risks associated with the development and use of GAI as mentioned in the context?", "0671508a-449a-49ea-86f6-db4a76a00577": "How can organizations utilize the defined risks to manage GAI effectively?", "f4960509-5115-47db-86f8-06422c42a2e9": "How are risks mapped to Trustworthy AI Characteristics in the context of risk management efforts?", "5447c18d-f9ca-4e98-b0df-e0b81bf4c943": "In what ways can organizations further categorize risks based on their unique approaches to risk definition and management?", "7c67e806-d758-4755-aedd-64eb96e4852f": "What are some examples of technical or model risks associated with advanced AI as mentioned in the report?", "0ef30b23-cf72-4519-acb2-1bcc7be0cacf": "How can advanced AI be misused by humans according to the scientific report?", "0ef657b1-60d4-4953-8633-f8e7c0d9c246": "What are the different categories of risks mentioned in the context related to Information Security?", "c42b2e50-7026-4059-9276-5aa3ca5e2e99": "How are some risks described in the context as being cross-cutting between the categories?", "9f57c805-36b6-4e4a-a115-7ba39be84206": "What does CBRN stand for and what types of threats does it encompass?", "5485786c-12e6-4ba5-9f45-8246329bd81e": "How is confabulation defined in the context of information dissemination?", "ca42395a-cdb4-48f8-a71c-42d81faf7520": "What are the potential consequences of eased access to violent or hateful content?", "b9dc1099-9b9e-45dd-8684-ed78b915bf7e": "How does data privacy relate to the unauthorized use or disclosure of personal information?", "ec44cdbc-1fbf-41a3-b4e2-053ece570d8f": "What types of sensitive data are mentioned in the context?", "a0813af1-6be5-4b2b-a71a-0921f81ba39c": "How can the training or operating of GAI models impact ecosystems?", "e3e3d04e-53f5-44df-96f6-8c8f7e7ecee5": "What are the potential consequences of using non-representative training data in AI systems?", "134bec27-5cb7-496a-bfd4-476414be3bbb": "How can human-AI configuration lead to inappropriate anthropomorphizing of AI systems?", "2dc7efbd-543a-4782-9309-8dde3a414696": "What are some potential consequences of algorithmic aversion and automation bias in the context of GAI systems?", "267efce7-11e9-48b0-88f5-9e0f8c224938": "How might lowered barriers to content generation impact the distinction between fact and opinion?", "adaf2d48-71ec-4deb-8fb0-e60d99e1edc2": "What are some risks associated with the anthropomorphization of GAI systems as mentioned in the context?", "fe6656f1-3c3f-4ba6-849c-4365a3be5501": "How can the categorization of sensitive data or sensitive PII vary based on context?", "e8098614-6f03-42ec-9e51-26d379e70f47": "What are some examples of sensitive information mentioned in the context?", "8f51d0a8-74ca-47eb-a659-cbeed871cf59": "How does the notion of harm relate to disparities between groups according to the context?", "e40d770e-be62-4ee1-8a2f-02a15a85b22a": "What factors contribute to divergent views on when a disparity in AI behaviors constitutes a harm?", "9ce38b02-495e-4784-a0ad-81e41430dd84": "How does the document define a harm resulting from biased behavior in AI systems?", "9a1d8b46-1a61-47b2-96a5-916a0dc9e5a5": "What are the potential consequences of increased attack surfaces for targeted cyberattacks on a system's training data, code, or model weights?", "fda67880-da08-433d-ade0-b30b7720bed0": "How might the easing of production or replication of copyrighted content impact intellectual property rights?", "508aedb9-6e50-464c-8fd3-7ed2040ebef1": "What types of harmful content are mentioned in the context regarding obscene, degrading, and/or abusive imagery?", "c4b6a2d7-6595-47a2-8006-4ca67ac20b45": "What issues are associated with the integration of upstream third-party components as described in the context?", "416c56f2-a372-44dc-bb0f-b454d294db1d": "What are the potential risks associated with increased automation from GAI in relation to supplier vetting?", "9a9e22fe-ebd2-4faa-8df1-c9fbb122b716": "How might GAI impact the accessibility of CBRN weapons and related knowledge for malicious actors in the future?", "988c7340-d8a9-4344-bdad-7b03eec5dec1": "What role do LLMs play in the analysis or synthesis of biological and chemical threat knowledge for individuals without formal scientific training?", "5187c8e7-a801-40bc-b0f0-a4f5ebc9fb18": "What recent research findings are mentioned regarding LLM outputs related to biological threat creation and attack?", "10a4e5db-dd0a-49d0-9c0c-ce451dbe7b05": "What does the context suggest about the effectiveness of state-of-the-art LLMs in assisting with planning for attacks?", "3bc7082f-2a55-497d-af9f-15d9443e3f50": "According to the context, what are the necessary components for the physical synthesis, development, production, and use of chemical or biological agents?", "0bc92e68-ff92-4fba-8f04-31339e087d22": "What are the key barriers for malicious actors regarding the misuse of chemical or biological agents in the context of GAI?", "d999cee8-112f-4a6f-ac98-0a830d457ee3": "How might chemical and biological design tools (BDTs) enhance design capabilities in chemistry?", "76027f7f-9147-4c75-b93a-c4aeb9951c1d": "What are the potential beneficial uses of text-based LLMs in biology?", "cd5f4ad9-5817-433b-b42f-ad6732375a4e": "How can ongoing assessments of AI tools help in monitoring the risks associated with the ideation and design of harmful agents?", "f82981f1-0f22-4a5c-a45e-d4895ffd6163": "What are the key characteristics of trustworthy AI in the context of weapons planning and GAI systems?", "39d98943-888b-400b-b7e4-4e646bb901a2": "How do GAI systems ensure safe, explainable, and interpretable access to relevant data and tools in weapons planning?", "8ef5356a-a69f-42e2-9aa1-d45f8c0ded00": "What does the term \"confabulation\" refer to in the context of GAI systems?", "0e956f7b-60a0-4ad6-913d-f1e7a23ec836": "How are confabulations in GAI systems related to the concepts of \"hallucinations\" or \"fabrications\"?", "54f17719-6559-4e21-a871-abdafe965c21": "What are confabulations in the context of generative AI outputs?", "dcd11d30-e8dc-40f1-9593-52e8060218c5": "How do generative models like LLMs generate outputs based on their training data?", "3e002c9f-349f-4898-9c42-2adde4cfa1b5": "What are the potential risks associated with confabulations in responses to open-ended prompts?", "6e548619-c929-4bf7-90fa-21b7f8f4a744": "How can the confident nature of a response contribute to the spread of false information?", "f5a94717-56fe-4fbe-b68b-7fecc9da960a": "What are the potential consequences of confabulated summaries of patient information in healthcare?", "791d55ce-8e81-4b98-9110-9223dce4c999": "Why is it important to monitor the risks of confabulated content when integrating GAI into consequential decision-making applications?", "fbf92bec-d73c-4ae6-818a-dfac3a0b3247": "What are some ways in which LLMs can mislead humans into trusting their outputs?", "f1a4438a-4eb5-4bfa-a047-4233a86d332e": "How might an LLM falsely assert its identity or traits to deceive users?", "6af930b1-eea5-444f-afa8-db00b0bb2a71": "What are the potential risks associated with adversarial prompting in GAI systems?", "a76d003c-baf2-427a-a203-b39d08e47df9": "How do the characteristics of trustworthy AI address the issue of harmful bias in generated content?", "0f05cb9b-a5dd-4d8d-b854-f3e4624d622a": "What are some potential risks associated with the use of LLMs in generating content?", "651d2536-4293-44cf-98de-165e8902ca3d": "In what contexts can creative generation of non-factual content be considered a desired behavior?", "7beec528-c074-4861-9aea-1aeaf05896a3": "What are legal confabulations, and how do they relate to current state-of-the-art LLMs?", "af5aa401-e8a3-46b5-8a8e-95f1276413f8": "In what ways have legal confabulations been demonstrated to be pervasive in LLMs?", "ef88c956-99f1-4b5a-8006-65341edaad28": "What are some potential dangers associated with text-to-image models in terms of content creation?", "0904834a-1753-4699-a3d0-34a82904ee0e": "How do current systems attempt to mitigate the risks of generating harmful or illegal content with GAI media?", "48736b18-d6a5-4980-917e-286a5bf000ce": "What is the term used to describe the act of manipulating prompts to circumvent output controls in GAI systems?", "74cd7873-a28b-43c6-9d55-ec9833ce8626": "What types of content may still lead to harmful recommendations despite the approach mentioned in the context?", "19753cb2-44c5-4016-9b15-1a9014254171": "What negative reactions do users exhibit when chatbots provide unhelpful responses during distressing situations?", "ecc278af-594f-4ebb-91fd-845e7a20f630": "How might the generation of offensive or hateful language by AI contribute to harmful outcomes in conversations?", "786f25e0-c6d9-4002-bcbd-6867c7b7ad0c": "What are some potential downstream harms associated with the spread of denigrating or stereotypical content?", "29680099-a2ae-444a-8687-f259fd7b2400": "How do GAI systems pose risks to data privacy during their training process?", "fb35a9a4-05ec-487a-9335-a0d2317b32cc": "What are the risks associated with using personal data for GAI training in relation to privacy principles?", "89169f57-3a00-4437-9999-630d56e7e9b5": "Why is the lack of disclosure about data sources a concern for users regarding personally identifiable information (PII)?", "c50194a6-c65c-4118-b0b9-e453736019c4": "What is the term used to describe the issue where models reveal sensitive information from their training data during adversarial attacks?", "49004544-4eb1-4444-becc-d96f273105eb": "How can data memorization in models pose privacy risks, even for data present in a small number of training samples?", "fc81cee8-5fbd-4f7e-bf23-2564ce1e6b9e": "What are the potential negative impacts of GAI models inferring PII or sensitive data from disparate sources?", "ffbbe8ee-bb35-4523-9866-c1b98a47275d": "How can GAI models reveal sensitive information that was not included in their training data?", "a0b398fe-daf3-423e-a987-d59949335a2f": "What are some potential harms that can arise from the exposure of sensitive information or PII?", "d6419312-c74f-4396-bfaa-62a3deb7bcfa": "How can predictive inferences made by GAI models based on PII lead to adverse decisions for individuals or groups?", "dca4051b-4125-4355-bb71-b5a1ab6f70f0": "What is the process of homogenization as mentioned in the context?", "aa84545c-5245-4ce5-b1cb-00d6c95bd328": "In what contexts or fields is homogenization typically applied?", "a08a182d-fbe3-4ccf-8437-fcd13bc6af01": "What are the key characteristics of trustworthy AI mentioned in the context?", "0e405d79-1a70-4fd2-8804-2c9b1c2a2afa": "How do the energy and carbon emissions of GAI systems vary based on their usage?", "b54c3d83-6e3d-4455-b32c-bf8338212fa5": "What is the estimated carbon emission of training a single transformer LLM compared to round-trip flights between San Francisco and New York?", "96e73113-9bc9-48c9-b25c-9b1546a47f51": "How do the energy consumption and carbon emissions of generative tasks compare to those of discriminative or non-generative tasks in LLM inference?", "8e4ea705-62d4-48ef-b1c7-9194a0cc30d7": "What are some methods mentioned for creating smaller versions of trained models to reduce environmental impacts?", "90787a3c-b6c5-460f-bc04-18e586bb23ae": "Why is there currently no agreed upon method to estimate environmental impacts from GAI?", "d4e7f5e0-788a-4384-ba22-4865c3fd2d99": "How can AI systems contribute to the perpetuation and amplification of harmful biases in society?", "e05c44ea-62db-426c-8344-3233be27fe39": "What are some examples of professions that may be affected by bias in AI-generated images?", "b7586360-4755-421c-a909-bb6efbcfa34d": "What demographic groups are underrepresented in text-to-image models according to the context?", "7c38d78b-56c7-42d9-a040-4daa777751ad": "How do image generator models struggle when producing content that is non-stereotyped?", "3c598788-7dc2-481e-bef9-d6fdb30bfb7d": "What are some examples of protected classes that can be affected by bias in GAI systems?", "0b136c25-6ba2-441a-a322-1314af3d7f47": "How can disparities in model performance for different subgroups contribute to discriminatory decision-making?", "24e84b42-c0fb-4a1c-a633-c0e4c22c3f46": "What challenges do lower-resource languages face in the context of GAI system adoption?", "50049a0e-7299-418b-921f-19825ed016a5": "How might the use of GAI systems impact the preservation of endangered languages?", "9ac658a5-b688-4ca5-aa9e-3a900bbe2871": "How does bias contribute to the issue of undesired homogenization in GAI systems?", "f564a52e-9e55-4d03-808b-afeb04775554": "What are some examples of outputs that may result from skewed distributions in GAI systems?", "9e5c7ac0-2f32-40c5-93fe-4527e6c220f2": "What are the potential consequences of overly homogenized outputs in foundation models?", "1274a002-d426-4750-b070-762fce425ab5": "How can foundation models act as \"bottlenecks\" in the context of content diversity and decision-making?", "78c7bf5c-5791-46ad-a266-4351eaa621b9": "How does the over-reliance on synthetic data during training affect the distribution of a new model's outputs?", "21b412fa-50ba-490f-ac0a-8eca1e34f458": "What are the potential consequences of model collapse in terms of output homogenization?", "58f5fc5d-2ef4-4a9a-820e-7bd9cabe868a": "What are some potential risks associated with human-AI configuration in GAI systems?", "9c5d8cb8-21e7-474a-8dfe-f70977210eff": "How might a lack of detailed knowledge about AI systems affect human interactions with GAI?", "c5efb9cf-bdec-4b70-973a-b670b08e4c92": "What is automation bias in the context of GAI technology?", "b9606e96-b25c-4303-aa23-166315d2f617": "How can automation bias exacerbate the risks associated with GAI systems?", "5391e513-3b67-4450-90a9-5368b59ec6ec": "What are some potential negative psychological impacts of emotional entanglement between humans and GAI systems?", "388c4e33-02b3-40fb-ae78-d2d75c227aa9": "What are the characteristics that define trustworthy AI?", "b227bfd9-59dc-4c37-bb94-b4e7f163689b": "What characteristics define high-integrity information according to the provided context?", "70db3ddf-f80b-4b78-b11b-7ac02c806abd": "Why is it important for high-integrity information to be linked to original sources?", "fe6fa3db-15e2-44d3-9477-86e0dd22385b": "What is the source of the definition of information integrity mentioned in the context?", "c6e26aee-ec67-48bb-9631-26dbfc59425e": "In what year was the White House Roadmap for Researchers on Priorities Related to Information Integrity Research and Development published?", "4a9b1cca-a7f6-4d09-8cbe-b8a6d45a89cf": "How do GAI systems contribute to the unintentional production of misinformation?", "6296ff40-aea1-4bcd-8607-c3ae071de026": "In what ways can GAI systems facilitate the deliberate dissemination of disinformation?", "29cb0067-e5f0-408e-880d-4d40d1f54a7f": "How could GAI systems enhance the ability of malicious actors to create targeted disinformation?", "0e7d42eb-8aa1-4359-bce7-7463d13451f2": "What types of content can current multimodal models generate that contribute to disinformation threats?", "04b5edda-3c70-4cc8-88fa-e4e3d186e017": "How can generative AI contribute to the spread of disinformation and misinformation?", "d737d0a8-e2ed-47f4-a139-7f45d4e5c174": "What impact did a synthetic image of a Pentagon blast have on the stock market?", "543a927d-3cff-450b-a238-678eb3dbccb9": "How can generative AI models enhance the reach and engagement of campaigns on social media platforms?", "7fb9efdd-6989-436c-852e-0ad72ccd3d3b": "What are the trustworthy AI characteristics mentioned in the context?", "0463d3f6-260d-4acd-94a0-3ce9a81c3d5e": "What are the two primary information security risks associated with GAI-based systems?", "4e8ccec0-e4f4-46b4-b08c-979c47a9464e": "How might GAI-based systems lower the barriers for offensive cybersecurity capabilities?", "3fc58164-b216-4e36-8194-3394c0bfe39e": "What types of attacks are GAI systems vulnerable to, as mentioned in the context?", "4d0cd971-1bc1-4dfd-8015-d91747fc942c": "How might GAI systems enhance cybersecurity attacks according to the provided information?", "d4c5c535-3cad-4cc6-965d-7071d6e2e299": "How might GAI-powered security co-pilots assist attackers in evading threat detection?", "f80a1da1-4da6-4bce-9d22-1e35ecc2e091": "What are the key aspects of information security that need to be maintained for GAI models and systems?", "e7bd39db-4985-474a-9096-c280371467fe": "What is the purpose of identifying and securing potential attack points in AI systems?", "ad6c4283-bf50-40d7-b7e4-fc8c7ab0efc4": "Where can additional information regarding AI security be found?", "0d5a5c48-367a-4b3c-84b7-8e31b6600b2d": "What is prompt injection in the context of GAI systems?", "7c062f9e-e27c-4d0f-82fb-7f14c13aca6a": "How might conventional cybersecurity practices need to adapt in response to prompt injection attacks?", "45cb7046-a066-40d4-878d-3c460fb494e1": "What are indirect prompt injection attacks and how do they exploit LLM-integrated applications?", "955acb56-f01e-4e42-b3ed-7046cad87e95": "What potential consequences can arise from indirect prompt injection attacks, as demonstrated by security researchers?", "39e82040-a9bc-4d01-9986-d22a4747efb1": "What is data poisoning in the context of GAI, and how does it affect the model's outputs?", "10634e64-50b6-43c1-8821-8a97e69ffbdb": "What are the key characteristics of trustworthy AI as mentioned in the context?", "2e1aca03-7471-4bc0-a43c-49af217684db": "What are the potential intellectual property risks associated with GAI systems in relation to copyrighted works?", "7a81d97a-dbf9-4a63-9a55-9c17ee98b62b": "How does the fair use doctrine apply to the use of copyrighted material in GAI systems?", "5bf5b622-2752-4782-ae3b-8c545368c0da": "What are the current legal debates surrounding the copying of work protected by copyright?", "c58693b2-8acc-4108-bc96-22912970f034": "How does the use or emulation of personal identity, likeness, or voice without permission relate to the discussions on copyright?", "f13721d6-71de-4d3f-81e1-7e851a7db36d": "What are some potential harms associated with GAI-generated obscene or abusive content?", "1d4ee2bd-4cf7-409a-8625-682478972038": "How can the spread of explicit AI-generated content impact individuals and society?", "8a7c01fd-8617-41d2-a11f-741bc526c468": "How does the prevalence of CSAM images affect the search for real-world victims?", "857d1bb5-10b4-419b-8502-435b3ff07466": "What are some negative consequences associated with the creation and spread of NCII, particularly for women and sexual minorities?", "39b1ede6-b0d3-434d-964c-9d18688d0858": "What types of sensitive content may unintentionally be included in the training data for GAI models?", "1797b3ab-f887-44df-8ad0-045c30ce3103": "What did a recent report reveal about the presence of known images in commonly used GAI training datasets?", "776807a9-d8e5-41f3-a551-63a6e23f35fa": "What are the implications of GAI models being able to synthesize or produce synthetic NCII and CSAM, even when trained on \"clean\" data?", "571c0bde-ce77-4acd-a964-189a4c2e6bb6": "How have websites and mobile apps that generate synthetic NCII evolved from niche forums to mainstream businesses?", "e8c22ada-1444-4c40-bdd0-0e94b19a92b9": "What are some examples of third-party components involved in GAI value chains?", "6a36bd89-6b87-4a0b-9eb5-90542d5b3bc2": "How does the risk of improperly obtained components in GAI differ from that in traditional AI systems?", "ee36886c-d8e7-4cbd-8c28-c108d379d266": "What challenges are associated with vetting large training data for foundation models?", "45d436cf-103c-46e6-a420-a5a7057cb7b0": "How does the integration of GAI systems with third-party components complicate the attribution of behavioral issues?", "2df60392-38d1-40e3-9c68-1b9db5727c32": "How can errors in third-party GAI components affect the accuracy and robustness of models?", "8cf94226-6539-4c39-b85b-27e924202bfa": "Why are label errors in test datasets significant for the stability of benchmarks in GAI model selection?", "c5600959-9177-4725-837e-9fb5dac162f9": "What are the suggested actions to manage risks unique to or exacerbated by GAI?", "ec485ff9-12d1-43ac-a816-2ebbe0996a0f": "How do the AI risk management activities in AI RMF 10 and Playbook relate to managing GAI risks?", "78f36117-ecba-4879-aeea-228d471a85f8": "What factors influence the implementation of suggested actions for managing GAI risks according to the AI RMF and its Playbook?", "4277366d-b0dd-4a99-9323-78f6947ed356": "How are the suggested actions for managing GAI risks organized in relation to the AI RMF subcategories?", "192138d5-fbd6-4c76-94d0-473f137248cd": "Which subcategories of the AI RMF are included in this document?", "16a49d99-02ed-401f-9779-8b1bcb868e81": "What is the focus of this document regarding the AI RMF subcategories?", "d61d78b2-ae63-4e2e-b690-96eb51d87ce2": "What factors should be considered when determining the applicability of suggested actions to AI actors?", "da0c8826-3fb6-4bcc-b01c-71e310c494d9": "How might the suggested actions for GAI developers differ from those for GAI deployers?", "3a5b3ceb-c1dc-42b8-a0c0-ba81990afff2": "What does each Action ID correspond to in the context of AI RMF functions and subcategories?", "7b91873b-7fcf-4cc4-a714-5c88ca417289": "What is the purpose of the Suggested Action in the context of managing GAI risks?", "7a4318f6-1026-42a1-928b-e8ed02e0a291": "What are the GAI risks associated with the suggested actions in the AI RMF subcategory?", "92f520d2-60fb-46c7-8d2c-5a6dc11bb85d": "How do the AI Actor Tasks differ between AI development and AI deployment for each subcategory?", "8076e2cb-58d3-4fe5-95ba-2bd6dd16ea0c": "What are the key legal and regulatory requirements that must be understood and managed in relation to AI development and use?", "63afae28-38a6-4e3e-927b-d0959ed245b7": "How should GAI development align with laws related to data privacy and intellectual property?", "f06769a4-83e4-4d94-b510-fe052a843500": "What are AI Actors as defined by the OECD?", "bbb83601-cccd-401a-8a98-5b9da0d9e690": "What roles do AI Actors play in the AI system lifecycle?", "b14855cb-8487-4c0c-948d-26d68bbdc651": "What are the characteristics of trustworthy AI that should be integrated into organizational policies?", "df9ade84-251b-4a01-8854-4da806d8328a": "How can organizations balance the proprietary nature of training approaches with the need for transparency in GAI applications?", "c6403904-2d92-406b-b0c0-55bc3ae9fc1a": "What policies should be established to evaluate the risk-relevant capabilities of GAI before deployment?", "dd98b58c-15cc-48b6-aa2f-b23a5774708e": "How can organizations ensure the robustness of safety measures for GAI on an ongoing basis?", "a72e2713-dc44-423c-b816-7dfe500684c5": "What factors should be considered when updating or defining risk tiers for GAI according to the provided context?", "661ee90a-fe27-487c-9f2f-f4e62e31e2f0": "How does the organization determine the needed level of risk management activities based on its risk tolerance?", "c7b1c9c6-ceeb-4fb3-bc1c-9a29f1a3423b": "What are the potential psychological impacts on humans due to the use of data systems, such as emotional entanglement or algorithmic aversion?", "853a5aea-9538-479e-8c9c-2c5630a76f64": "How might data systems introduce significant new security vulnerabilities that could harm fundamental rights or public safety?", "f4aaf0cf-8c3b-408d-9ffd-2b86a26cd350": "What are the key factors that influence the performance and adaptability of GAI systems over time?", "e8eea805-18cb-4904-9054-11ac8e017b49": "How do minimum thresholds for performance or assurance criteria impact the deployment approval process for GAI systems?", "a2881edc-9675-4177-a001-809634f7b1c5": "What is the purpose of establishing a test plan and response policy before developing highly capable models?", "e2027359-8c48-4e43-bc9f-af1a1be9db72": "How should the evaluation of GAI capabilities and risks be reflected in the approval thresholds?", "459c845c-59c6-42a5-a99e-aa9cec59fdef": "What types of unacceptable use should be identified by obtaining input from stakeholder communities according to the AI RMF Map function?", "7493dc38-e666-4e0c-92e0-db899fb62c51": "What is the purpose of maintaining an updated hierarchy of identified and expected GAI risks in relation to GAI model advancement and use?", "adb8a6df-063e-4ca7-9478-c7f8ae1871e9": "What are the key issues that GAI systems aim to address regarding model collapse and algorithmic monoculture?", "e8d9dc1e-0ae6-4d79-a387-6525461b40c1": "How should organizations reevaluate their risk tolerances in relation to the negative impacts of GAI systems?", "f70602a9-9ab9-45a3-9863-17e678e85158": "What are the potential impacts of GAI on democratic processes as mentioned in the context?", "a12d193e-206a-4a07-9b8b-853f16ba74c3": "What steps can be taken to halt the development or deployment of a GAI system that poses unacceptable negative risks?", "a3b3512b-0554-44dc-89af-7e36d6bf34e1": "What are the key components of the risk management process as outlined in the governance and oversight tasks for AI actors?", "4b4be905-98ac-47bb-9ecd-8d8df5aa57bb": "How can organizations ensure that GAI systems do not generate content that violates laws, such as CSAM or NCII?", "5a80f59f-3465-4e74-9037-996a7fe7fcd3": "What are the key components that should be included in acceptable use policies for GAI to address illegal applications?", "67265e7c-b3eb-47f2-a6a8-e56b912c69f8": "How do the tasks of AI development, deployment, and governance relate to the management of dangerous or violent content?", "e712f919-8449-417e-b816-faaa4d841f90": "What is the purpose of ongoing monitoring and periodic review in the risk management process as mentioned in the context?", "61f8e02f-a0a3-4045-b023-264779965da5": "What specific action is suggested to define organizational responsibilities related to GAI systems?", "346048fd-90ce-4098-b01a-c3964228486c": "What organizational policies and procedures should be established for after action reviews of GAI system incident responses?", "35425921-ac3c-4fbf-8b24-11f6c2199f26": "What is the purpose of maintaining a document retention policy in relation to test, evaluation, validation, and verification (TEVV) for GAI?", "166d0d97-11b7-47a9-a0d2-48aa34457682": "What mechanisms are suggested for inventorying AI systems in relation to GAI risks?", "74893817-90b6-4dc9-b68f-0ba23eda51f9": "How should AI system inventory requirements be adjusted according to organizational risk priorities?", "0ac87bf7-4b0f-4ff8-a0ee-b498a4bbe649": "What are the inventory exemptions defined in organizational policies for GAI systems embedded into application software?", "92a9d689-7441-4c0b-846c-77f6332b6271": "What specific items should be considered in GAI system inventory entries beyond general model, governance, and risk information?", "5472b3c1-bff9-48f9-b475-b0f114dd3d96": "What are the roles and responsibilities associated with human oversight in the context of AI incident monitoring?", "fab111ea-1bf0-42c3-b757-5236a20b7099": "How do special rights and considerations for intellectual property impact the sharing of sensitive data in AI systems?", "f45bfce7-4ead-4a30-9820-33e764003b06": "What role does integrity play in the governance and oversight of AI actor tasks?", "268b8356-c520-4238-8e61-c4048e1d2a36": "How does intellectual property relate to the value chain and component integration in AI systems?", "78c9cc97-72a7-404d-a46b-2961b44522e9": "What processes are established for the safe decommissioning of AI systems?", "76700c67-6bc5-494d-bd5a-6de90665aa0c": "What factors should be considered when decommissioning GAI systems?", "781748b3-d0ac-41a6-bca2-8e76486ba04b": "What are the retention requirements for data security after decommissioning systems?", "f532ddf8-63af-421e-95d6-d45613657deb": "How do users' emotional entanglement with GAI functions impact the human-AI configuration?", "9699e807-db53-4345-ac13-795d69425ba5": "What are the documented roles and responsibilities related to mapping, measuring, and managing AI risks within the organization?", "b8d47ed0-8c79-4714-b93d-6f1433333020": "How should GAI incidents and performance be communicated to AI Actors and downstream stakeholders?", "19c4cac3-ef75-4871-98ca-20f875c3268d": "What procedures should be established to engage teams for GAI system incident response according to GV-21-002?", "4d8f4504-42da-4eb9-8940-40aec734657e": "What processes are recommended to verify the skills and training of AI Actors involved in GAI incident response tasks as per GV-21-003?", "176cf50a-8e5f-4b7e-9a6a-b175fd33861a": "What should organizations do when systems may raise national security risks according to GV-21-004?", "2e87b785-c18f-4faa-9b89-ee6a34c6fa08": "What protections should be created for whistleblowers as stated in GV-21-005?", "8b1aa0d6-2c9a-449c-9de6-c462cd115741": "What constitutes a specific and empirically well-substantiated negative risk to public safety in the context of CBRN information or capabilities?", "61ce4905-c224-49a6-a807-e5131ebf8600": "How do governance and oversight tasks relate to the management of dangerous, violent, or hateful content?", "cc25ad8e-d342-488a-a0f0-79037d32187a": "What policies are suggested to enhance oversight of GAI systems according to the context?", "f1a9d366-3a4f-4fd8-bd42-15350777d5a5": "How should the type and robustness of evaluations for GAI models be determined?", "52d59750-c207-44d5-9961-7377c6a1c0af": "What are the key lifecycle stages of large or complex GAI systems that should be considered for organizational role adjustments?", "972cdeb1-b44a-49af-9ebe-d24cdb0e0b51": "How can harmful bias and homogenization impact the development and engineering of GAI systems?", "397af11c-5018-403e-9b69-f29a27920a0a": "What criteria should be included in acceptable use policies for GAI applications regarding the types of queries they should refuse to respond to?", "ba813978-c4c3-4ca0-92b8-520e3d51b786": "What should user feedback mechanisms for GAI systems encompass according to the established policies?", "2d354b97-3502-40b4-9914-e58aae9287d0": "What is the purpose of engaging in threat modeling for GAI systems according to the context?", "dfc98789-e764-437c-a167-7b9c63fa3906": "How do organizational policies and practices contribute to minimizing potential negative impacts of AI systems?", "6833fc3d-b335-443d-b57c-86cefdaf0436": "What techniques are suggested for addressing risks associated with a lack of explainability and transparency in GAI systems?", "1850cec2-b1fb-4475-b3da-22177a5774b0": "What is the purpose of establishing policies and procedures for continual improvement processes in GAI risk measurement?", "83929fac-8a6d-4805-890f-9a0170764127": "What are the key components that should be included in the policies and procedures for risk measurement?", "d605b584-ff58-47e4-af9d-b9ed9723dd26": "How can structured public feedback exercises, such as AI red-teaming, enhance the risk measurement process?", "6f341356-c6d5-450c-8bbc-3f3a666d7e33": "What are the key oversight functions that need to be established for the GAI lifecycle according to the context?", "10323136-bcdb-49d6-900d-25dec3b6ef4b": "Which tasks are included in the AI Actor Tasks related to the GAI lifecycle?", "0a9c41bd-e3c7-48fa-9995-84208e9fcd9f": "What are the key responsibilities of organizational teams regarding the documentation of risks associated with AI technology?", "dfd7e333-8a0f-4f44-bae4-4e152c8aa7ec": "What types of content risks should be addressed in the terms of use and terms of service for GAI systems?", "65bdb2cb-8cbc-4037-9081-22010197d6d4": "What is the importance of including relevant AI Actors in the GAI system risk identification process?", "62ed6998-079c-407b-91ca-722ac55212b1": "How should the impacts of third-party plugins be documented in the GAI system?", "7a349c80-e68d-4235-aa1a-64d5afa5ce2e": "What organizational practices are suggested for identifying incidents related to AI testing?", "79818b22-7f8c-41b6-b371-a1e34d650ae3": "What is the purpose of establishing policies for measuring the effectiveness of content provenance methodologies?", "45ebd20d-0150-47dc-84a7-9aea10e659ee": "What information is required for GAI system incident reporting?", "120a7f63-d25c-45f7-9526-a6b40237e293": "Which stakeholders are impacted according to the incident reporting context?", "4946ca99-3ed9-466e-aecd-4369a4d6806e": "What mechanisms are in place to verify information sharing and feedback regarding the negative impacts of GAI systems?", "6563b2d1-0390-46c3-8406-fd352d7f6539": "How do organizational policies ensure the integration of feedback from affected individuals and communities?", "a74298f3-c2da-4782-8cc4-07a0cfe3f56e": "What are the potential individual and societal impacts related to AI risks that should be considered during the development of GAI systems?", "1314f8e9-c9f4-4f9b-8f06-814bcdf63081": "Why is it important to allocate time and resources for outreach, feedback, and recourse processes in GAI system development?", "a7b15cc6-6361-4ab5-9174-2206621b04e6": "What policies and procedures are suggested to address AI risks associated with third-party entities?", "1e335cc4-7ed2-4324-9496-923f160ebf4f": "How does the concept of confabulation relate to AI actor tasks such as AI design and impact assessment?", "088ed4a1-76b5-4105-9d1e-7f0e860fd3fe": "What are the different types of GAI content that need to be categorized with associated third-party rights?", "1b09308d-f168-488c-99fb-c81282d7b8ea": "How can joint educational activities and events help in promoting best practices for managing GAI risks?", "bf51d3c8-27ba-460c-9e00-c03b6458a458": "What are the key elements that should be included in contracts and service level agreements (SLAs) for GAI systems according to GV-61-004?", "0fe306f3-79eb-4cbb-b072-598091469bee": "How can the success of content provenance management efforts be measured in relation to third parties as outlined in GV-61-003?", "1fa77a2f-43a8-4bcb-ac05-003529505a13": "What are the key components of Information Integrity in relation to Information Security?", "f342840f-c175-4e0f-8743-3c6a152abcce": "How does Intellectual Property relate to the concepts of Information Integrity and Information Security?", "111d9464-8962-4c3a-a2b3-13e291c025ef": "What is the purpose of the use-case based supplier risk assessment framework mentioned in the context?", "4dc02326-c912-4dfe-b759-d7aff51f9421": "Which aspects of third-party entities' performance are evaluated and monitored according to the framework?", "8e133ec2-746a-45d1-bcac-0f74ff3effc8": "What clauses should be included in contracts to evaluate third-party GAI processes and standards?", "5b707c1c-51ed-42da-87a5-e319ae12b426": "How can an organization maintain records of changes to content made by third parties?", "da7e435d-8712-4eb5-8751-132b02f647ff": "What aspects should be included in the updated due diligence processes for GAI acquisition and procurement vendor assessments?", "d5eff59a-66a4-431b-8936-634c8b214f8d": "How can ongoing monitoring be integrated into the due diligence processes for GAI technologies?", "c9b20fd7-6bbb-40dc-985f-6f595c380f90": "What are the key components involved in monitoring third-party GAI risks according to the context?", "126da3b2-39d5-46b4-b239-6cad4f5e7438": "How should organizations assess GAI vendors and tools in relation to incident or vulnerability databases?", "ae571637-e810-45dc-a495-5bf1a3799668": "What updates are suggested for GAI acceptable use policies regarding proprietary and open-source technologies?", "72cac010-add9-4acc-b7f9-ef2865bdf9d2": "Which tasks are associated with AI actors in the context of operation and monitoring?", "fc9717bb-6f84-43e9-a26b-3d7ffc2ad76e": "What are the suggested actions to manage GAI risks associated with third-party data and AI systems?", "3a310e77-7a0f-4a63-a915-d22cf6023d8e": "How should incidents involving third-party GAI data and systems be documented according to the contingency processes?", "5fcaeeaf-59ec-4873-9673-18a2023dd76a": "How does open-source software impact the value chain in relation to intellectual property?", "516884bc-d7bf-4f0e-bad1-82d9071e9d4a": "What role does component integration play in the management of intellectual property within data-driven projects?", "8385d3df-0762-4665-9ff4-a80fe58ce6c0": "What are the key components that should be included in incident response plans for third-party GAI technologies?", "6c1201f8-1df8-493a-8a15-b97024c5e15d": "How often should third-party GAI incident response plans be rehearsed to ensure effectiveness?", "30b3568d-a78a-4b14-a4c0-2d0f1fadf81d": "What policies and procedures should be established for the continuous monitoring of third-party GAI systems in deployment?", "b4ab09c0-8158-46a7-aed0-c43caf83c9ac": "How should organizations address GAI data redundancy, including model weights and other system artifacts?", "2ca3ec38-65c2-48ea-bedc-f798b4c4aa9e": "What policies and procedures should be established to manage risks related to rollover and fallback technologies for GAI systems?", "4b9bfd7a-5510-4fb5-bb7f-d908d2de2203": "Why is it important to review vendor contracts in relation to GAI technologies and services?", "170d1add-af9f-4456-ad2a-7cf3ba2f4c9d": "What are the potential risks associated with unauthorized data collection by vendors or third-parties?", "df251bcb-bca5-4ae0-9760-c26e80acd805": "How can Service Level Agreements (SLAs) in vendor contracts help mitigate liability for incidents involving third-party data?", "cc183ca5-3b1c-4320-9d78-c8fb4a5eb588": "What are the intended purposes and potentially beneficial uses of the AI system as outlined in the context?", "7c8a80d2-f69c-409a-8be2-636a2043bd91": "What considerations should be taken into account regarding the specific set or types of users for the AI system?", "8e5936cc-9447-4077-8639-b087475b4680": "What factors should be considered when identifying the intended purposes of an AI system according to the provided context?", "3089311c-8043-43f5-84b4-a39ebc2d632c": "What are the potential positive and negative impacts of AI system uses on individuals and communities?", "4ee2f619-5988-4755-9654-49523b6a5751": "What are the differences between narrow and broad application scopes in the context of external use?", "f8c8ded7-69eb-4f82-9a7c-df2578d5d5f2": "How do data privacy and intellectual property concerns relate to the use of various data sources such as grounding and retrieval-augmented generation?", "fb762e0c-1948-4cab-b1ee-ab0ca5919007": "What factors should be assessed to determine the expected and acceptable GAI system context of use?", "fafdb574-8ba4-4c3d-b5dc-9653e4368c61": "How can collaboration with socio-cultural and domain experts enhance the documentation of GAI system impacts?", "e6d94f3e-a129-476f-ba3a-dfe43f45df24": "What types of cognitive biases should be documented in risk measurement plans for AI Actors involved in GAI systems?", "3b8271aa-e7bf-4a0f-8f06-b9d1824e9390": "Why is it important to consider known past GAI system incidents and failure modes in risk measurement plans?", "7955b50d-71eb-43fb-809c-9c95960af063": "What are the potential limitations of relying solely on quantitative metrics in the context of human-AI configurations?", "5eb8be4b-cb4f-4260-a628-2904036be344": "How can organizations identify and document foreseeable illegal uses of GAI systems that exceed their risk tolerances?", "234c85ec-5f2d-4ea5-94a9-71da126ec78d": "What are the key competencies and skills required for interdisciplinary AI actors as mentioned in the context?", "e4c7b812-8d49-4690-a62b-3a48e1a6705c": "How does the context address the issue of dangerous or violent content in relation to organizational risk tolerances?", "70f3dbcd-ae57-4b19-9e2c-082d0be52986": "What is the purpose of establishing interdisciplinary teams as suggested in Action ID MP-12-001?", "a1cdb6a6-b726-434d-a806-e88176c1d397": "What risks are associated with the human-AI configuration mentioned in the context?", "45f45ccb-aaa6-42ea-a6ff-58a8007b2b1e": "What is the importance of ensuring that data or benchmarks used in risk measurement are representative of diverse in-context user populations?", "2e4bd2f0-30aa-4241-844d-f0375a83ff13": "How can harmful bias and homogenization affect the outcomes of structured GAI public feedback exercises?", "dbd80163-cf8e-4ad4-bb01-9e74bb101b49": "What are the specific tasks and methods that the AI system will support according to MAP 21?", "41623169-e544-4867-99c7-3efac5850845": "What is the purpose of establishing known assumptions and practices for determining data origin and content lineage?", "6a28881c-441a-4297-81ce-1c3657e22c99": "What types of information are documented regarding the AI system's knowledge limits and the oversight of its output by humans?", "b3602378-bfa4-4665-8798-e2357a1022f4": "How does the documentation assist relevant AI Actors in making decisions and taking subsequent actions?", "dc6ccaf1-9309-4bc1-a2e6-cc0a998235eb": "What steps should be taken to identify and document the system's reliance on upstream data sources for content provenance?", "600bc4d4-32ed-4cb9-b1f7-19b691da7377": "How can the GAI system's interaction with external networks be analyzed to identify potential negative externalities?", "29d3a9e7-6e4c-4a70-aeb5-57077c92ceae": "What aspects of scientific integrity are identified and documented in MAP 23?", "6d5771f9-28c1-4c7d-8db8-828572e81981": "What is the suggested action associated with Action ID MP-23-001 regarding GAI output?", "dd1900ce-dbb9-48fe-be23-1d7325ce3c45": "What methods are mentioned for evaluating the accuracy of data in relation to known ground truth data?", "2361a7a9-b219-434b-aaf0-1ffe4a18c47b": "How does human oversight contribute to the evaluation of information integrity?", "9b633fbf-7d2d-4f57-8f5f-4698d812043b": "What are the key aspects to review and document regarding data used at different stages of the AI life cycle according to MP-23-002?", "cdfdf33e-d7c7-4abd-a87e-f6a1df9fddb8": "What techniques should be deployed to verify the accuracy and veracity of information generated by GAI systems as outlined in MP-23-003?", "a3d8b56f-0199-4246-948b-bac4c22f3225": "What testing techniques should be developed and implemented to identify GAI produced content that may resemble human-generated content?", "2fcf45d7-1dae-49f1-9617-57d7ee188e39": "Why is it important for GAI systems to undergo regular adversarial testing?", "9d47fa0f-7c9c-4977-8336-f8062b3ae63e": "What processes are defined, assessed, and documented for operator and practitioner proficiency with AI system performance and trustworthiness?", "2edf849c-ecc7-460a-853f-83464481bae0": "How can existing training programs be adapted to address the understanding of digital content lineage and origin for GAI operators and end-users?", "de3c5444-a098-40b8-8640-696c5b9ed1a9": "What is the purpose of developing certification programs related to GAI risks and content provenance?", "7d21def8-2e62-4874-b198-20163dd35670": "How do human proficiency tests differ from tests of GAI capabilities according to the provided context?", "31852ec4-afd9-482c-9945-9a15161a0dc3": "What is the importance of involving end-users, practitioners, and operators in the prototyping and testing activities of GAI systems?", "1e9c29cd-f6ca-4ee1-b2c0-9d9d85746cb7": "What types of scenarios should be covered during the testing of GAI systems to ensure information integrity?", "302f3cfe-b5fc-4f12-9745-983974fd8185": "What are the roles of AI actors involved in the design and development of systems to address violent or hateful content?", "df0d70e5-b120-4800-9f65-d570c9575e66": "How do human factors play a role in the operation and monitoring of AI systems that manage violent or hateful content?", "6fa5f94e-8610-42d5-8b2f-f132e7d64630": "What are the approaches mentioned for mapping AI technology and the legal risks associated with its components?", "1e62c657-aff1-4d0b-ae5f-45e0fdaa52f9": "What specific action is suggested to address privacy risks related to AI-generated content?", "53b0e8cd-929f-4ebf-89c3-1a45a55e9439": "What processes should be implemented to respond to potential intellectual property infringement claims?", "8495ea69-3b51-4013-ae7f-3fb7a657c856": "How should new GAI policies be connected to existing governance and compliance activities?", "4ffb4cbd-aac6-451d-85ad-ccb2cab1510f": "What are the key considerations for establishing policies related to the collection and retention of data according to the context provided?", "469dac88-7a3a-44d5-bcf6-0ea6e115e4c4": "How do the applicable laws and policies address risks associated with offensive cyber capabilities and harmful biases in training data?", "6abe785a-4ca4-4183-baa5-042c66c0ccab": "What policies and practices should be implemented to define the use, storage, and protection of third-party intellectual property and training data?", "9705ef98-10c2-40c2-81bd-656e5fb0372a": "How does harmful bias and homogenization relate to data privacy in the context of information security?", "0d40c653-90f8-4b64-974f-c212bb102821": "What is the purpose of re-evaluating models that were fine-tuned or enhanced on top of third-party models?", "5101afbc-5b55-4cec-a691-a6c092244a22": "Why is it important to establish warning systems when adapting GAI models to new domains?", "c3e847ea-aac8-4e52-87f0-a7dcb0a41e68": "What approaches can be leveraged to detect the presence of PII or sensitive data in generated output?", "50042242-b2e6-4725-b819-7109717a5835": "How does harmful bias and homogenization relate to data privacy concerns?", "93713bae-1713-40f8-b18b-ad7dfc2759a4": "What types of risks should be assessed when conducting diligence on training data use according to the context provided?", "1be9ace4-f31d-435f-aac0-c11db4032314": "Which tasks are associated with AI actors in relation to the governance and oversight of training data use?", "8bb648a6-4c1d-4e1a-8cf4-242ff036e8cd": "What factors are considered when assessing the likelihood and magnitude of impacts from AI systems according to MAP 51?", "b18a60a3-52e2-4ebb-9667-d7759b9c8c57": "What does the acronym TEVV stand for in the context of suggested actions for AI systems?", "3214c9cb-5e53-462f-9395-077d948209a8": "What are the potential content provenance harms associated with Generative AI (GAI) as mentioned in the context?", "c72cc79d-2bf9-413a-9e7a-759b76b79f0c": "How can risks related to misinformation, disinformation, and deepfakes be ranked based on their likelihood and potential impact?", "5454315d-20b2-4ce9-a099-709dec3d379d": "What factors should be considered when disclosing the use of GAI to end users?", "570859be-9aa9-4a0c-bcba-4cee364b3905": "How should GAI structured public feedback processes be prioritized according to risk assessment estimates?", "25b4f175-8173-4d6a-a811-9f0434ffdba7": "What are the potential negative impacts of GAI systems interacting with or generating content?", "99ad4ea2-eb0f-42d0-abf1-2d5b2db81ed9": "How can adversarial role-playing exercises help identify unforeseen failure modes in GAI systems?", "3c3af73c-1049-4211-accb-b8a36b69bd36": "What are the key tasks involved in AI Actor roles related to Information Security?", "3cfa8296-5450-4985-af38-1dea9ff6eb9f": "How do vulnerabilities in AI systems impact affected individuals and communities?", "f191ee1b-59ca-4195-adc8-2db33a4f8a8c": "What measures should be determined to identify new impacts from the GAI system according to MAP 52?", "9bfed8ae-4cc3-4e1a-a5b2-272fa3251bf9": "How can regular engagements with downstream AI Actors help in quantifying unanticipated impacts of GAI systems?", "a52a155b-46cb-4a8b-ba4d-c61dba11a8ae": "What are the key tasks assigned to AI Actors in the context of Human-AI Configuration and Value Chain integration?", "9ae47683-5007-485f-977b-daa193870824": "Why is it important to plan regular engagements with AI Actors responsible for inputs to GAI systems?", "b6af3a54-2fc2-4716-98c9-816d61725772": "What is the purpose of MEASURE 11 in relation to AI risks?", "c1155a7a-c0ec-4639-a3ce-4205e3de37a7": "How are the most significant AI risks prioritized for measurement according to the context?", "813d72fc-4f91-4fac-aacd-2520218b59a9": "What tools are suggested for analyzing content provenance and detecting data anomalies?", "94146da2-bef5-44f3-bfbf-83e8fa9ff181": "How can evaluation metrics be disaggregated to identify discrepancies in content provenance mechanisms across different demographic factors?", "dafd308d-b282-472e-b5ab-2c22fe99529b": "What are the key objectives of developing metrics for evaluating structured public feedback exercises informed by representative AI Actors?", "a660a279-349f-40a9-a93c-204c300886dc": "How can novel methods and technologies be evaluated for measuring GAI-related risks while ensuring the models produce valid and reliable outputs?", "19d50448-aeef-46ef-a1e3-267aed5aa42d": "What does CBRN stand for in the context of information integrity?", "ae3a92be-dba9-43ad-b2a7-2da040587029": "How does obscene, degrading, and/or abusive content relate to information or capabilities?", "3e55bd0e-0582-4b50-a984-48b208e3d41b": "What methods can be used to seek feedback from affected communities regarding the impacts of GAI systems?", "0b3d80d8-9f8f-4313-b454-b3b87700a757": "Why is it important to evaluate the quality and integrity of data used in training AI systems?", "f55b22c0-f08f-49b0-a1cc-f1f988903edd": "What are the key components that need to be defined for structured human feedback exercises in GAI risk measurement and management?", "259f71ae-f230-41a6-9189-bcc5d0fffa07": "How should risks or opportunities related to GAI be tracked and documented according to the provided context?", "654d90cb-224b-44ba-9c7c-114dcea5fc43": "What are some reasons why certain risks cannot be measured quantitatively in the context of AI development?", "80b65398-4c52-4dfa-b592-258aa393fbe9": "Who are considered internal experts in the measurement of risks related to AI systems?", "e96fb15e-8241-42ab-a8c9-6b615399eba8": "What types of groups are suggested to be defined in the context of use for GAI technology?", "d762ecdc-135a-425b-836c-2fdd78cb8e3e": "Who is consulted during the assessments and updates of the AI system according to the organizational risk tolerance?", "b0e19780-10b5-41cc-9f6e-efab168a2d6b": "What are the key components of the plans for gathering structured public feedback mentioned in the context?", "c91c890b-7538-4afb-9497-cde2142ad432": "How does the context suggest involving representative AI Actors in the evaluation process?", "e114efe3-29a9-48f6-b3f6-52661d358138": "What measures should be taken to ensure that individuals conducting structured human feedback exercises are not involved in the development of the same GAI model?", "742f5ed9-844b-4823-860e-09e401ac01e6": "What are the key tasks associated with AI deployment and impact assessment as mentioned in the context?", "de97cb0a-6231-4e1a-ba99-4e78d4e129a0": "What are the applicable requirements that evaluations involving human subjects must meet according to Measure 22?", "95c4f0a3-304a-4fb4-9f88-1e5877a01b18": "What techniques are suggested to assess and manage statistical biases related to GAI content provenance?", "3bbdd3aa-892f-4209-8dfb-1777b25a13f9": "How is content provenance data tracked in relation to privacy and security measures?", "a5e88bbe-5b35-4413-bd0b-16db4a1bf929": "What methods can be employed to anonymize data and remove personally identifiable information (PII) to protect human subjects?", "39383dd4-d31e-4a89-a50a-0b800460e04b": "What options must be provided to human subjects regarding their participation and consent in GAI applications?", "b47d9372-17f9-4433-84eb-aebc666001ee": "What techniques can be used to minimize risks associated with linking AI-generated content to individual human subjects?", "f06a56f3-2628-41c7-8ffc-6e77a6960683": "What are the criteria for measuring AI system performance or assurance according to MEASURE 23?", "eda782d7-1c4d-47b5-bf4c-e4512841b7c6": "How should baseline model performance be considered when selecting benchmarks for AI development?", "fefb8859-15fc-411c-a91b-5783e55b2b95": "What methods are suggested for evaluating claims of model capabilities in the context of information security?", "19090965-51e5-4cb1-b133-fc85553f4585": "Who should receive the results of pre-deployment testing according to the provided context?", "8d4138ef-ad43-4108-a92d-5381e79e40fe": "What is the purpose of utilizing a testing environment like NIST Dioptra in evaluating GAI trustworthy characteristics?", "fee6d9ea-3eae-47f2-a140-1fef8d3f60c6": "What are some of the characteristics that need to be empirically evaluated in the context of GAI?", "59306433-98c1-454d-8b88-5fdb02299751": "What are the suggested actions to avoid extrapolating GAI system performance from anecdotal assessments?", "1c0ad06c-f25f-4686-b947-6d7ba642f3eb": "How can human domain knowledge be utilized to enhance GAI system performance according to the documented conditions?", "8185b43d-8cc1-464a-ba77-1cd0ff89262a": "What activities are involved in the pre-deployment risk measurement and ongoing monitoring of GAI system outputs?", "eba9fd70-e3d6-4774-bf53-ebafeeb34cbd": "How should instances of anthropomorphization be tracked and documented in GAI system interfaces?", "6e642794-9aa0-409d-9ff5-fbedc2d97a38": "What should be regularly reviewed to ensure the safety of the GAI system in novel circumstances?", "c2199c75-de68-4754-aa16-8fd0e9180c4f": "Who are the AI Actor Tasks mentioned in the context?", "f0eac856-2d89-4130-8366-b3587342f4af": "What criteria are used to evaluate the safety risks of the AI system according to Measure 26?", "f264a4fd-9711-427a-be32-98557db50e32": "How does the AI system ensure it can fail safely when operating beyond its knowledge limits?", "ee9960e1-c93f-4c36-9b50-26737c3a5792": "What are the potential adverse impacts on health and wellbeing for AI actors exposed to explicit or violent information during GAI training?", "e99e6fd6-3f13-4816-a692-e16453d63414": "How can harmful bias and intellectual property infringement be assessed in the context of GAI risks?", "2dba3900-9437-44d4-ac84-16b2d3d22b34": "What are the potential risks associated with data privacy violations in system training data?", "1b49a8d8-96c5-469b-ad42-818e0ce55905": "How should organizations respond when the negative risk of fine-tuned models exceeds their risk tolerance?", "753492ab-1ef3-44ba-8809-9f253490b37d": "What measures should be taken to review generated code for risks associated with unreliable downstream decision-making in GAI systems?", "073d5b17-6c69-4edb-bc5a-ce4bce9a6066": "How can GAI system architecture be designed to effectively monitor outputs and recover from security anomalies?", "3b95f237-4b6c-4272-8cf6-1c3a2c6fa637": "What measures should be taken to verify that systems handle queries that could lead to inappropriate or malicious usage?", "bdbdc681-3f1c-49ae-abb9-b547e371bec4": "How often should GAI system vulnerabilities be evaluated to prevent circumvention of safety measures?", "546efded-d069-4b01-b4dd-174429d1ad43": "What are the AI Actor Tasks mentioned in the context?", "fff65443-8cf7-4987-a89c-a3b1246a816b": "How does Information Security relate to CBRN Information or Capabilities?", "e458be44-4a85-488a-99b0-6eeee096c808": "What are some of the vulnerabilities and threats that need to be assessed according to Measure 27?", "1f18957b-4059-44c6-b8ef-116b5b6ff0f1": "How does Measure 27 suggest documenting the evaluation of AI system security and resilience?", "b805936d-bb81-408d-90e5-2882918cfb18": "What are the key components involved in ensuring information integrity and security in the context of GAI system security?", "47995665-8fc7-4439-b145-e1cac6774ce5": "How can the security features and content provenance methods of GAI systems be benchmarked against industry standards?", "c1896d0b-8d50-4194-90a3-54becf29bbbe": "What methods are suggested for gathering user satisfaction regarding AI-generated content?", "4d06d781-c177-477f-8bb1-5922c93df601": "How can user feedback be utilized to address concerns related to content authenticity and provenance?", "ef7049e1-7176-42e6-9e2a-0ef094f207a1": "What methods can be used to measure the reliability of content authentication techniques in the context of information security?", "5d608978-0963-498a-aad7-f6aa56e3b21a": "How do content provenance techniques support information integrity and security?", "f2f21453-1c8f-4754-b453-9f0ce563264d": "What metrics are used to evaluate the effectiveness of content provenance in terms of false positives and false negatives?", "10c4fbbd-4822-45fd-8eac-52a332e0817d": "How is the implementation rate of recommendations from security checks and incidents measured in relation to the AI system's adaptability?", "f7c91fc7-ccc7-4ac6-a4aa-c85679c143ab": "What types of attacks are assessed during AI red-teaming according to the context provided?", "9720bb47-1d15-4bcb-8b83-4f14673d2727": "How does the context address the issue of harmful bias and homogenization in relation to security?", "c4ed339d-76ce-4629-9a74-0db22fb1471b": "What measures are in place to ensure that fine-tuning does not compromise safety and security controls?", "b5bb3d25-7e2f-4668-aadf-758752d0641e": "How does the verification process address the presence of dangerous, violent, or hateful content?", "b6c94b68-de74-40c1-bf84-199d682e457a": "What is the purpose of regularly assessing and verifying security measures according to MS-27-009?", "cfb4d288-e0bd-4b15-ac1b-a0a3f5c61480": "How are the risks associated with transparency and accountability documented as per MEASURE 28?", "e10aa1b0-8ea7-441b-9c57-d85da32ff6d0": "What types of statistics should be compiled regarding policy violations and intellectual property infringement for organizational GAI systems?", "9c5356b5-2753-4877-b206-61ffab6732fe": "Why is it important to document the instructions given to data annotators or AI red-teamers?", "bb64e6dd-655c-4439-b19f-c17b4d58efdc": "What is the purpose of using digital content transparency solutions in the context of content generation and modification?", "4c8fc6d4-8791-4625-a742-3a4f1c1c1fde": "How can robust version control systems contribute to the AI lifecycle according to the provided context?", "68790611-83f9-4eb4-b3f4-9ede81442691": "What are the tasks involved in the AI Actor configuration?", "8960020f-d788-4f7b-a0b2-dd819ad757cd": "What does TEVV stand for in the context of Human-AI configuration?", "15dd3cf8-01c0-46be-b0f5-af2bb7d5dbda": "What are some methods suggested for applying and documenting ML explanation results according to Measure 29?", "5b4b53a1-12be-4df6-9205-0401c19d9b65": "How does the AI model's output interpretation contribute to responsible use and governance?", "c1758bb8-b298-416c-9562-907a909e6d5a": "What are the key components that should be documented in the GAI model details according to the context provided?", "210954d6-8aa5-4a62-8a5e-490ee6e8be69": "What ethical considerations must be taken into account when developing the GAI model as outlined in the context?", "2cb6d219-85ae-4a2d-8984-318978e3d2ad": "What is the purpose of conducting AI red-teaming as suggested in Action ID MS-210-001?", "a3167777-7433-40c7-8f5b-eb6bbbdb226d": "How is the privacy risk of the AI system examined and documented according to MEASURE 210?", "cd155b05-4810-4dd8-a5c7-04a64a52e81d": "What are the potential risks associated with membership inference in relation to user data?", "70c7b93b-8ec1-4781-87be-6ad59d408eef": "How can engaging with end-users help address concerns about content provenance?", "950c2e4b-6277-4b9f-b2ae-f20958461a16": "What are the key considerations for ensuring information integrity in the design of provenance data-tracking techniques?", "8701b2f2-9b25-4978-a47e-702cfe428cc8": "How can harmful bias and homogenization be addressed in the context of AI deployment and impact assessment?", "8a464a48-7418-4c74-a6f6-a6363e99b847": "What types of benchmarks are suggested to quantify systemic bias in GAI system outputs?", "3c774838-865c-48ae-a52d-a4e7d7b65c7d": "Why is it important to document assumptions and limitations of the benchmarks used in the evaluation of fairness and bias?", "9624d5cc-e318-41c6-bbf9-00796191d629": "What measures should be taken to conduct fairness assessments in GAI systems to address systemic bias?", "8da274f7-df73-4ad6-88a6-6681c265580f": "How can the performance of GAI systems be evaluated across different demographic groups and subgroups?", "6bba4a17-3eef-4f35-b5cc-40fc708d2753": "What are some general fairness metrics that can be applied to ML pipelines relying on generated AI content?", "a304ecd7-9052-4f05-8b8d-99ccf152216f": "How can AI red-teaming help address harmful bias in generated content?", "a77c5103-8b46-4832-bec0-c35295cb3771": "What methods are suggested for measuring the prevalence of denigration in generated content during deployment?", "3b9eb9c7-9abf-455c-a032-e2e6152b1090": "How can direct engagement with potentially impacted communities help identify the classes of individuals or groups affected by GAI systems?", "4d67bfff-e89b-4dd6-8ba0-1bce0700c95e": "What are the key factors to consider when reviewing and measuring sources of bias in GAI training and TEVV data?", "c57f100b-7d28-44cd-a7ee-4b615b7f59c9": "How can the completeness and representativeness of data sources impact the outcomes across different demographic groups in GAI systems?", "4051af20-4573-4daf-b11f-22b5a2ec4a22": "What are some examples of input data features that may serve as proxies for demographic group membership in GAI systems?", "42276e79-a635-4c67-8d71-05e7dc49d5e9": "How might the digital divide affect the representativeness of GAI system training and TEVV data?", "b7db7ce9-273d-4d10-b0ab-987f942b45d4": "What are Winogender Schemas used for in the context of natural language processing?", "4ba735d5-d25c-4b17-ad51-f0a2a33c2346": "How do Winogender Schemas differ in their paired sentences?", "42f5a1bc-bb91-4d29-80ee-5747851a7f6e": "What is the importance of assessing the proportion of synthetic to non-synthetic training data in AI model development?", "66d4264b-4702-43ec-a93a-2b5bd8229a9a": "How can verifying that training data is not overly homogenous help mitigate concerns of model collapse?", "e4933310-b1b4-4925-b247-09c2a043e99e": "What are the suggested actions for assessing the environmental impact of AI model training and management activities?", "55dad69a-c6e3-4bc5-ac7b-d3acb343c853": "How should the anticipated environmental impacts of model development be documented according to Measure 212?", "68674ba8-1fe6-4fad-af5a-7dc5958b48b3": "What are the trade-offs between resources used at inference time and those required at training time for model deployment?", "64b00ced-e625-4885-a78c-cf01291b10ad": "How can the effectiveness of carbon capture or offset programs for GAI training be verified?", "3375e40b-e711-4d36-b106-6693f98eee37": "What are the key tasks involved in the deployment of AI within environmental contexts?", "4986506b-e45e-4d2e-be04-e379b6b4941b": "How does AI impact assessment contribute to environmental sustainability?", "7b6708ab-3aca-4421-b56c-de3d29eb1894": "What is the purpose of creating measurement error models for pre-deployment metrics in the MEASURE function?", "f9cc4605-e89e-43a4-80cc-e5a482d3cd4e": "How is construct validity demonstrated for each metric according to the suggested action in the context?", "f3b6669b-f08c-421b-a949-03ff44ca3bd9": "What are the key considerations for risk tracking approaches in settings with difficult-to-assess AI risks?", "6f1555b5-a517-4b37-9b9c-82e94833cc2e": "How can domain expertise be leveraged when modeling complex societal constructs like hateful content?", "353a259f-bf03-417b-a0ee-2f50f67550bd": "What processes are suggested for identifying emergent GAI system risks?", "a7adf46d-2081-4e5f-8944-c53df2e11a72": "How are feedback processes for end users and impacted communities integrated into AI system evaluation metrics?", "606a4837-87c3-4efe-827b-de21257acea1": "What is the purpose of conducting impact assessments on AI-generated content as suggested in Action ID MS-33-001?", "1707cf15-6ab9-4f22-ab75-c9cbf768e0a4": "How does Action ID MS-33-002 propose to evaluate end users' perceptions of GAI content?", "12ef24fd-7c8c-4f27-bb91-f26a4950c19f": "What methodologies can be used to evaluate potential biases and stereotypes in AI-generated content?", "d93e1c1a-88ec-467c-8d42-3c0337ffdddb": "How can structured feedback input contribute to assessing harmful bias and homogenization in AI systems?", "183ad455-0fc3-4f5e-83d3-90cad9a3cd58": "What are the capabilities and limitations of GAI systems in relation to digital content transparency?", "b505ce17-4190-4e48-93e2-40da22f01ad7": "How can structured feedback about content provenance be recorded and integrated to address harmful bias and homogenization?", "d07be81d-1f5d-4c2f-9067-d186164b8fce": "What methods are suggested for gathering feedback from operators, users, and impacted communities?", "39c3395c-2fa7-4132-8302-fa60cbc4f970": "Why is it important to assess the general awareness of feedback channels among end users and impacted communities?", "a711af99-7562-4d30-9e77-49a864cb0843": "What is the purpose of Measure 42 in relation to AI system trustworthiness?", "3b6a8413-8cdd-49fd-a96e-1d5f5ff16c1f": "Who provides input to inform the measurement results regarding AI system performance in deployment contexts?", "5437aa29-a999-4816-ab7f-0171ed95fc8c": "What is the purpose of conducting adversarial testing in relation to GAI risks?", "26951269-6092-41d7-91ed-ae4c03bd31ab": "How can evaluating GAI system performance in real-world scenarios contribute to understanding potential misuse scenarios?", "4ba7f9a3-1d66-4b4c-8110-0c4e218152d8": "What are the potential issues that might arise in practical environments that are not evident in controlled testing environments?", "0a848933-772b-4c81-924a-57a2f0e21cb9": "How can interpretability and explainability methods be implemented to evaluate GAI system decisions?", "53eb1f8b-74e4-48c3-9f5c-fa5ef9d3d76e": "What is the purpose of evaluating cases where GAI's decisions are overridden?", "8965c3cb-b583-4109-be7c-84519e4ca45d": "How should structured public feedback be incorporated into the decision-making process according to the context provided?", "edacd7f2-688e-452a-9458-88c11965db60": "What are the key tasks involved in the AI Actor's responsibilities within the Human-AI Configuration?", "d090fd47-869c-4477-b77e-d42730dd9c4f": "How does Information Security relate to the deployment and operation of AI systems?", "f1db0b9b-bc83-4fbd-890b-f275827ea928": "What are the possible risk response options mentioned in the context for high-priority AI risks?", "d8c488e2-2581-45e4-8518-63bcfe844ea6": "What should be documented for risks that do not surpass organizational risk tolerance according to the suggested action?", "be4758a7-d4f0-4b58-857a-55c675d4b754": "What are some approaches to model release that can be considered in the context of projected use cases?", "bd3a7923-9e11-4ff8-99e6-f7f3c7a4926a": "How can organizations mitigate risks that exceed their risk tolerances during the model release process?", "c4a4462b-0a95-48f1-9625-7e2fa9537568": "What mechanisms are suggested to sustain the value of deployed AI systems according to the context?", "59a5efa6-0316-481c-9c52-51648babb1d4": "How should GAI system outputs be evaluated in relation to organizational risk tolerance?", "b5826720-6408-4f69-9cb4-c2ff55be1ade": "What are the key guidelines and principles for reviewing and testing AI-generated content?", "05d49bc9-2fe5-4ac9-b7b2-bb5837b60d83": "How can the origin and provenance of AI-generated content be documented according to the provided context?", "ad298146-c893-453a-a068-d8bea4250191": "What techniques can be employed to mitigate biases in generated content according to the context provided?", "145c7745-3573-427f-a8df-72261ad6d47d": "How can real-time monitoring systems contribute to the effectiveness of content provenance protocols?", "d03569f4-1aa7-4b55-b74d-81ffb4340412": "What types of harmful content should be analyzed in GAI output according to the due diligence guidelines?", "ca30c779-262a-49b4-8ffb-ddc1242ccc06": "How does the context address the issue of harmful bias and homogenization in content analysis?", "e5aecd6d-a715-4e2c-85ab-21863a484c8d": "What methods are suggested for assessing the impact of AI-generated content according to the context?", "c28e368d-edd6-4ea9-8e99-46ae614c3453": "How can real-time auditing tools contribute to the validation of AI-generated data?", "aa319ea4-6620-4bfc-8810-34cbeb4dd4fe": "What are the potential benefits of using synthetic data in GAI development while ensuring privacy?", "87f8b08d-b07b-4e15-b008-42b3ec3f197b": "How can the use of synthetic data help in detecting shifts in quality or alignment with community values?", "b1b7d964-d37c-4b6c-9cf8-b35ee5946107": "What procedures are followed to respond to and recover from a previously unknown risk when it is identified in the context of AI deployment?", "e5f4b413-e75b-4b68-9cce-4dafa14e757f": "How does the development and updating of GAI system incident response and recovery plans address harmful bias and homogenization?", "a9807194-9d9c-4051-9c1b-8df8af085ce1": "What procedures are in place for the review and maintenance of policies regarding newly encountered uses of the GAI system?", "ff48c2cd-3b3a-4b1d-ae2c-d11c50c62659": "How are response and recovery plans verified to ensure they include necessary details for communication with downstream GAI system Actors?", "81d66fcb-a052-41fd-83c3-64acb7267416": "What mechanisms are in place to deactivate AI systems that do not perform as intended?", "dcbf1f6c-7827-4259-a51e-2947b373b304": "How are responsibilities assigned and understood regarding the management of AI systems?", "283e3d4d-a7d6-4a6d-8804-948b9f0158ae": "What are the reasons for the deactivation or disengagement of a specific GAI system?", "b177e0ab-9328-4ee1-b01c-272459b84901": "What alternative processes are available for users after the removal of access to the GAI system?", "0b34b975-f0ed-4364-996d-ab8b02dcd27a": "What procedures should be established for escalating GAI system incidents to the organizational risk management authority?", "fcb3ac19-35ed-4270-bf42-757183d317c7": "What criteria must be met for the deactivation or disengagement of a GAI system in a specific context of use?", "98c8bd10-f544-4fdf-9b6c-818c16497dc6": "What specific criteria should be established and regularly reviewed for the deactivation of GAI systems according to the remediation plan?", "dbd3b41c-e8a7-4b53-afe6-355a3982a6da": "How are AI risks and benefits from third-party resources monitored and documented in the context of the remediation plan?", "23f5fc9c-d634-4a74-a3ab-3c8b51b6c02b": "What are some examples of organizational risk tolerances and controls mentioned in the context?", "d7190994-1fab-4914-989d-0f623a003e9a": "How should organizations apply risk tolerances to third-party GAI resources according to the provided context?", "9a7167c5-b74b-4523-9298-32c94aa550c8": "What are the key considerations when applying organizational risk tolerances to third-party GAI models?", "cc6ebb75-517c-4059-a382-d88638d4f263": "How can organizations reassess risk measurements after fine-tuning third-party GAI models?", "8948d801-96fd-44a2-a55a-9035df7801f8": "What are the key considerations for re-assessing model risks after implementing retrieval-augmented generation?", "bca70e0f-2598-4485-9cc6-d841df307c82": "How does harmful bias and homogenization relate to data privacy and information security in the context of geopolitical alignment?", "49bfdf22-732c-4cfb-b088-9ce2a13795ec": "What measures should be taken to review training data for CBRN information and intellectual property?", "9449c36e-5aff-43a0-9155-c8c3a1afedff": "How can organizations prevent or respond to outputs that reproduce particular training data, such as plagiarized or trademarked content?", "d15f877b-a1f1-4f98-a651-c92ad0f1823d": "What types of transparency artifacts should be reviewed for third-party models according to the context?", "9ba81e7a-85f5-4835-bb3c-df2ba2c830b9": "How are pre-trained models monitored as part of the AI system's regular maintenance?", "222791a6-a4eb-455d-958d-182b60c7a5ab": "What techniques are suggested for applying explainable AI (XAI) to mitigate risks associated with unexplainable GAI systems?", "df229865-5dcd-4403-afdd-9f05e02eedc3": "How should the adaptation of pre-trained models be documented according to the provided context?", "2fbeacf6-26cb-4c7e-8523-78cbeb4ce181": "What is the purpose of accessing un-tuned (baseline) models in the context of retrieval-augmented generation?", "9bd9930b-6fb7-4638-9563-2f03099aa765": "Why is it important to document sources and types of training data, including their origins and potential biases?", "69f848e7-2021-42fa-ba33-7fe4ad528e3b": "What aspects of the GAI application are covered in the context regarding its architecture and training process?", "5f01e56e-1324-4028-aeb9-a73996fb92a2": "How does the evaluation of user-reported problematic content contribute to system updates in the GAI application?", "b0215aa7-4f8c-40cc-9860-91b76a905bba": "What types of content should the implemented filters prevent in the GAI application?", "c908dfd4-f442-4463-b199-a2367681add6": "How can the content filters be designed to flag problematic inputs and outputs?", "3b3fcb19-7145-4e2c-b5bb-7f45a5668fd8": "What processes are suggested for monitoring the performance and trustworthiness of generated content?", "9ba84d4e-f6ea-4edb-95b4-748a7fe1ac6e": "How can deviations from desired content standards be identified and addressed?", "73342338-38de-460d-b74f-6a4f818d0d1f": "What should organizations leverage when deploying GAI applications and using third-party pre-trained models?", "02c5d33e-e359-40e6-be85-3fb77ed7cccb": "When is it appropriate to use human moderation systems in the review of generated content?", "067076ac-b0d5-41ba-b3e5-1bafadde987e": "What factors should be considered when evaluating acceptable risks and performance metrics for AI models in organizational settings?", "6834e514-d625-49e7-afcc-1e26eecfcccc": "In what contexts do AI models typically perform poorly, and how can this impact their deployment and operation?", "f80c2d3d-3e75-4db8-85bc-f51d951b8806": "What mechanisms are included in the post-deployment AI system monitoring plans for capturing user input?", "7d4ab63c-dda4-4dd8-9057-2d92f0218d74": "How does the suggested action MG-41-001 aim to address GAI risks?", "7f373e5a-7c8f-4fb4-b8ae-44975f72ff4f": "What are the key technologies mentioned for measuring and managing identified risks in GAI systems?", "21cb153e-4001-4282-8afa-fd3ce68dcf0c": "How can sentiment analysis be utilized to assess user sentiment towards GAI systems?", "acc6400c-253b-42dc-9c49-3e01610a4f24": "What techniques are suggested for identifying instances where the model fails or produces unexpected outputs in the context of Human-AI Configuration?", "f98d3812-ebdd-4e81-a230-bd9dcad8d6e0": "What is the purpose of sharing transparency reports with stakeholders regarding the GAI system?", "a75a5ff3-057b-4290-bf8f-e2290b6addba": "What measures can be taken to track dataset modifications for provenance in the context of Human-AI Configuration?", "b65a80b5-e908-42c3-8034-255267d9d061": "How do harmful bias and homogenization relate to the monitoring of data deletions and rectification requests?", "f17e745b-4758-4bdf-949d-0c353472811e": "What are the responsibilities of AI Actors in monitoring reported issues related to GAI system performance?", "53538b5d-b942-4b1f-9e52-c9248388cad2": "How do content provenance data tracking techniques contribute to the evaluation of GAI system performance by AI Actors?", "4b9d1f11-5eaa-45d8-944c-62263b3176cc": "What is the purpose of conducting regular monitoring of GAI systems as outlined in the context?", "88403993-708f-47aa-bbef-f5e50a151c8c": "How are measurable activities for continual improvements integrated into AI system updates?", "eaa00f70-773c-417a-a50b-ff02970a5217": "What steps should be taken to adapt processes based on findings from incidents involving inappropriate or harmful content?", "5efa4f93-9171-4caf-999b-beda88554fb4": "Why is it important to conduct post-mortem analyses of incidents with relevant AI Actors?", "537ac27e-2bc6-4840-a609-c69c3883dd7c": "What methods can be used to represent GAI model behavior for non-technical stakeholders?", "0931d05e-778d-41be-a5e7-d505183fc5ff": "How are incidents and errors communicated to relevant AI Actors and affected communities?", "91d98ceb-8f0f-40df-aaab-3b804bc8669c": "What procedures should be followed for communicating incidents to relevant AI Actors and legal bodies after a GAI system incident?", "e4ade30b-d167-4b93-b018-21ed46cfcf50": "Why is it important to conduct after-action assessments for GAI system incidents?", "63e30b77-1159-4533-9cde-3b4353eec832": "What policies and procedures should be established to record and track GAI system reported errors?", "b7304081-393b-4724-a195-f3f8199f371c": "How can organizations ensure the integrity of information related to near-misses and negative impacts in the GAI system?", "455a8826-1ab7-4c3d-8735-de0939dcca38": "What are the legal and regulatory requirements for reporting GAI incidents mentioned in the context?", "cc183b87-b146-428f-9499-b96d41ca2c5f": "Which organizations' reporting requirements are referenced in relation to HIPAA and autonomous vehicle crashes?", "5ee98732-8c16-4a81-87c9-c2c26f8e06a9": "What are the primary considerations derived from the GAI PWG consultation process?", "655cad1f-41a4-48dc-ae8e-aec77fb05789": "How do the primary considerations inform the Actions to Manage GAI risks?", "16ff3ed0-8b4e-40a3-94c7-46cf186f82b1": "Who are the GAI PWG leads acknowledged for their contributions in the context?", "638255b4-29ff-422a-8464-5027592e0ce8": "What is the purpose of the considerations mentioned in the context?", "e47e3253-5b56-44a9-bf56-f536bdd3ba6e": "What are the governance principles and techniques mentioned for managing risks related to generative AI models?", "12ee080b-aac9-440f-8a91-8fb4d66e80ba": "How might organizations approach risk tiering for generative AI systems according to the context provided?", "b8f890aa-fe35-4039-a16e-1098c7f43b75": "What are the key differences in oversight required for GAI compared to non-generative AI tools?", "ac3a8972-f247-40c8-b00a-aa94c06bcf58": "How do human perceptions and actions regarding GAI opportunities and risks differ from those related to non-generative AI?"}, "relevant_contexts": {"7da4306b-07a5-40a2-a188-25437e45abaf": ["13ab5c44-7c66-4f6a-b2ab-9e738739127f"], "957125d2-fb67-48e3-8d1d-f4325a566484": ["13ab5c44-7c66-4f6a-b2ab-9e738739127f"], "f229f517-f23a-43f4-8a09-6b69e76b6783": ["6ecf9145-9e3f-4609-bd14-b01776d477c2"], "987aa119-fd53-436a-b9af-0c82aa68e598": ["6ecf9145-9e3f-4609-bd14-b01776d477c2"], "39bf9a10-3f3a-407f-847c-7aefe861beea": ["aa9acb4a-aafa-4c99-89f5-ce6a37a36019"], "79ca268f-4d35-4c4b-8ba5-4d56dfbc097d": ["aa9acb4a-aafa-4c99-89f5-ce6a37a36019"], "b602dc85-f613-4a50-b303-d85c312d07bc": ["550ce037-301b-49a4-be60-09f0550259a7"], "3576faba-8c35-4382-a8d2-5469d48cfeba": ["550ce037-301b-49a4-be60-09f0550259a7"], "89377f71-26fa-4d0b-a4c9-9e4df3c7d41b": ["943dd47f-e9b3-41c6-a07b-bc4bb0b539a5"], "5684046a-0420-45c1-a81d-0c8bb0694783": ["943dd47f-e9b3-41c6-a07b-bc4bb0b539a5"], "daa24cc1-9244-407a-a961-f7303f6660be": ["ee48d633-8662-41f0-9371-e7154a2e2682"], "9cb3088c-f196-453a-9d02-a860bbee0253": ["ee48d633-8662-41f0-9371-e7154a2e2682"], "4e0aa1d2-d7a0-4e34-b962-31481fc60432": ["487b7e66-7d1d-4d53-a3f1-29a3366e756c"], "51fa362a-a05c-4184-a255-b3310f8e96c9": ["487b7e66-7d1d-4d53-a3f1-29a3366e756c"], "3a4f6df5-cbba-4b51-b226-3782f1c0f02b": ["aae1324d-e572-4a72-9d7b-7a41ea71ca7c"], "9b1cf4f6-fbc2-4cec-a3c9-2313af798226": ["aae1324d-e572-4a72-9d7b-7a41ea71ca7c"], "f3aa3a80-0885-4502-bfdd-c775eb5c88bf": ["72f64b09-4f01-45c0-8cf7-d632ede75a76"], "35c630e9-3e88-450b-bcca-da30efbbf0c0": ["72f64b09-4f01-45c0-8cf7-d632ede75a76"], "618cc897-0c43-438e-a3ce-0b98cacc93ce": ["9ce51271-7da0-4a36-8235-adf61c2a7ab2"], "80f50aec-d0ad-47c9-8d27-87587a841504": ["9ce51271-7da0-4a36-8235-adf61c2a7ab2"], "c2baf0f1-b816-4678-b4bc-95a4533e7f2a": ["5874e900-77aa-44f8-8a5c-3057f3f949b5"], "3782a589-e437-4c5d-9861-7c9eaa8c03df": ["5874e900-77aa-44f8-8a5c-3057f3f949b5"], "e5a6107e-1fe9-455a-861e-3d6556ca8bdc": ["9d071388-d8dc-409e-a61b-5c2e12bca1da"], "1f0b83a8-8467-432a-a2b3-4c822fc21647": ["9d071388-d8dc-409e-a61b-5c2e12bca1da"], "43c6a76a-e065-4717-84fc-86b86faefb71": ["4b28f694-8a0d-43c7-b871-4fff513670f9"], "bc3edda3-22fa-4376-be8a-911a9972f247": ["4b28f694-8a0d-43c7-b871-4fff513670f9"], "b0dbee88-053c-43a2-8a68-4331ad22336e": ["fa28956e-2c9f-436d-9f55-34e940682bf3"], "10732235-3d5a-488b-9540-70a86aa2c2e1": ["fa28956e-2c9f-436d-9f55-34e940682bf3"], "d30764e4-985c-445d-b4da-f08dcc74b273": ["8abf64cb-6829-47ad-acd2-94ce13043a0c"], "f3cef27e-3b55-4ea0-9f2f-74d95a6733f0": ["8abf64cb-6829-47ad-acd2-94ce13043a0c"], "eddf8984-d9cd-4159-91d7-09e566302725": ["7f9f4b19-3911-44bb-b55b-a2105267cb97"], "bc648d2f-5f5f-4c1c-abfd-0702bff16ec1": ["7f9f4b19-3911-44bb-b55b-a2105267cb97"], "14d14675-62cb-44bd-8e92-11c0e45b358a": ["5559cac5-3fcb-4945-a45e-1fb176a99a0b"], "31c1c6cf-78ca-4d9c-b3e1-ffc6e96d50ec": ["5559cac5-3fcb-4945-a45e-1fb176a99a0b"], "d0aced1d-fee9-4cc5-8b60-e2e10bdcee5e": ["e94266c0-d458-4eec-b13e-99fd2c13f854"], "6ce560e2-4d54-47fa-86b0-853619d9a656": ["e94266c0-d458-4eec-b13e-99fd2c13f854"], "c536f25b-1a69-4d08-867d-84f025515d2d": ["6f983242-11d0-490b-8b48-6a45970de66a"], "ce384c85-10e9-4f62-8168-5eb908e1df1e": ["6f983242-11d0-490b-8b48-6a45970de66a"], "909cad34-8791-499a-a8ad-a377a07386d7": ["abc40c26-5325-44cb-a03c-698039cc5aa6"], "eb5ba597-f014-483c-894c-5d2a4b622299": ["abc40c26-5325-44cb-a03c-698039cc5aa6"], "f42ee69a-19d0-47e1-9500-f8de76d9607f": ["b54de951-a0ed-4a9b-8c90-2432c688cc7c"], "b5f2314e-384b-4741-b504-1706514bdbb5": ["b54de951-a0ed-4a9b-8c90-2432c688cc7c"], "4c5d9c86-c124-4918-b863-0cb5a84b94c3": ["00d0dca3-14b2-450d-939f-4f63c666f867"], "42755778-5835-470c-af7f-f51714e1e985": ["00d0dca3-14b2-450d-939f-4f63c666f867"], "d5df1217-f07f-4e89-8819-dc703cde3421": ["7b45ff07-9ccf-404a-a050-ef7b7cf39261"], "ea233e4e-9056-45c8-a3bd-0a943d521fe6": ["7b45ff07-9ccf-404a-a050-ef7b7cf39261"], "a9e62eb7-6203-45ed-8f86-a2cbc240be51": ["f0871f37-b49d-4a30-a282-f5e5e43b922a"], "f43cb85e-c8bb-4ec3-89d7-6a04ba3745dc": ["f0871f37-b49d-4a30-a282-f5e5e43b922a"], "eac2900f-8d7e-43a7-89b0-79d3b4a14378": ["0983b5d5-e480-4563-a3cb-eb4234b92391"], "79900a50-d876-4f30-906f-f5038d13fa40": ["0983b5d5-e480-4563-a3cb-eb4234b92391"], "df61f92a-d1db-4ed1-84e0-537eca8f9021": ["063dc893-dd57-4d89-ab09-8285c52dc21a"], "775126fc-70fb-4b34-a2a8-b4ea8bff3d31": ["063dc893-dd57-4d89-ab09-8285c52dc21a"], "cfc775c0-3e34-4c9b-a9ed-f0007d6d791b": ["ff043860-2028-49e4-92ea-88ab2948a849"], "193fe9a9-38bc-4fe8-9b6c-e7e96a5da0e9": ["ff043860-2028-49e4-92ea-88ab2948a849"], "56971afe-1ebc-405e-a79d-19ef239d63f7": ["b96c24fb-84ec-4658-81aa-f57fdd47baa1"], "99f43c2f-128b-4a39-b2a5-783943abd1b1": ["b96c24fb-84ec-4658-81aa-f57fdd47baa1"], "f812fb0a-3483-4cc0-acf9-e65f21bcd9b4": ["b5bcc0bd-0a35-4b4f-acc3-1cacaa6c36d0"], "067d80a4-97c9-4cae-8833-921a4a09620b": ["b5bcc0bd-0a35-4b4f-acc3-1cacaa6c36d0"], "1c5cfb3c-d909-4a34-b409-de538296c990": ["deaf0ecf-7a3a-4371-8645-82479a904fd7"], "3d6f0601-221a-44bc-9629-52e98ca7887f": ["deaf0ecf-7a3a-4371-8645-82479a904fd7"], "9fec5fe0-43f6-42b8-860e-d59c7b3efda4": ["959b70c3-615b-4207-a4f9-ce9c012cace9"], "0671508a-449a-49ea-86f6-db4a76a00577": ["959b70c3-615b-4207-a4f9-ce9c012cace9"], "f4960509-5115-47db-86f8-06422c42a2e9": ["bf7eaca6-e10d-44ba-9019-ca34ac8cb519"], "5447c18d-f9ca-4e98-b0df-e0b81bf4c943": ["bf7eaca6-e10d-44ba-9019-ca34ac8cb519"], "7c67e806-d758-4755-aedd-64eb96e4852f": ["235c8567-33b0-42f6-a403-287a1ff63bbb"], "0ef30b23-cf72-4519-acb2-1bcc7be0cacf": ["235c8567-33b0-42f6-a403-287a1ff63bbb"], "0ef657b1-60d4-4953-8633-f8e7c0d9c246": ["6a24b211-7d0c-4d38-8749-c9b4f92f66fa"], "c42b2e50-7026-4059-9276-5aa3ca5e2e99": ["6a24b211-7d0c-4d38-8749-c9b4f92f66fa"], "9f57c805-36b6-4e4a-a115-7ba39be84206": ["710217a6-641a-470e-9bbd-5a5f26561649"], "5485786c-12e6-4ba5-9f45-8246329bd81e": ["710217a6-641a-470e-9bbd-5a5f26561649"], "ca42395a-cdb4-48f8-a71c-42d81faf7520": ["3f3e0458-e0a4-4d4a-bf0b-434d43250212"], "b9dc1099-9b9e-45dd-8684-ed78b915bf7e": ["3f3e0458-e0a4-4d4a-bf0b-434d43250212"], "ec44cdbc-1fbf-41a3-b4e2-053ece570d8f": ["220a4da5-61a1-4c89-91a6-a920387912ca"], "a0813af1-6be5-4b2b-a71a-0921f81ba39c": ["220a4da5-61a1-4c89-91a6-a920387912ca"], "e3e3d04e-53f5-44df-96f6-8c8f7e7ecee5": ["7eda0beb-368a-47b5-8acf-826b359c4ee4"], "134bec27-5cb7-496a-bfd4-476414be3bbb": ["7eda0beb-368a-47b5-8acf-826b359c4ee4"], "2dc7efbd-543a-4782-9309-8dde3a414696": ["4dda00bc-6e6a-4c0d-8bee-034d463ac011"], "267efce7-11e9-48b0-88f5-9e0f8c224938": ["4dda00bc-6e6a-4c0d-8bee-034d463ac011"], "adaf2d48-71ec-4deb-8fb0-e60d99e1edc2": ["66f65809-9f20-4318-83e6-962e6b43827a"], "fe6656f1-3c3f-4ba6-849c-4365a3be5501": ["66f65809-9f20-4318-83e6-962e6b43827a"], "e8098614-6f03-42ec-9e51-26d379e70f47": ["ee9a3aac-893a-49eb-ae9c-ebbd73ddf155"], "8f51d0a8-74ca-47eb-a659-cbeed871cf59": ["ee9a3aac-893a-49eb-ae9c-ebbd73ddf155"], "e40d770e-be62-4ee1-8a2f-02a15a85b22a": ["de5ad05c-3d78-4d81-b484-42915bc61166"], "9ce38b02-495e-4784-a0ad-81e41430dd84": ["de5ad05c-3d78-4d81-b484-42915bc61166"], "9a1d8b46-1a61-47b2-96a5-916a0dc9e5a5": ["51e13acd-c5d0-4bd1-b1bd-cada999156f8"], "fda67880-da08-433d-ade0-b30b7720bed0": ["51e13acd-c5d0-4bd1-b1bd-cada999156f8"], "508aedb9-6e50-464c-8fd3-7ed2040ebef1": ["825ee573-c2b5-4c34-9195-ca4e7bb016b3"], "c4b6a2d7-6595-47a2-8006-4ca67ac20b45": ["825ee573-c2b5-4c34-9195-ca4e7bb016b3"], "416c56f2-a372-44dc-bb0f-b454d294db1d": ["8ef7c298-b94b-4240-ad46-77258e83661b"], "9a9e22fe-ebd2-4faa-8df1-c9fbb122b716": ["8ef7c298-b94b-4240-ad46-77258e83661b"], "988c7340-d8a9-4344-bdad-7b03eec5dec1": ["8721ddd9-2ab3-4b0e-a5d1-47110817bfa8"], "5187c8e7-a801-40bc-b0f0-a4f5ebc9fb18": ["8721ddd9-2ab3-4b0e-a5d1-47110817bfa8"], "10a4e5db-dd0a-49d0-9c0c-ce451dbe7b05": ["303da3b9-03fe-41bc-9ca0-9212ed9dd1e5"], "3bc7082f-2a55-497d-af9f-15d9443e3f50": ["303da3b9-03fe-41bc-9ca0-9212ed9dd1e5"], "0bc92e68-ff92-4fba-8f04-31339e087d22": ["e20cb8a4-d241-400a-ac14-88a80d423155"], "d999cee8-112f-4a6f-ac98-0a830d457ee3": ["e20cb8a4-d241-400a-ac14-88a80d423155"], "76027f7f-9147-4c75-b93a-c4aeb9951c1d": ["6dbf71a1-b0e1-4a5c-90cd-6a857b861ebf"], "cd5f4ad9-5817-433b-b42f-ad6732375a4e": ["6dbf71a1-b0e1-4a5c-90cd-6a857b861ebf"], "f82981f1-0f22-4a5c-a45e-d4895ffd6163": ["44a9f4a8-1ec9-4213-95fc-a4deef9f2951"], "39d98943-888b-400b-b7e4-4e646bb901a2": ["44a9f4a8-1ec9-4213-95fc-a4deef9f2951"], "8ef5356a-a69f-42e2-9aa1-d45f8c0ded00": ["c05cd88e-eb49-4ce9-8556-962d8bfeb9b3"], "0e956f7b-60a0-4ad6-913d-f1e7a23ec836": ["c05cd88e-eb49-4ce9-8556-962d8bfeb9b3"], "54f17719-6559-4e21-a871-abdafe965c21": ["7bff0eda-6a82-4128-ac77-5b63c7856257"], "dcd11d30-e8dc-40f1-9593-52e8060218c5": ["7bff0eda-6a82-4128-ac77-5b63c7856257"], "3e002c9f-349f-4898-9c42-2adde4cfa1b5": ["a21c4079-5ad3-42ef-b2f7-9b9db51aea43"], "6e548619-c929-4bf7-90fa-21b7f8f4a744": ["a21c4079-5ad3-42ef-b2f7-9b9db51aea43"], "f5a94717-56fe-4fbe-b68b-7fecc9da960a": ["754e96d8-afc5-4736-b1e4-223822f6bf72"], "791d55ce-8e81-4b98-9110-9223dce4c999": ["754e96d8-afc5-4736-b1e4-223822f6bf72"], "fbf92bec-d73c-4ae6-818a-dfac3a0b3247": ["ed823956-27d0-445b-ab4e-3c3ff755dda3"], "f1a4438a-4eb5-4bfa-a047-4233a86d332e": ["ed823956-27d0-445b-ab4e-3c3ff755dda3"], "6af930b1-eea5-444f-afa8-db00b0bb2a71": ["9374b6bc-4cf9-4740-9394-f29308dc7daf"], "a76d003c-baf2-427a-a203-b39d08e47df9": ["9374b6bc-4cf9-4740-9394-f29308dc7daf"], "0f05cb9b-a5dd-4d8d-b854-f3e4624d622a": ["8afc75ca-7cdf-4c1d-9902-abe6652c5ffb"], "651d2536-4293-44cf-98de-165e8902ca3d": ["8afc75ca-7cdf-4c1d-9902-abe6652c5ffb"], "7beec528-c074-4861-9aea-1aeaf05896a3": ["732f2bb0-58d3-4807-87db-a0247257fd3d"], "af5aa401-e8a3-46b5-8a8e-95f1276413f8": ["732f2bb0-58d3-4807-87db-a0247257fd3d"], "ef88c956-99f1-4b5a-8006-65341edaad28": ["4407d785-3ecc-4783-8ba3-c0016d39f133"], "0904834a-1753-4699-a3d0-34a82904ee0e": ["4407d785-3ecc-4783-8ba3-c0016d39f133"], "48736b18-d6a5-4980-917e-286a5bf000ce": ["b8c5f583-62c0-414c-90db-78f372db9420"], "74cd7873-a28b-43c6-9d55-ec9833ce8626": ["b8c5f583-62c0-414c-90db-78f372db9420"], "19753cb2-44c5-4016-9b15-1a9014254171": ["275f6eeb-c845-4869-8efb-7bc0d5a781da"], "ecc278af-594f-4ebb-91fd-845e7a20f630": ["275f6eeb-c845-4869-8efb-7bc0d5a781da"], "786f25e0-c6d9-4002-bcbd-6867c7b7ad0c": ["7422e046-726e-4192-8493-b472ddcf6644"], "29680099-a2ae-444a-8687-f259fd7b2400": ["7422e046-726e-4192-8493-b472ddcf6644"], "fb35a9a4-05ec-487a-9335-a0d2317b32cc": ["ae410d2f-dd72-43ad-bafb-bbb0ce9f6582"], "89169f57-3a00-4437-9999-630d56e7e9b5": ["ae410d2f-dd72-43ad-bafb-bbb0ce9f6582"], "c50194a6-c65c-4118-b0b9-e453736019c4": ["bd51d60d-ad70-4558-a4bf-2d870d7ab9d5"], "49004544-4eb1-4444-becc-d96f273105eb": ["bd51d60d-ad70-4558-a4bf-2d870d7ab9d5"], "fc81cee8-5fbd-4f7e-bf23-2564ce1e6b9e": ["3776154c-db39-47ce-889e-17b39503e8a4"], "ffbbe8ee-bb35-4523-9866-c1b98a47275d": ["3776154c-db39-47ce-889e-17b39503e8a4"], "a0b398fe-daf3-423e-a987-d59949335a2f": ["eafd0478-db38-4d96-a135-924cbf8955d6"], "d6419312-c74f-4396-bfaa-62a3deb7bcfa": ["eafd0478-db38-4d96-a135-924cbf8955d6"], "dca4051b-4125-4355-bb71-b5a1ab6f70f0": ["98aa4f70-c0a9-4466-8fc4-7aa110e00b21"], "aa84545c-5245-4ce5-b1cb-00d6c95bd328": ["98aa4f70-c0a9-4466-8fc4-7aa110e00b21"], "a08a182d-fbe3-4ccf-8437-fcd13bc6af01": ["a62c0872-5bec-4b9a-8860-2ce67167a2da"], "0e405d79-1a70-4fd2-8804-2c9b1c2a2afa": ["a62c0872-5bec-4b9a-8860-2ce67167a2da"], "b54c3d83-6e3d-4455-b32c-bf8338212fa5": ["6c61a3cd-244e-466a-aba7-280ff802f576"], "96e73113-9bc9-48c9-b25c-9b1546a47f51": ["6c61a3cd-244e-466a-aba7-280ff802f576"], "8e4ea705-62d4-48ef-b1c7-9194a0cc30d7": ["244307c9-f8da-490e-b1a0-6f379b71abac"], "90787a3c-b6c5-460f-bc04-18e586bb23ae": ["244307c9-f8da-490e-b1a0-6f379b71abac"], "d4e7f5e0-788a-4384-ba22-4865c3fd2d99": ["9f9e5712-2858-4885-b1f9-2a3137788579"], "e05c44ea-62db-426c-8344-3233be27fe39": ["9f9e5712-2858-4885-b1f9-2a3137788579"], "b7586360-4755-421c-a909-bb6efbcfa34d": ["72c43dda-7942-4db5-8ef2-79b59728bfb5"], "7c38d78b-56c7-42d9-a040-4daa777751ad": ["72c43dda-7942-4db5-8ef2-79b59728bfb5"], "3c598788-7dc2-481e-bef9-d6fdb30bfb7d": ["0f64cc85-1f40-4301-a0cf-62da43cbe24c"], "0b136c25-6ba2-441a-a322-1314af3d7f47": ["0f64cc85-1f40-4301-a0cf-62da43cbe24c"], "24e84b42-c0fb-4a1c-a633-c0e4c22c3f46": ["676a914e-0b98-48ef-b77e-fe3d5747e9c4"], "50049a0e-7299-418b-921f-19825ed016a5": ["676a914e-0b98-48ef-b77e-fe3d5747e9c4"], "9ac658a5-b688-4ca5-aa9e-3a900bbe2871": ["e86e66d2-488c-4d6d-b2a3-3c8aee17177b"], "f564a52e-9e55-4d03-808b-afeb04775554": ["e86e66d2-488c-4d6d-b2a3-3c8aee17177b"], "9e5c7ac0-2f32-40c5-93fe-4527e6c220f2": ["56960bb9-af76-4b81-8361-4260a51997c0"], "1274a002-d426-4750-b070-762fce425ab5": ["56960bb9-af76-4b81-8361-4260a51997c0"], "78c7bf5c-5791-46ad-a266-4351eaa621b9": ["6433266f-0590-485c-91c0-dae0ba7d2913"], "21b412fa-50ba-490f-ac0a-8eca1e34f458": ["6433266f-0590-485c-91c0-dae0ba7d2913"], "58f5fc5d-2ef4-4a9a-820e-7bd9cabe868a": ["c44383a3-9e05-491a-8295-d8efabb367ee"], "9c5d8cb8-21e7-474a-8dfe-f70977210eff": ["c44383a3-9e05-491a-8295-d8efabb367ee"], "c5efb9cf-bdec-4b70-973a-b670b08e4c92": ["666008aa-55c1-4df2-aeeb-e7e45c9f165a"], "b9606e96-b25c-4303-aa23-166315d2f617": ["666008aa-55c1-4df2-aeeb-e7e45c9f165a"], "5391e513-3b67-4450-90a9-5368b59ec6ec": ["45566d45-9b1c-4391-8c00-8173dfc6684e"], "388c4e33-02b3-40fb-ae78-d2d75c227aa9": ["45566d45-9b1c-4391-8c00-8173dfc6684e"], "b227bfd9-59dc-4c37-bb94-b4e7f163689b": ["a2f14943-ba1b-4562-9b85-8519a4d4a92c"], "70db3ddf-f80b-4b78-b11b-7ac02c806abd": ["a2f14943-ba1b-4562-9b85-8519a4d4a92c"], "fe6fa3db-15e2-44d3-9477-86e0dd22385b": ["24525d3d-7bf0-4601-b403-efa9e17398cd"], "c6e26aee-ec67-48bb-9631-26dbfc59425e": ["24525d3d-7bf0-4601-b403-efa9e17398cd"], "4a9b1cca-a7f6-4d09-8cbe-b8a6d45a89cf": ["c2f3e1a5-9449-436d-bb39-4a776a66fc8b"], "6296ff40-aea1-4bcd-8607-c3ae071de026": ["c2f3e1a5-9449-436d-bb39-4a776a66fc8b"], "29cb0067-e5f0-408e-880d-4d40d1f54a7f": ["1b5a542c-42e6-47fe-b108-42cb5107ff95"], "0e7d42eb-8aa1-4359-bce7-7463d13451f2": ["1b5a542c-42e6-47fe-b108-42cb5107ff95"], "04b5edda-3c70-4cc8-88fa-e4e3d186e017": ["c7ab2e6e-3140-4080-a980-638374a17ee2"], "d737d0a8-e2ed-47f4-a139-7f45d4e5c174": ["c7ab2e6e-3140-4080-a980-638374a17ee2"], "543a927d-3cff-450b-a238-678eb3dbccb9": ["95e6f848-d25e-404b-abc9-0047637a2f69"], "7fb9efdd-6989-436c-852e-0ad72ccd3d3b": ["95e6f848-d25e-404b-abc9-0047637a2f69"], "0463d3f6-260d-4acd-94a0-3ce9a81c3d5e": ["a413be5b-5112-419d-b575-1b59e1df2509"], "4e8ccec0-e4f4-46b4-b08c-979c47a9464e": ["a413be5b-5112-419d-b575-1b59e1df2509"], "3fc58164-b216-4e36-8194-3394c0bfe39e": ["8e452509-7625-440b-b1b9-004d9436a01b"], "4d0cd971-1bc1-4dfd-8015-d91747fc942c": ["8e452509-7625-440b-b1b9-004d9436a01b"], "d4c5c535-3cad-4cc6-965d-7071d6e2e299": ["bf005bac-9bdb-4355-8074-e9a3bd763335"], "f80a1da1-4da6-4bce-9d22-1e35ecc2e091": ["bf005bac-9bdb-4355-8074-e9a3bd763335"], "e7bd39db-4985-474a-9096-c280371467fe": ["0d87c27b-7f3d-4683-937e-a8f2ea561d44"], "ad6c4283-bf50-40d7-b7e4-fc8c7ab0efc4": ["0d87c27b-7f3d-4683-937e-a8f2ea561d44"], "0d5a5c48-367a-4b3c-84b7-8e31b6600b2d": ["319211d5-0a90-4752-9d0a-a6df1c4ead2f"], "7c062f9e-e27c-4d0f-82fb-7f14c13aca6a": ["319211d5-0a90-4752-9d0a-a6df1c4ead2f"], "45cb7046-a066-40d4-878d-3c460fb494e1": ["be8dd8de-3bef-4876-a051-9e52582a7af0"], "955acb56-f01e-4e42-b3ed-7046cad87e95": ["be8dd8de-3bef-4876-a051-9e52582a7af0"], "39e82040-a9bc-4d01-9986-d22a4747efb1": ["d6fad9d7-720b-4d3e-8f47-ada473a963f0"], "10634e64-50b6-43c1-8821-8a97e69ffbdb": ["d6fad9d7-720b-4d3e-8f47-ada473a963f0"], "2e1aca03-7471-4bc0-a43c-49af217684db": ["eb8a8d51-2024-4590-8a5f-a4504655b5c7"], "7a81d97a-dbf9-4a63-9a55-9c17ee98b62b": ["eb8a8d51-2024-4590-8a5f-a4504655b5c7"], "5bf5b622-2752-4782-ae3b-8c545368c0da": ["3f0f251e-b854-4063-8a98-3d670764553f"], "c58693b2-8acc-4108-bc96-22912970f034": ["3f0f251e-b854-4063-8a98-3d670764553f"], "f13721d6-71de-4d3f-81e1-7e851a7db36d": ["31f40290-c4cb-4730-9669-743e6f36a08e"], "1d4ee2bd-4cf7-409a-8625-682478972038": ["31f40290-c4cb-4730-9669-743e6f36a08e"], "8a7c01fd-8617-41d2-a11f-741bc526c468": ["10694483-2f00-420c-82dc-99dbd771bc37"], "857d1bb5-10b4-419b-8502-435b3ff07466": ["10694483-2f00-420c-82dc-99dbd771bc37"], "39b1ede6-b0d3-434d-964c-9d18688d0858": ["38ce2a8c-7cc7-49ed-99ca-ebec9fec8c61"], "1797b3ab-f887-44df-8ad0-045c30ce3103": ["38ce2a8c-7cc7-49ed-99ca-ebec9fec8c61"], "776807a9-d8e5-41f3-a551-63a6e23f35fa": ["68f00fa6-8f6b-4b90-a6f9-1b42a7d167f8"], "571c0bde-ce77-4acd-a964-189a4c2e6bb6": ["68f00fa6-8f6b-4b90-a6f9-1b42a7d167f8"], "e8c22ada-1444-4c40-bdd0-0e94b19a92b9": ["886b1d6c-95f8-4364-b362-44119e9be5c2"], "6a36bd89-6b87-4a0b-9eb5-90542d5b3bc2": ["886b1d6c-95f8-4364-b362-44119e9be5c2"], "ee36886c-d8e7-4cbd-8c28-c108d379d266": ["e4802347-16ce-4e0f-8b38-04370de361e0"], "45d436cf-103c-46e6-a420-a5a7057cb7b0": ["e4802347-16ce-4e0f-8b38-04370de361e0"], "2df60392-38d1-40e3-9c68-1b9db5727c32": ["d70ce55f-d989-42f0-b182-76fd4d6fa9f8"], "8cf94226-6539-4c39-b85b-27e924202bfa": ["d70ce55f-d989-42f0-b182-76fd4d6fa9f8"], "c5600959-9177-4725-837e-9fb5dac162f9": ["536515ab-da06-47a5-bd1d-702b0ec0456d"], "ec485ff9-12d1-43ac-a816-2ebbe0996a0f": ["536515ab-da06-47a5-bd1d-702b0ec0456d"], "78f36117-ecba-4879-aeea-228d471a85f8": ["c3d59ec2-9f5a-4dbc-808c-9f11c13f474b"], "4277366d-b0dd-4a99-9323-78f6947ed356": ["c3d59ec2-9f5a-4dbc-808c-9f11c13f474b"], "192138d5-fbd6-4c76-94d0-473f137248cd": ["017d1e2b-31d2-4ab5-b7a8-ca399b302309"], "16a49d99-02ed-401f-9779-8b1bcb868e81": ["017d1e2b-31d2-4ab5-b7a8-ca399b302309"], "d61d78b2-ae63-4e2e-b690-96eb51d87ce2": ["6a8a0cef-e35d-45af-9cbc-d9203b2f4295"], "da0c8826-3fb6-4bcc-b01c-71e310c494d9": ["6a8a0cef-e35d-45af-9cbc-d9203b2f4295"], "3a5b3ceb-c1dc-42b8-a0c0-ba81990afff2": ["f7fc4dc0-51d2-461e-a396-b9319bcc5ead"], "7b91873b-7fcf-4cc4-a714-5c88ca417289": ["f7fc4dc0-51d2-461e-a396-b9319bcc5ead"], "7a4318f6-1026-42a1-928b-e8ed02e0a291": ["b187e3b8-18ab-4fa3-b818-779aeaa27e7c"], "92f520d2-60fb-46c7-8d2c-5a6dc11bb85d": ["b187e3b8-18ab-4fa3-b818-779aeaa27e7c"], "8076e2cb-58d3-4fe5-95ba-2bd6dd16ea0c": ["ad8d5b40-a089-4aae-9d42-c8ee195238ee"], "63afae28-38a6-4e3e-927b-d0959ed245b7": ["ad8d5b40-a089-4aae-9d42-c8ee195238ee"], "f06769a4-83e4-4d94-b510-fe052a843500": ["0036688d-e6c4-4b9d-854a-739323aeeb6c"], "bbb83601-cccd-401a-8a98-5b9da0d9e690": ["0036688d-e6c4-4b9d-854a-739323aeeb6c"], "b14855cb-8487-4c0c-948d-26d68bbdc651": ["ff4582ab-f151-45f5-a5ef-cb182dbd8cd4"], "df9ade84-251b-4a01-8854-4da806d8328a": ["ff4582ab-f151-45f5-a5ef-cb182dbd8cd4"], "c6403904-2d92-406b-b0c0-55bc3ae9fc1a": ["f63a8e94-6294-4231-9cef-1f9c686d4044"], "dd98b58c-15cc-48b6-aa2f-b23a5774708e": ["f63a8e94-6294-4231-9cef-1f9c686d4044"], "a72e2713-dc44-423c-b816-7dfe500684c5": ["faf9bf36-f9dd-42a0-ac6d-c735e40d0d7c"], "661ee90a-fe27-487c-9f2f-f4e62e31e2f0": ["faf9bf36-f9dd-42a0-ac6d-c735e40d0d7c"], "c7b1c9c6-ceeb-4fb3-bc1c-9a29f1a3423b": ["f15ddc9a-4364-4125-a2bf-bb63e5282c56"], "853a5aea-9538-479e-8c9c-2c5630a76f64": ["f15ddc9a-4364-4125-a2bf-bb63e5282c56"], "f4aaf0cf-8c3b-408d-9ffd-2b86a26cd350": ["a3cd6ae2-ce86-46b4-a2aa-06f9493b043b"], "e8eea805-18cb-4904-9054-11ac8e017b49": ["a3cd6ae2-ce86-46b4-a2aa-06f9493b043b"], "a2881edc-9675-4177-a001-809634f7b1c5": ["562e4f0f-6c62-4145-a63b-567c1c39dcaa"], "e2027359-8c48-4e43-bc9f-af1a1be9db72": ["562e4f0f-6c62-4145-a63b-567c1c39dcaa"], "459c845c-59c6-42a5-a99e-aa9cec59fdef": ["ed341718-61a0-42ee-8ce1-79adb58efe62"], "7493dc38-e666-4e0c-92e0-db899fb62c51": ["ed341718-61a0-42ee-8ce1-79adb58efe62"], "adb8a6df-063e-4ca7-9478-c7f8ae1871e9": ["f883cf24-85be-4bf9-b630-74e573719dfa"], "e8d9dc1e-0ae6-4d79-a387-6525461b40c1": ["f883cf24-85be-4bf9-b630-74e573719dfa"], "f70602a9-9ab9-45a3-9863-17e678e85158": ["ff3f2973-bacf-4507-8b2a-53a62514e155"], "a12d193e-206a-4a07-9b8b-853f16ba74c3": ["ff3f2973-bacf-4507-8b2a-53a62514e155"], "a3b3512b-0554-44dc-89af-7e36d6bf34e1": ["16f63209-c483-43bd-b8dd-2b4c937f03b8"], "4b4be905-98ac-47bb-9ecd-8d8df5aa57bb": ["16f63209-c483-43bd-b8dd-2b4c937f03b8"], "5a80f59f-3465-4e74-9037-996a7fe7fcd3": ["444d8b16-808b-4c67-a1c3-09cf9fbdc836"], "67265e7c-b3eb-47f2-a6a8-e56b912c69f8": ["444d8b16-808b-4c67-a1c3-09cf9fbdc836"], "e712f919-8449-417e-b816-faaa4d841f90": ["5440e5f6-70e2-4d75-af16-90380b955ba0"], "61f8e02f-a0a3-4045-b023-264779965da5": ["5440e5f6-70e2-4d75-af16-90380b955ba0"], "346048fd-90ce-4098-b01a-c3964228486c": ["b6680749-d27c-4a83-b6bf-94fee6096c9a"], "35425921-ac3c-4fbf-8b24-11f6c2199f26": ["b6680749-d27c-4a83-b6bf-94fee6096c9a"], "166d0d97-11b7-47a9-a0d2-48aa34457682": ["ccd26ddf-d19c-49fc-a6f4-8143af6ee351"], "74893817-90b6-4dc9-b68f-0ba23eda51f9": ["ccd26ddf-d19c-49fc-a6f4-8143af6ee351"], "0ac87bf7-4b0f-4ff8-a0ee-b498a4bbe649": ["e6ee5be0-00cb-4e93-b111-3498f0f20d90"], "92a9d689-7441-4c0b-846c-77f6332b6271": ["e6ee5be0-00cb-4e93-b111-3498f0f20d90"], "5472b3c1-bff9-48f9-b475-b0f114dd3d96": ["99a95571-ead0-4e2e-a346-7690ec7670a7"], "fab111ea-1bf0-42c3-b757-5236a20b7099": ["99a95571-ead0-4e2e-a346-7690ec7670a7"], "f45bfce7-4ead-4a30-9820-33e764003b06": ["576f1c91-0cb7-43e0-8d69-54b2111b5971"], "268b8356-c520-4238-8e61-c4048e1d2a36": ["576f1c91-0cb7-43e0-8d69-54b2111b5971"], "78c9cc97-72a7-404d-a46b-2961b44522e9": ["37982d43-22ca-45cd-83ce-4c9c6cc3cb60"], "76700c67-6bc5-494d-bd5a-6de90665aa0c": ["37982d43-22ca-45cd-83ce-4c9c6cc3cb60"], "781748b3-d0ac-41a6-bca2-8e76486ba04b": ["0be5801e-8eb8-4da6-ab31-be44c2dbae90"], "f532ddf8-63af-421e-95d6-d45613657deb": ["0be5801e-8eb8-4da6-ab31-be44c2dbae90"], "9699e807-db53-4345-ac13-795d69425ba5": ["41c069d8-65e1-4495-ac19-949a6612f571"], "b8d47ed0-8c79-4714-b93d-6f1433333020": ["41c069d8-65e1-4495-ac19-949a6612f571"], "19c4cac3-ef75-4871-98ca-20f875c3268d": ["209707b2-17f4-4c42-9603-cda4be4dd4b0"], "4d8f4504-42da-4eb9-8940-40aec734657e": ["209707b2-17f4-4c42-9603-cda4be4dd4b0"], "176cf50a-8e5f-4b7e-9a6a-b175fd33861a": ["569195d8-3a37-445e-a514-286c102763d8"], "2e87b785-c18f-4faa-9b89-ee6a34c6fa08": ["569195d8-3a37-445e-a514-286c102763d8"], "8b1aa0d6-2c9a-449c-9de6-c462cd115741": ["71105eba-5fbc-47b3-8f4b-03f9b8caaf60"], "61ce4905-c224-49a6-a807-e5131ebf8600": ["71105eba-5fbc-47b3-8f4b-03f9b8caaf60"], "cc25ad8e-d342-488a-a0f0-79037d32187a": ["31264d40-c2da-4ba9-9487-dc704268d896"], "f1a9d366-3a4f-4fd8-bd42-15350777d5a5": ["31264d40-c2da-4ba9-9487-dc704268d896"], "52d59750-c207-44d5-9961-7377c6a1c0af": ["919a361a-4a4f-458c-a10f-d9f35836038f"], "972cdeb1-b44a-49af-9ebe-d24cdb0e0b51": ["919a361a-4a4f-458c-a10f-d9f35836038f"], "397af11c-5018-403e-9b69-f29a27920a0a": ["015dcf2e-01e6-485c-89a3-dd9ba737c834"], "ba813978-c4c3-4ca0-92b8-520e3d51b786": ["015dcf2e-01e6-485c-89a3-dd9ba737c834"], "2d354b97-3502-40b4-9914-e58aae9287d0": ["610a0342-54e2-4731-835a-ec8a698c8594"], "dfc98789-e764-437c-a167-7b9c63fa3906": ["610a0342-54e2-4731-835a-ec8a698c8594"], "6833fc3d-b335-443d-b57c-86cefdaf0436": ["14202170-1ff1-4f10-814f-727e7dc8cf28"], "1850cec2-b1fb-4475-b3da-22177a5774b0": ["14202170-1ff1-4f10-814f-727e7dc8cf28"], "83929fac-8a6d-4805-890f-9a0170764127": ["e871e6d0-4b6f-414b-9989-dc55dfaae91a"], "d605b584-ff58-47e4-af9d-b9ed9723dd26": ["e871e6d0-4b6f-414b-9989-dc55dfaae91a"], "6f341356-c6d5-450c-8bbc-3f3a666d7e33": ["257254bb-de83-4647-bb4d-5a9a755e24ea"], "10323136-bcdb-49d6-900d-25dec3b6ef4b": ["257254bb-de83-4647-bb4d-5a9a755e24ea"], "0a9c41bd-e3c7-48fa-9995-84208e9fcd9f": ["c5183b5b-0579-401f-bd07-d9867090828a"], "dfd7e333-8a0f-4f44-bae4-4e152c8aa7ec": ["c5183b5b-0579-401f-bd07-d9867090828a"], "65bdb2cb-8cbc-4037-9081-22010197d6d4": ["b9b54081-e0e0-4104-ac44-009ee1a4b0b2"], "62ed6998-079c-407b-91ca-722ac55212b1": ["b9b54081-e0e0-4104-ac44-009ee1a4b0b2"], "7a349c80-e68d-4235-aa1a-64d5afa5ce2e": ["739017fd-dd12-4634-bfe2-38d19d38afd7"], "79818b22-7f8c-41b6-b371-a1e34d650ae3": ["739017fd-dd12-4634-bfe2-38d19d38afd7"], "45ebd20d-0150-47dc-84a7-9aea10e659ee": ["79ee56c4-711a-4cdd-abed-a16e3aaa7b68"], "120a7f63-d25c-45f7-9526-a6b40237e293": ["79ee56c4-711a-4cdd-abed-a16e3aaa7b68"], "4946ca99-3ed9-466e-aecd-4369a4d6806e": ["af3ad24b-8571-41ab-aaf9-911e834af7cf"], "6563b2d1-0390-46c3-8406-fd352d7f6539": ["af3ad24b-8571-41ab-aaf9-911e834af7cf"], "a74298f3-c2da-4782-8cc4-07a0cfe3f56e": ["9bdb6ef4-8748-4784-810f-6e31dc090aa8"], "1314f8e9-c9f4-4f9b-8f06-814bcdf63081": ["9bdb6ef4-8748-4784-810f-6e31dc090aa8"], "a7b15cc6-6361-4ab5-9174-2206621b04e6": ["390d3990-a20d-4394-a941-42ebe7a06821"], "1e335cc4-7ed2-4324-9496-923f160ebf4f": ["390d3990-a20d-4394-a941-42ebe7a06821"], "088ed4a1-76b5-4105-9d1e-7f0e860fd3fe": ["03af3d26-eecd-45bf-a335-f90b42ed89de"], "1b09308d-f168-488c-99fb-c81282d7b8ea": ["03af3d26-eecd-45bf-a335-f90b42ed89de"], "bf51d3c8-27ba-460c-9e00-c03b6458a458": ["b9f3f747-dc5a-4b45-9746-c5e1b954807f"], "0fe306f3-79eb-4cbb-b072-598091469bee": ["b9f3f747-dc5a-4b45-9746-c5e1b954807f"], "1fa77a2f-43a8-4bcb-ac05-003529505a13": ["72e10bdf-dc23-4393-9b7c-7e75574cdb5f"], "f342840f-c175-4e0f-8743-3c6a152abcce": ["72e10bdf-dc23-4393-9b7c-7e75574cdb5f"], "111d9464-8962-4c3a-a2b3-13e291c025ef": ["145113b4-8c35-411b-babc-7a875eacf0b4"], "4dc02326-c912-4dfe-b759-d7aff51f9421": ["145113b4-8c35-411b-babc-7a875eacf0b4"], "8e133ec2-746a-45d1-bcac-0f74ff3effc8": ["a9934331-7fa6-423a-ab9e-b1d42c9562ba"], "5b707c1c-51ed-42da-87a5-e319ae12b426": ["a9934331-7fa6-423a-ab9e-b1d42c9562ba"], "da7e435d-8712-4eb5-8751-132b02f647ff": ["480d0c45-0c92-4aaf-81b5-d11b74c7b19f"], "d5eff59a-66a4-431b-8936-634c8b214f8d": ["480d0c45-0c92-4aaf-81b5-d11b74c7b19f"], "c9b20fd7-6bbb-40dc-985f-6f595c380f90": ["47cde558-9ad2-410d-8ffb-c1509ee5df53"], "126da3b2-39d5-46b4-b239-6cad4f5e7438": ["47cde558-9ad2-410d-8ffb-c1509ee5df53"], "ae571637-e810-45dc-a495-5bf1a3799668": ["70391d0b-c1a5-44ec-89a1-dc98f66a0b55"], "72cac010-add9-4acc-b7f9-ef2865bdf9d2": ["70391d0b-c1a5-44ec-89a1-dc98f66a0b55"], "fc9717bb-6f84-43e9-a26b-3d7ffc2ad76e": ["667f2f8a-da23-44c4-aa8d-e657c9b8b6ec"], "3a310e77-7a0f-4a63-a915-d22cf6023d8e": ["667f2f8a-da23-44c4-aa8d-e657c9b8b6ec"], "5fcaeeaf-59ec-4873-9673-18a2023dd76a": ["944e0f81-e0f7-4fb5-a598-7b29990d179d"], "516884bc-d7bf-4f0e-bad1-82d9071e9d4a": ["944e0f81-e0f7-4fb5-a598-7b29990d179d"], "8385d3df-0762-4665-9ff4-a80fe58ce6c0": ["56a66cb4-4c44-461d-86cc-c0d9d6d56343"], "6c1201f8-1df8-493a-8a15-b97024c5e15d": ["56a66cb4-4c44-461d-86cc-c0d9d6d56343"], "30b3568d-a78a-4b14-a4c0-2d0f1fadf81d": ["b56fa832-bb27-492f-bb71-1875a2e305d2"], "b4ab09c0-8158-46a7-aed0-c43caf83c9ac": ["b56fa832-bb27-492f-bb71-1875a2e305d2"], "2ca3ec38-65c2-48ea-bedc-f798b4c4aa9e": ["adc5d2af-5bd1-4e77-960b-e0793bcc9ad7"], "4b9bfd7a-5510-4fb5-bb7f-d908d2de2203": ["adc5d2af-5bd1-4e77-960b-e0793bcc9ad7"], "170d1add-af9f-4456-ad2a-7cf3ba2f4c9d": ["a4562603-9381-4337-a104-0e49f9e991ab"], "df251bcb-bca5-4ae0-9760-c26e80acd805": ["a4562603-9381-4337-a104-0e49f9e991ab"], "cc183ca5-3b1c-4320-9d78-c8fb4a5eb588": ["af292c09-d3f9-4425-b1da-7d5a3eae704a"], "7c8a80d2-f69c-409a-8be2-636a2043bd91": ["af292c09-d3f9-4425-b1da-7d5a3eae704a"], "8e5936cc-9447-4077-8639-b087475b4680": ["f1b7b858-6d8b-45ef-9c3d-f84b0bbf9b5f"], "3089311c-8043-43f5-84b4-a39ebc2d632c": ["f1b7b858-6d8b-45ef-9c3d-f84b0bbf9b5f"], "4ee2f619-5988-4755-9654-49523b6a5751": ["851f9823-9380-4d95-9f14-e24c350c29aa"], "f8c8ded7-69eb-4f82-9a7c-df2578d5d5f2": ["851f9823-9380-4d95-9f14-e24c350c29aa"], "fb762e0c-1948-4cab-b1ee-ab0ca5919007": ["bc92b533-6432-44fa-ab33-29020fb475d1"], "fafdb574-8ba4-4c3d-b5dc-9653e4368c61": ["bc92b533-6432-44fa-ab33-29020fb475d1"], "e6d94f3e-a129-476f-ba3a-dfe43f45df24": ["30c76ce9-0821-4bb3-b04a-f856bcf93159"], "3b8271aa-e7bf-4a0f-8f06-b9d1824e9390": ["30c76ce9-0821-4bb3-b04a-f856bcf93159"], "7955b50d-71eb-43fb-809c-9c95960af063": ["1958c94c-5fb5-4edb-9056-33f063104422"], "5eb8be4b-cb4f-4260-a628-2904036be344": ["1958c94c-5fb5-4edb-9056-33f063104422"], "234c85ec-5f2d-4ea5-94a9-71da126ec78d": ["f50f3efe-506e-4113-834b-4684131005c4"], "e4c7b812-8d49-4690-a62b-3a48e1a6705c": ["f50f3efe-506e-4113-834b-4684131005c4"], "70f3dbcd-ae57-4b19-9e2c-082d0be52986": ["2d09bfbb-8028-41c4-86c4-df651ef01dda"], "a1cdb6a6-b726-434d-a806-e88176c1d397": ["2d09bfbb-8028-41c4-86c4-df651ef01dda"], "45f45ccb-aaa6-42ea-a6ff-58a8007b2b1e": ["297c46ce-fc38-4eb7-9f3a-749301e38744"], "2e4bd2f0-30aa-4241-844d-f0375a83ff13": ["297c46ce-fc38-4eb7-9f3a-749301e38744"], "dbd80163-cf8e-4ad4-bb01-9e74bb101b49": ["0f5b941c-11b4-4ab5-bdd9-f3e5dfae51a3"], "41623169-e544-4867-99c7-3efac5850845": ["0f5b941c-11b4-4ab5-bdd9-f3e5dfae51a3"], "6a28881c-441a-4297-81ce-1c3657e22c99": ["5de3928e-0cdb-4216-9847-cd2ef7c39266"], "b3602378-bfa4-4665-8798-e2357a1022f4": ["5de3928e-0cdb-4216-9847-cd2ef7c39266"], "dc6ccaf1-9309-4bc1-a2e6-cc0a998235eb": ["0d409da2-57e3-4917-a799-9461af3eaa1c"], "600bc4d4-32ed-4cb9-b1f7-19b691da7377": ["0d409da2-57e3-4917-a799-9461af3eaa1c"], "29d3a9e7-6e4c-4a70-aeb5-57077c92ceae": ["924ebf16-aa94-45b6-b458-77f36134fc72"], "6d5771f9-28c1-4c7d-8db8-828572e81981": ["924ebf16-aa94-45b6-b458-77f36134fc72"], "dd1900ce-dbb9-48fe-be23-1d7325ce3c45": ["17ba07f7-c245-4fda-9ba4-c069a7bdf67c"], "2361a7a9-b219-434b-aaf0-1ffe4a18c47b": ["17ba07f7-c245-4fda-9ba4-c069a7bdf67c"], "9b633fbf-7d2d-4f57-8f5f-4698d812043b": ["d2482e09-2280-4774-ad5f-82c7a76f333b"], "cdfdf33e-d7c7-4abd-a87e-f6a1df9fddb8": ["d2482e09-2280-4774-ad5f-82c7a76f333b"], "a3d8b56f-0199-4246-948b-bac4c22f3225": ["e6400329-2b4a-4855-95fe-80d97f8f2ae6"], "2fcf45d7-1dae-49f1-9617-57d7ee188e39": ["e6400329-2b4a-4855-95fe-80d97f8f2ae6"], "9d47fa0f-7c9c-4977-8336-f8062b3ae63e": ["a57e8f7e-b554-4ec8-9883-724250b4de0f"], "2edf849c-ecc7-460a-853f-83464481bae0": ["a57e8f7e-b554-4ec8-9883-724250b4de0f"], "de3c5444-a098-40b8-8640-696c5b9ed1a9": ["33615dea-79a7-4f0c-b514-e14bededf990"], "7d21def8-2e62-4874-b198-20163dd35670": ["33615dea-79a7-4f0c-b514-e14bededf990"], "31852ec4-afd9-482c-9945-9a15161a0dc3": ["e38c3bb1-c587-4264-b136-ae28ee07b4f7"], "1e9c29cd-f6ca-4ee1-b2c0-9d9d85746cb7": ["e38c3bb1-c587-4264-b136-ae28ee07b4f7"], "302f3cfe-b5fc-4f12-9745-983974fd8185": ["359f4b4c-0282-48e0-833b-5a5d04632a67"], "df0d70e5-b120-4800-9f65-d570c9575e66": ["359f4b4c-0282-48e0-833b-5a5d04632a67"], "6fa5f94e-8610-42d5-8b2f-f132e7d64630": ["b0d14d8f-1162-40ad-a713-5051e684159b"], "1e62c657-aff1-4d0b-ae5f-45e0fdaa52f9": ["b0d14d8f-1162-40ad-a713-5051e684159b"], "53b0e8cd-929f-4ebf-89c3-1a45a55e9439": ["fcbe8813-092b-4497-b628-d6d49338d2b9"], "8495ea69-3b51-4013-ae7f-3fb7a657c856": ["fcbe8813-092b-4497-b628-d6d49338d2b9"], "4ffb4cbd-aac6-451d-85ad-ccb2cab1510f": ["15ea5bb5-6551-4eb2-aad6-3b662e66bf19"], "469dac88-7a3a-44d5-bcf6-0ea6e115e4c4": ["15ea5bb5-6551-4eb2-aad6-3b662e66bf19"], "6abe785a-4ca4-4183-baa5-042c66c0ccab": ["10476be1-63fe-483e-8895-004c2c0c51c0"], "9705ef98-10c2-40c2-81bd-656e5fb0372a": ["10476be1-63fe-483e-8895-004c2c0c51c0"], "0d40c653-90f8-4b64-974f-c212bb102821": ["1ae108f9-b63d-43dd-b72e-834564d7b215"], "5101afbc-5b55-4cec-a691-a6c092244a22": ["1ae108f9-b63d-43dd-b72e-834564d7b215"], "c3e847ea-aac8-4e52-87f0-a7dcb0a41e68": ["2b92dab4-2bc8-473b-a934-46d205880dde"], "50042242-b2e6-4725-b819-7109717a5835": ["2b92dab4-2bc8-473b-a934-46d205880dde"], "93713bae-1713-40f8-b18b-ad7dfc2759a4": ["d0c57791-0b56-40d5-a3ae-2bb982b9ed2b"], "1be9ace4-f31d-435f-aac0-c11db4032314": ["d0c57791-0b56-40d5-a3ae-2bb982b9ed2b"], "8bb648a6-4c1d-4e1a-8cf4-242ff036e8cd": ["2ea047da-24dc-4a08-b554-6d9b437e97c6"], "b18a60a3-52e2-4ebb-9667-d7759b9c8c57": ["2ea047da-24dc-4a08-b554-6d9b437e97c6"], "3214c9cb-5e53-462f-9395-077d948209a8": ["d84ad962-92a2-4f9c-a4a4-8eeb1c056bb9"], "c72cc79d-2bf9-413a-9e7a-759b76b79f0c": ["d84ad962-92a2-4f9c-a4a4-8eeb1c056bb9"], "5454315d-20b2-4ce9-a099-709dec3d379d": ["64b3379e-17e4-4355-91c5-f29b8a985e4a"], "570859be-9aa9-4a0c-bcba-4cee364b3905": ["64b3379e-17e4-4355-91c5-f29b8a985e4a"], "25b4f175-8173-4d6a-a811-9f0434ffdba7": ["716cb343-c898-4c13-8605-a8fdb5bdb6a5"], "99ad4ea2-eb0f-42d0-abf1-2d5b2db81ed9": ["716cb343-c898-4c13-8605-a8fdb5bdb6a5"], "3c3af73c-1049-4211-accb-b8a36b69bd36": ["4416ba5b-9812-4972-92ce-d99fa00a48c1"], "3cfa8296-5450-4985-af38-1dea9ff6eb9f": ["4416ba5b-9812-4972-92ce-d99fa00a48c1"], "f191ee1b-59ca-4195-adc8-2db33a4f8a8c": ["c62d6d0a-ecf2-4752-84d2-f3bfd081d33d"], "9bfed8ae-4cc3-4e1a-a5b2-272fa3251bf9": ["c62d6d0a-ecf2-4752-84d2-f3bfd081d33d"], "a52a155b-46cb-4a8b-ba4d-c61dba11a8ae": ["c23a61e2-960c-415e-823f-b635ffc184be"], "9ae47683-5007-485f-977b-daa193870824": ["c23a61e2-960c-415e-823f-b635ffc184be"], "b6af3a54-2fc2-4716-98c9-816d61725772": ["6e2abe33-0577-44ac-b9a1-c92165788e9f"], "c1155a7a-c0ec-4639-a3ce-4205e3de37a7": ["6e2abe33-0577-44ac-b9a1-c92165788e9f"], "813d72fc-4f91-4fac-aacd-2520218b59a9": ["2f20af6a-fbb6-479f-8e32-835b2c0de8cf"], "94146da2-bef5-44f3-bfbf-83e8fa9ff181": ["2f20af6a-fbb6-479f-8e32-835b2c0de8cf"], "dafd308d-b282-472e-b5ab-2c22fe99529b": ["6e3716b3-492b-43f9-90f1-f1a0b03651fa"], "a660a279-349f-40a9-a93c-204c300886dc": ["6e3716b3-492b-43f9-90f1-f1a0b03651fa"], "19d50448-aeef-46ef-a1e3-267aed5aa42d": ["815a32a8-633e-4a9f-8ceb-8a4da0e102f6"], "ae3a92be-dba9-43ad-b2a7-2da040587029": ["815a32a8-633e-4a9f-8ceb-8a4da0e102f6"], "3e55bd0e-0582-4b50-a984-48b208e3d41b": ["7017ebcd-a073-456e-9934-6a1478b6a1f0"], "0b3d80d8-9f8f-4313-b454-b3b87700a757": ["7017ebcd-a073-456e-9934-6a1478b6a1f0"], "f55b22c0-f08f-49b0-a1cc-f1f988903edd": ["a7622acf-e255-4455-aca0-ad10d6e27d8f"], "259f71ae-f230-41a6-9189-bcc5d0fffa07": ["a7622acf-e255-4455-aca0-ad10d6e27d8f"], "654d90cb-224b-44ba-9c7c-114dcea5fc43": ["031247b6-1e11-48a8-ab70-61df26ae02d3"], "80b65398-4c52-4dfa-b592-258aa393fbe9": ["031247b6-1e11-48a8-ab70-61df26ae02d3"], "e96fb15e-8241-42ab-a8c9-6b615399eba8": ["3b8bc3e4-63c4-4f32-90f6-6212abba9162"], "d762ecdc-135a-425b-836c-2fdd78cb8e3e": ["3b8bc3e4-63c4-4f32-90f6-6212abba9162"], "b0e19780-10b5-41cc-9f6e-efab168a2d6b": ["7364233a-b9d9-4538-88e9-0963a172135d"], "c91c890b-7538-4afb-9497-cde2142ad432": ["7364233a-b9d9-4538-88e9-0963a172135d"], "e114efe3-29a9-48f6-b3f6-52661d358138": ["e1a5a27c-6c74-48a0-9cb2-5795cd1f275e"], "742f5ed9-844b-4823-860e-09e401ac01e6": ["e1a5a27c-6c74-48a0-9cb2-5795cd1f275e"], "de97cb0a-6231-4e1a-ba99-4e78d4e129a0": ["bd34a213-7c8d-4299-9efc-d2badf32d4ae"], "95c4f0a3-304a-4fb4-9f88-1e5877a01b18": ["bd34a213-7c8d-4299-9efc-d2badf32d4ae"], "3bbdd3aa-892f-4209-8dfb-1777b25a13f9": ["9a348f71-8119-4592-beff-25ed171d860d"], "a5e88bbe-5b35-4413-bd0b-16db4a1bf929": ["9a348f71-8119-4592-beff-25ed171d860d"], "39383dd4-d31e-4a89-a50a-0b800460e04b": ["4b03716f-53a6-4a13-85ba-3fe11fcb52a9"], "b47d9372-17f9-4433-84eb-aebc666001ee": ["4b03716f-53a6-4a13-85ba-3fe11fcb52a9"], "f06a56f3-2628-41c7-8ffc-6e77a6960683": ["30c62926-7bee-453d-a950-b2e30234ab4d"], "eda782d7-1c4d-47b5-bf4c-e4512841b7c6": ["30c62926-7bee-453d-a950-b2e30234ab4d"], "fefb8859-15fc-411c-a91b-5783e55b2b95": ["6588384f-edae-4dcf-b8a4-412ad19c3f8e"], "19090965-51e5-4cb1-b133-fc85553f4585": ["6588384f-edae-4dcf-b8a4-412ad19c3f8e"], "8d4138ef-ad43-4108-a92d-5381e79e40fe": ["cfc36ea6-1a2d-455c-8b54-d6ecf7990801"], "fee6d9ea-3eae-47f2-a140-1fef8d3f60c6": ["cfc36ea6-1a2d-455c-8b54-d6ecf7990801"], "59306433-98c1-454d-8b88-5fdb02299751": ["e6cdb624-6ee0-4341-abe7-fcd57e3ca5da"], "1c0ad06c-f25f-4686-b947-6d7ba642f3eb": ["e6cdb624-6ee0-4341-abe7-fcd57e3ca5da"], "8185b43d-8cc1-464a-ba77-1cd0ff89262a": ["574d14cb-a89d-4caa-8b7d-09869f4ef30e"], "eba9fd70-e3d6-4774-bf53-ebafeeb34cbd": ["574d14cb-a89d-4caa-8b7d-09869f4ef30e"], "6e642794-9aa0-409d-9ff5-fbedc2d97a38": ["d9f63217-6ee7-4cdc-bcc7-a5a47794dc49"], "c2199c75-de68-4754-aa16-8fd0e9180c4f": ["d9f63217-6ee7-4cdc-bcc7-a5a47794dc49"], "f0eac856-2d89-4130-8366-b3587342f4af": ["c5aa3fdc-500e-47a2-a4fa-3533b3b31215"], "f264a4fd-9711-427a-be32-98557db50e32": ["c5aa3fdc-500e-47a2-a4fa-3533b3b31215"], "ee9960e1-c93f-4c36-9b50-26737c3a5792": ["31ab7c4f-3148-42f9-b2bb-fbebff597fa9"], "e99e6fd6-3f13-4816-a692-e16453d63414": ["31ab7c4f-3148-42f9-b2bb-fbebff597fa9"], "2dba3900-9437-44d4-ac84-16b2d3d22b34": ["53f1b6d6-ed79-4575-b8b7-daf701ff77da"], "1b49a8d8-96c5-469b-ad42-818e0ce55905": ["53f1b6d6-ed79-4575-b8b7-daf701ff77da"], "753492ab-1ef3-44ba-8809-9f253490b37d": ["d029aef5-b500-4b5c-90dc-55ab7649740c"], "073d5b17-6c69-4edb-bc5a-ce4bce9a6066": ["d029aef5-b500-4b5c-90dc-55ab7649740c"], "3b95f237-4b6c-4272-8cf6-1c3a2c6fa637": ["d3acfb42-af32-4fc3-b2b2-95f83b20f359"], "bdbdc681-3f1c-49ae-abb9-b547e371bec4": ["d3acfb42-af32-4fc3-b2b2-95f83b20f359"], "546efded-d069-4b01-b4dd-174429d1ad43": ["f5d019f7-f216-48d9-bb0a-a01b59683479"], "fff65443-8cf7-4987-a89c-a3b1246a816b": ["f5d019f7-f216-48d9-bb0a-a01b59683479"], "e458be44-4a85-488a-99b0-6eeee096c808": ["a576b3bd-59db-415e-bd4d-df58d9e55795"], "1f18957b-4059-44c6-b8ef-116b5b6ff0f1": ["a576b3bd-59db-415e-bd4d-df58d9e55795"], "b805936d-bb81-408d-90e5-2882918cfb18": ["56a3e3bd-408b-4839-9063-bdb2157861ba"], "47995665-8fc7-4439-b145-e1cac6774ce5": ["56a3e3bd-408b-4839-9063-bdb2157861ba"], "c1896d0b-8d50-4194-90a3-54becf29bbbe": ["307382de-e114-41a0-9bf0-d57eeb8951c0"], "4d06d781-c177-477f-8bb1-5922c93df601": ["307382de-e114-41a0-9bf0-d57eeb8951c0"], "ef7049e1-7176-42e6-9e2a-0ef094f207a1": ["da4b6cc5-560e-49b0-9e36-f42dc9ea906a"], "5d608978-0963-498a-aad7-f6aa56e3b21a": ["da4b6cc5-560e-49b0-9e36-f42dc9ea906a"], "f2f21453-1c8f-4754-b453-9f0ce563264d": ["0d8fa597-434e-41cb-a848-8f4f6f31a360"], "10c4fbbd-4822-45fd-8eac-52a332e0817d": ["0d8fa597-434e-41cb-a848-8f4f6f31a360"], "f7c91fc7-ccc7-4ac6-a4aa-c85679c143ab": ["2d53c379-5019-47ac-ac27-77f678963c52"], "9720bb47-1d15-4bcb-8b83-4f14673d2727": ["2d53c379-5019-47ac-ac27-77f678963c52"], "c4ed339d-76ce-4629-9a74-0db22fb1471b": ["5a0f5659-184e-4139-9ee9-913c4374f090"], "b5bb3d25-7e2f-4668-aadf-758752d0641e": ["5a0f5659-184e-4139-9ee9-913c4374f090"], "b6c94b68-de74-40c1-bf84-199d682e457a": ["9445b50a-fce9-457f-9fb1-1c4d784d1cad"], "cfb4d288-e0bd-4b15-ac1b-a0a3f5c61480": ["9445b50a-fce9-457f-9fb1-1c4d784d1cad"], "e10aa1b0-8ea7-441b-9c57-d85da32ff6d0": ["b7f0301a-85d5-4ed9-9057-6c445568d10d"], "9c5356b5-2753-4877-b206-61ffab6732fe": ["b7f0301a-85d5-4ed9-9057-6c445568d10d"], "bb64e6dd-655c-4439-b19f-c17b4d58efdc": ["ff2e8735-63d2-4867-bbfe-e27c67c38a63"], "4c8fc6d4-8791-4625-a742-3a4f1c1c1fde": ["ff2e8735-63d2-4867-bbfe-e27c67c38a63"], "68790611-83f9-4eb4-b3f4-9ede81442691": ["f092c38c-a9ba-48a4-88cf-d7537cdb00e5"], "8960020f-d788-4f7b-a0b2-dd819ad757cd": ["f092c38c-a9ba-48a4-88cf-d7537cdb00e5"], "15dd3cf8-01c0-46be-b0f5-af2bb7d5dbda": ["09f4769b-a76e-40d4-872e-a1fbdfe4a4d5"], "5b4b53a1-12be-4df6-9205-0401c19d9b65": ["09f4769b-a76e-40d4-872e-a1fbdfe4a4d5"], "c1758bb8-b298-416c-9562-907a909e6d5a": ["e5a21908-2123-4986-a53a-a97126970641"], "210954d6-8aa5-4a62-8a5e-490ee6e8be69": ["e5a21908-2123-4986-a53a-a97126970641"], "2cb6d219-85ae-4a2d-8984-318978e3d2ad": ["7da18a7d-75a9-4154-b1bb-d36df5038ba8"], "a3167777-7433-40c7-8f5b-eb6bbbdb226d": ["7da18a7d-75a9-4154-b1bb-d36df5038ba8"], "cd155b05-4810-4dd8-a5c7-04a64a52e81d": ["042cbff3-d409-487d-91e3-bdedf935f77f"], "70c7b93b-8ec1-4781-87be-6ad59d408eef": ["042cbff3-d409-487d-91e3-bdedf935f77f"], "950c2e4b-6277-4b9f-b2ae-f20958461a16": ["518de83d-e9ba-427d-86a8-92bd8a9ebbd7"], "8701b2f2-9b25-4978-a47e-702cfe428cc8": ["518de83d-e9ba-427d-86a8-92bd8a9ebbd7"], "8a464a48-7418-4c74-a6f6-a6363e99b847": ["2a7243b2-85bd-487e-9172-851bb42842aa"], "3c774838-865c-48ae-a52d-a4e7d7b65c7d": ["2a7243b2-85bd-487e-9172-851bb42842aa"], "9624d5cc-e318-41c6-bbf9-00796191d629": ["42d1e208-e07a-4111-bf95-ec6fff362537"], "8da274f7-df73-4ad6-88a6-6681c265580f": ["42d1e208-e07a-4111-bf95-ec6fff362537"], "6bba4a17-3eef-4f35-b5cc-40fc708d2753": ["7c9fd1a6-5ebf-4b67-a3b5-84642aa5413b"], "a304ecd7-9052-4f05-8b8d-99ccf152216f": ["7c9fd1a6-5ebf-4b67-a3b5-84642aa5413b"], "a77c5103-8b46-4832-bec0-c35295cb3771": ["ea7256ef-c970-4924-9fa8-9c5374b8e4e8"], "3b9eb9c7-9abf-455c-a032-e2e6152b1090": ["ea7256ef-c970-4924-9fa8-9c5374b8e4e8"], "4d67bfff-e89b-4dd6-8ba0-1bce0700c95e": ["addbb0d2-e4be-48e2-b27d-e5b3889d9337"], "c57f100b-7d28-44cd-a7ee-4b615b7f59c9": ["addbb0d2-e4be-48e2-b27d-e5b3889d9337"], "4051af20-4573-4daf-b11f-22b5a2ec4a22": ["c0a8d284-739a-4850-8e23-caf08c2d756b"], "42276e79-a635-4c67-8d71-05e7dc49d5e9": ["c0a8d284-739a-4850-8e23-caf08c2d756b"], "b7db7ce9-273d-4d10-b0ab-987f942b45d4": ["6e8e6392-f299-419a-923d-9e9e16d22a3f"], "4ba735d5-d25c-4b17-ad51-f0a2a33c2346": ["6e8e6392-f299-419a-923d-9e9e16d22a3f"], "42f5a1bc-bb91-4d29-80ee-5747851a7f6e": ["1d644852-9826-4958-90e8-b6962f953382"], "66d4264b-4702-43ec-a93a-2b5bd8229a9a": ["1d644852-9826-4958-90e8-b6962f953382"], "e4933310-b1b4-4925-b247-09c2a043e99e": ["338644b4-39b2-4a12-abdd-f22d6d653bec"], "55dad69a-c6e3-4bc5-ac7b-d3acb343c853": ["338644b4-39b2-4a12-abdd-f22d6d653bec"], "68674ba8-1fe6-4fad-af5a-7dc5958b48b3": ["7cb0d367-a3e0-4726-8d26-504897a3a4e7"], "64b00ced-e625-4885-a78c-cf01291b10ad": ["7cb0d367-a3e0-4726-8d26-504897a3a4e7"], "3375e40b-e711-4d36-b106-6693f98eee37": ["cd0d5f5f-0262-495a-86cc-425bc2ffd74f"], "4986506b-e45e-4d2e-be04-e379b6b4941b": ["cd0d5f5f-0262-495a-86cc-425bc2ffd74f"], "7b6708ab-3aca-4421-b56c-de3d29eb1894": ["5df435ca-a7c2-4148-9a15-36e99b3b2a4b"], "f9cc4605-e89e-43a4-80cc-e5a482d3cd4e": ["5df435ca-a7c2-4148-9a15-36e99b3b2a4b"], "f3b6669b-f08c-421b-a949-03ff44ca3bd9": ["65c9cefc-c99f-41c5-8e8a-d54ecf807d5a"], "6f1555b5-a517-4b37-9b9c-82e94833cc2e": ["65c9cefc-c99f-41c5-8e8a-d54ecf807d5a"], "353a259f-bf03-417b-a0ee-2f50f67550bd": ["bb53b74a-7e3b-4a40-ad89-819923c541cc"], "a7adf46d-2081-4e5f-8944-c53df2e11a72": ["bb53b74a-7e3b-4a40-ad89-819923c541cc"], "606a4837-87c3-4efe-827b-de21257acea1": ["b67d8869-719d-4200-b11a-1d12e5806894"], "1707cf15-6ab9-4f22-ab75-c9cbf768e0a4": ["b67d8869-719d-4200-b11a-1d12e5806894"], "12ef24fd-7c8c-4f27-bb91-f26a4950c19f": ["46e15488-b075-4fc0-a5eb-d8dfd6a5b7eb"], "d93e1c1a-88ec-467c-8d42-3c0337ffdddb": ["46e15488-b075-4fc0-a5eb-d8dfd6a5b7eb"], "183ad455-0fc3-4f5e-83d3-90cad9a3cd58": ["7c838b34-44a5-4578-9299-120fcfa5086f"], "b505ce17-4190-4e48-93e2-40da22f01ad7": ["7c838b34-44a5-4578-9299-120fcfa5086f"], "d07be81d-1f5d-4c2f-9067-d186164b8fce": ["f06c026b-c110-4515-84b2-91c5366d3ab6"], "39c3395c-2fa7-4132-8302-fa60cbc4f970": ["f06c026b-c110-4515-84b2-91c5366d3ab6"], "a711af99-7562-4d30-9e77-49a864cb0843": ["9a2dd6c8-4923-434f-8cc9-f43a74702d90"], "3b6a8413-8cdd-49fd-a96e-1d5f5ff16c1f": ["9a2dd6c8-4923-434f-8cc9-f43a74702d90"], "5437aa29-a999-4816-ab7f-0171ed95fc8c": ["23a63448-25b3-4aa9-b9a9-5f789d7e30e2"], "26951269-6092-41d7-91ed-ae4c03bd31ab": ["23a63448-25b3-4aa9-b9a9-5f789d7e30e2"], "4ba7f9a3-1d66-4b4c-8110-0c4e218152d8": ["b7d794d7-db5a-46d3-a4bc-820bb816139b"], "0a848933-772b-4c81-924a-57a2f0e21cb9": ["b7d794d7-db5a-46d3-a4bc-820bb816139b"], "53eb1f8b-74e4-48c3-9f5c-fa5ef9d3d76e": ["64202c3f-46cd-4d2a-9e53-e51531764f7f"], "8965c3cb-b583-4109-be7c-84519e4ca45d": ["64202c3f-46cd-4d2a-9e53-e51531764f7f"], "edacd7f2-688e-452a-9458-88c11965db60": ["f4fece0b-d67d-4cd7-8e8d-ffbfe0298980"], "d090fd47-869c-4477-b77e-d42730dd9c4f": ["f4fece0b-d67d-4cd7-8e8d-ffbfe0298980"], "f1db0b9b-bc83-4fbd-890b-f275827ea928": ["ba222052-aa9b-4ace-9697-e8736cc999a9"], "d8c488e2-2581-45e4-8518-63bcfe844ea6": ["ba222052-aa9b-4ace-9697-e8736cc999a9"], "be4758a7-d4f0-4b58-857a-55c675d4b754": ["02ff8ada-38bf-485a-8b01-8bf789220a11"], "bd3a7923-9e11-4ff8-99e6-f7f3c7a4926a": ["02ff8ada-38bf-485a-8b01-8bf789220a11"], "c4a4462b-0a95-48f1-9625-7e2fa9537568": ["5209bccb-31ca-4866-b16b-3e583df327ac"], "59a5efa6-0316-481c-9c52-51648babb1d4": ["5209bccb-31ca-4866-b16b-3e583df327ac"], "b5826720-6408-4f69-9cb4-c2ff55be1ade": ["7e4e8503-07c4-41c6-8b9b-c9eb56846664"], "05d49bc9-2fe5-4ac9-b7b2-bb5837b60d83": ["7e4e8503-07c4-41c6-8b9b-c9eb56846664"], "ad298146-c893-453a-a068-d8bea4250191": ["f29803eb-defd-4a4c-95ae-b2bdf3f2e780"], "145c7745-3573-427f-a8df-72261ad6d47d": ["f29803eb-defd-4a4c-95ae-b2bdf3f2e780"], "d03569f4-1aa7-4b55-b74d-81ffb4340412": ["91146c6b-8df0-419c-95bd-89df152049ae"], "ca30c779-262a-49b4-8ffb-ddc1242ccc06": ["91146c6b-8df0-419c-95bd-89df152049ae"], "e5aecd6d-a715-4e2c-85ab-21863a484c8d": ["9d28b196-5f24-477c-a779-fbe4792d5e5a"], "c28e368d-edd6-4ea9-8e99-46ae614c3453": ["9d28b196-5f24-477c-a779-fbe4792d5e5a"], "aa319ea4-6620-4bfc-8810-34cbeb4dd4fe": ["d62eeec4-2abb-4a28-8755-ff94e882ce89"], "87f8b08d-b07b-4e15-b008-42b3ec3f197b": ["d62eeec4-2abb-4a28-8755-ff94e882ce89"], "b1b7d964-d37c-4b6c-9cf8-b35ee5946107": ["2a7cb8a4-5279-40c1-a953-bda469ba1cc4"], "e5f4b413-e75b-4b68-9cce-4dafa14e757f": ["2a7cb8a4-5279-40c1-a953-bda469ba1cc4"], "a9807194-9d9c-4051-9c1b-8df8af085ce1": ["89979000-f73e-47b9-93cf-000ebec9e009"], "ff48c2cd-3b3a-4b1d-ae2c-d11c50c62659": ["89979000-f73e-47b9-93cf-000ebec9e009"], "81d66fcb-a052-41fd-83c3-64acb7267416": ["d23dc50b-e726-48c8-9902-3cbb09995f30"], "dcbf1f6c-7827-4259-a51e-2947b373b304": ["d23dc50b-e726-48c8-9902-3cbb09995f30"], "283e3d4d-a7d6-4a6d-8804-948b9f0158ae": ["812a957e-8d09-4b79-a556-d26e07e8b05c"], "b177e0ab-9328-4ee1-b01c-272459b84901": ["812a957e-8d09-4b79-a556-d26e07e8b05c"], "0b34b975-f0ed-4364-996d-ab8b02dcd27a": ["52abff36-9d40-42e8-af8f-a0427d90a519"], "fcb3ac19-35ed-4270-bf42-757183d317c7": ["52abff36-9d40-42e8-af8f-a0427d90a519"], "98c8bd10-f544-4fdf-9b6c-818c16497dc6": ["1fa92ead-2a4b-4b0a-9f19-ef2a8dd864db"], "dbd3b41c-e8a7-4b53-afe6-355a3982a6da": ["1fa92ead-2a4b-4b0a-9f19-ef2a8dd864db"], "23f5fc9c-d634-4a74-a3ab-3c8b51b6c02b": ["6d3fed1f-a1ff-4838-940a-531a16692b76"], "d7190994-1fab-4914-989d-0f623a003e9a": ["6d3fed1f-a1ff-4838-940a-531a16692b76"], "9a7167c5-b74b-4523-9298-32c94aa550c8": ["f4c58a1b-7877-460b-ae20-eae5766d7b94"], "cc6ebb75-517c-4059-a382-d88638d4f263": ["f4c58a1b-7877-460b-ae20-eae5766d7b94"], "8948d801-96fd-44a2-a55a-9035df7801f8": ["8316504d-b00b-429f-9549-81dfbf07eb87"], "bca70e0f-2598-4485-9cc6-d841df307c82": ["8316504d-b00b-429f-9549-81dfbf07eb87"], "49bfdf22-732c-4cfb-b088-9ce2a13795ec": ["f2527c10-2c51-4e0f-8086-53eae394d0eb"], "9449c36e-5aff-43a0-9155-c8c3a1afedff": ["f2527c10-2c51-4e0f-8086-53eae394d0eb"], "d15f877b-a1f1-4f98-a651-c92ad0f1823d": ["34c27803-30c5-41ce-ba18-0b1edc20d984"], "9ba81e7a-85f5-4835-bb3c-df2ba2c830b9": ["34c27803-30c5-41ce-ba18-0b1edc20d984"], "222791a6-a4eb-455d-958d-182b60c7a5ab": ["404014d6-b425-49ec-b2f9-e43a47dc18c5"], "df229865-5dcd-4403-afdd-9f05e02eedc3": ["404014d6-b425-49ec-b2f9-e43a47dc18c5"], "2fbeacf6-26cb-4c7e-8523-78cbeb4ce181": ["e1531ea2-b493-496c-961a-08c899fa4172"], "9bd9930b-6fb7-4638-9563-2f03099aa765": ["e1531ea2-b493-496c-961a-08c899fa4172"], "69f848e7-2021-42fa-ba33-7fe4ad528e3b": ["37ba9d3c-7ada-4ff9-9995-de796092d1ba"], "5f01e56e-1324-4028-aeb9-a73996fb92a2": ["37ba9d3c-7ada-4ff9-9995-de796092d1ba"], "b0215aa7-4f8c-40cc-9860-91b76a905bba": ["fa0790da-e8ad-4ae9-b51f-1452a6bbe66c"], "c908dfd4-f442-4463-b199-a2367681add6": ["fa0790da-e8ad-4ae9-b51f-1452a6bbe66c"], "3b3fcb19-7145-4e2c-b5bb-7f45a5668fd8": ["0fd68789-61e7-4b36-ba8a-23428ba84c8d"], "9ba84d4e-f6ea-4edb-95b4-748a7fe1ac6e": ["0fd68789-61e7-4b36-ba8a-23428ba84c8d"], "73342338-38de-460d-b74f-6a4f818d0d1f": ["4b05b9f7-3ed9-4463-a305-9f9b52ec12a3"], "02c5d33e-e359-40e6-be85-3fb77ed7cccb": ["4b05b9f7-3ed9-4463-a305-9f9b52ec12a3"], "067076ac-b0d5-41ba-b3e5-1bafadde987e": ["ed7aa582-ff3b-40e1-8df6-1bd24ca6e6e9"], "6834e514-d625-49e7-afcc-1e26eecfcccc": ["ed7aa582-ff3b-40e1-8df6-1bd24ca6e6e9"], "f80c2d3d-3e75-4db8-85bc-f51d951b8806": ["b783fa0c-5517-4bc0-9cd7-4fc11536a4a0"], "7d4ab63c-dda4-4dd8-9057-2d92f0218d74": ["b783fa0c-5517-4bc0-9cd7-4fc11536a4a0"], "7f373e5a-7c8f-4fb4-b8ae-44975f72ff4f": ["d4a09c99-54bd-469e-9afa-8da500d66d28"], "21cb153e-4001-4282-8afa-fd3ce68dcf0c": ["d4a09c99-54bd-469e-9afa-8da500d66d28"], "acc6400c-253b-42dc-9c49-3e01610a4f24": ["0dba7b27-9ddf-4fc9-a33b-1b468d4d479c"], "f98d3812-ebdd-4e81-a230-bd9dcad8d6e0": ["0dba7b27-9ddf-4fc9-a33b-1b468d4d479c"], "a75a5ff3-057b-4290-bf8f-e2290b6addba": ["e549e55e-fcf0-4c8a-b3ba-b3988fc5557d"], "b65a80b5-e908-42c3-8034-255267d9d061": ["e549e55e-fcf0-4c8a-b3ba-b3988fc5557d"], "f17e745b-4758-4bdf-949d-0c353472811e": ["15fcbd74-4fad-48e2-8c38-77e7ce00e6b3"], "53538b5d-b942-4b1f-9e52-c9248388cad2": ["15fcbd74-4fad-48e2-8c38-77e7ce00e6b3"], "4b9d1f11-5eaa-45d8-944c-62263b3176cc": ["37abf575-cb71-4a3f-ad32-aceeb9a5c2e0"], "88403993-708f-47aa-bbef-f5e50a151c8c": ["37abf575-cb71-4a3f-ad32-aceeb9a5c2e0"], "eaa00f70-773c-417a-a50b-ff02970a5217": ["567d66e7-1c3f-4e1f-be3a-1c4c5f646f75"], "5efa4f93-9171-4caf-999b-beda88554fb4": ["567d66e7-1c3f-4e1f-be3a-1c4c5f646f75"], "537ac27e-2bc6-4840-a609-c69c3883dd7c": ["f9c4f5b4-ff0d-4acb-80ef-badde0a9370b"], "0931d05e-778d-41be-a5e7-d505183fc5ff": ["f9c4f5b4-ff0d-4acb-80ef-badde0a9370b"], "91d98ceb-8f0f-40df-aaab-3b804bc8669c": ["4f4f3aae-2fc8-4854-ba44-11c735d1912c"], "e4ade30b-d167-4b93-b018-21ed46cfcf50": ["4f4f3aae-2fc8-4854-ba44-11c735d1912c"], "63e30b77-1159-4533-9cde-3b4353eec832": ["5f3ca707-5144-4a2c-88b6-de1452d78b94"], "b7304081-393b-4724-a195-f3f8199f371c": ["5f3ca707-5144-4a2c-88b6-de1452d78b94"], "455a8826-1ab7-4c3d-8735-de0939dcca38": ["0fd7bc57-c13d-4456-80d4-3713553ed097"], "cc183b87-b146-428f-9499-b96d41ca2c5f": ["0fd7bc57-c13d-4456-80d4-3713553ed097"], "5ee98732-8c16-4a81-87c9-c2c26f8e06a9": ["83923590-f766-45b9-b36d-14d2d9cea223"], "655cad1f-41a4-48dc-ae8e-aec77fb05789": ["83923590-f766-45b9-b36d-14d2d9cea223"], "16ff3ed0-8b4e-40a3-94c7-46cf186f82b1": ["eb6f9a4d-693a-461d-abdf-e3a6d0efdb45"], "638255b4-29ff-422a-8464-5027592e0ce8": ["eb6f9a4d-693a-461d-abdf-e3a6d0efdb45"], "e47e3253-5b56-44a9-bf56-f536bdd3ba6e": ["724144d2-c133-4b8a-b3d6-39e3f55451f3"], "12ee080b-aac9-440f-8a91-8fb4d66e80ba": ["724144d2-c133-4b8a-b3d6-39e3f55451f3"], "b8f890aa-fe35-4039-a16e-1098c7f43b75": ["37666a9a-0aee-4d88-b2f0-2f03d1be9960"], "ac3a8972-f247-40c8-b00a-aa94c06bcf58": ["37666a9a-0aee-4d88-b2f0-2f03d1be9960"]}, "corpus": {"13ab5c44-7c66-4f6a-b2ab-9e738739127f": "NIST Trustworthy and Responsible AI  \nNIST AI 600-1 \nArtificial Intelligence Risk Management \nFramework: Generative Artificial \nIntelligence Profile \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.AI.600-1", "6ecf9145-9e3f-4609-bd14-b01776d477c2": "NIST Trustworthy and Responsible AI  \nNIST AI 600-1 \nArtificial Intelligence Risk Management \nFramework: Generative Artificial \nIntelligence Profile \n \n \n \nThis publication is available free of charge from: \nhttps://doi.org/10.6028/NIST.AI.600-1 \n \nJuly 2024 \n \n \n \n \nU.S. Department of Commerce  \nGina M. Raimondo, Secretary \nNational Institute of Standards and Technology  \nLaurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology", "aa9acb4a-aafa-4c99-89f5-ce6a37a36019": "About AI at NIST: The National Institute of Standards and Technology (NIST) develops measurements, \ntechnology, tools, and standards to advance reliable, safe, transparent, explainable, privacy-enhanced, \nand fair arti\ufb01cial intelligence (AI) so that its full commercial and societal bene\ufb01ts can be realized without \nharm to people or the planet. NIST, which has conducted both fundamental and applied work on AI for", "550ce037-301b-49a4-be60-09f0550259a7": "more than a decade, is also helping to ful\ufb01ll the 2023 Executive Order on Safe, Secure, and Trustworthy \nAI. NIST established the U.S. AI Safety Institute and the companion AI Safety Institute Consortium to \ncontinue the e\ufb00orts set in motion by the E.O. to build the science necessary for safe, secure, and \ntrustworthy development and use of AI. \nAcknowledgments: This report was accomplished with the many helpful comments and contributions", "943dd47f-e9b3-41c6-a07b-bc4bb0b539a5": "from the community, including the NIST Generative AI Public Working Group, and NIST sta\ufb00 and guest \nresearchers: Chloe Autio, Jesse Dunietz, Patrick Hall, Shomik Jain, Kamie Roberts, Reva Schwartz, Martin \nStanley, and Elham Tabassi. \nNIST Technical Series Policies \nCopyright, Use, and Licensing Statements \nNIST Technical Series Publication Identifier Syntax \nPublication History \nApproved by the NIST Editorial Review Board on 07-25-2024 \nContact Information \nai-inquiries@nist.gov", "ee48d633-8662-41f0-9371-e7154a2e2682": "Contact Information \nai-inquiries@nist.gov \nNational Institute of Standards and Technology \nAttn: NIST AI Innovation Lab, Information Technology Laboratory \n100 Bureau Drive (Mail Stop 8900) Gaithersburg, MD 20899-8900 \nAdditional Information \nAdditional information about this publication and other NIST AI publications are available at \nhttps://airc.nist.gov/Home. \n \nDisclaimer: Certain commercial entities, equipment, or materials may be identi\ufb01ed in this document in", "487b7e66-7d1d-4d53-a3f1-29a3366e756c": "order to adequately describe an experimental procedure or concept. Such identi\ufb01cation is not intended to \nimply recommendation or endorsement by the National Institute of Standards and Technology, nor is it \nintended to imply that the entities, materials, or equipment are necessarily the best available for the \npurpose. Any mention of commercial, non-pro\ufb01t, academic partners, or their products, or references is", "aae1324d-e572-4a72-9d7b-7a41ea71ca7c": "for information only; it is not intended to imply endorsement or recommendation by any U.S. \nGovernment agency.", "72f64b09-4f01-45c0-8cf7-d632ede75a76": "Table of Contents \n1. \nIntroduction ..............................................................................................................................................1 \n2. \nOverview of Risks Unique to or Exacerbated by GAI .....................................................................2 \n3. \nSuggested Actions to Manage GAI Risks ......................................................................................... 12", "9ce51271-7da0-4a36-8235-adf61c2a7ab2": "Appendix A. Primary GAI Considerations ............................................................................................... 47 \nAppendix B. References ................................................................................................................................ 54", "5874e900-77aa-44f8-8a5c-3057f3f949b5": "1 \n1. \nIntroduction \nThis document is a cross-sectoral pro\ufb01le of and companion resource for the AI Risk Management \nFramework (AI RMF 1.0) for Generative AI,1 pursuant to President Biden\u2019s Executive Order (EO) 14110 on \nSafe, Secure, and Trustworthy Arti\ufb01cial Intelligence.2 The AI RMF was released in January 2023, and is \nintended for voluntary use and to improve the ability of organizations to incorporate trustworthiness", "9d071388-d8dc-409e-a61b-5c2e12bca1da": "considerations into the design, development, use, and evaluation of AI products, services, and systems.  \nA pro\ufb01le is an implementation of the AI RMF functions, categories, and subcategories for a speci\ufb01c \nsetting, application, or technology \u2013 in this case, Generative AI (GAI) \u2013 based on the requirements, risk \ntolerance, and resources of the Framework user. AI RMF pro\ufb01les assist organizations in deciding how to", "4b28f694-8a0d-43c7-b871-4fff513670f9": "best manage AI risks in a manner that is well-aligned with their goals, considers legal/regulatory \nrequirements and best practices, and re\ufb02ects risk management priorities. Consistent with other AI RMF \npro\ufb01les, this pro\ufb01le o\ufb00ers insights into how risk can be managed across various stages of the AI lifecycle \nand for GAI as a technology.  \nAs GAI covers risks of models or applications that can be used across use cases or sectors, this document", "fa28956e-2c9f-436d-9f55-34e940682bf3": "is an AI RMF cross-sectoral pro\ufb01le. Cross-sectoral pro\ufb01les can be used to govern, map, measure, and \nmanage risks associated with activities or business processes common across sectors, such as the use of \nlarge language models (LLMs), cloud-based services, or acquisition. \nThis document de\ufb01nes risks that are novel to or exacerbated by the use of GAI. After introducing and \ndescribing these risks, the document provides a set of suggested actions to help organizations govern,", "8abf64cb-6829-47ad-acd2-94ce13043a0c": "map, measure, and manage these risks. \n \n \n1 EO 14110 de\ufb01nes Generative AI as \u201cthe class of AI models that emulate the structure and characteristics of input \ndata in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital \ncontent.\u201d While not all GAI is derived from foundation models, for purposes of this document, GAI generally refers", "7f9f4b19-3911-44bb-b55b-a2105267cb97": "to generative foundation models. The foundation model subcategory of \u201cdual-use foundation models\u201d is de\ufb01ned by \nEO 14110 as \u201can AI model that is trained on broad data; generally uses self-supervision; contains at least tens of \nbillions of parameters; is applicable across a wide range of contexts.\u201d  \n2 This pro\ufb01le was developed per Section 4.1(a)(i)(A) of EO 14110, which directs the Secretary of Commerce, acting", "5559cac5-3fcb-4945-a45e-1fb176a99a0b": "through the Director of the National Institute of Standards and Technology (NIST), to develop a companion \nresource to the AI RMF, NIST AI 100\u20131, for generative AI.", "e94266c0-d458-4eec-b13e-99fd2c13f854": "2 \nThis work was informed by public feedback and consultations with diverse stakeholder groups as part of NIST\u2019s \nGenerative AI Public Working Group (GAI PWG). The GAI PWG was an open, transparent, and collaborative \nprocess, facilitated via a virtual workspace, to obtain multistakeholder input on GAI risk management and to \ninform NIST\u2019s approach. \nThe focus of the GAI PWG was limited to four primary considerations relevant to GAI: Governance, Content", "6f983242-11d0-490b-8b48-6a45970de66a": "Provenance, Pre-deployment Testing, and Incident Disclosure (further described in Appendix A). As such, the \nsuggested actions in this document primarily address these considerations. \nFuture revisions of this pro\ufb01le will include additional AI RMF subcategories, risks, and suggested actions based \non additional considerations of GAI as the space evolves and empirical evidence indicates additional risks. A", "abc40c26-5325-44cb-a03c-698039cc5aa6": "glossary of terms pertinent to GAI risk management will be developed and hosted on NIST\u2019s Trustworthy & \nResponsible AI Resource Center (AIRC), and added to The Language of Trustworthy AI: An In-Depth Glossary of \nTerms. \nThis document was also informed by public comments and consultations from several Requests for Information. \n \n2. \nOverview of Risks Unique to or Exacerbated by GAI \nIn the context of the AI RMF, risk refers to the composite measure of an event\u2019s probability (or", "b54de951-a0ed-4a9b-8c90-2432c688cc7c": "likelihood) of occurring and the magnitude or degree of the consequences of the corresponding event. \nSome risks can be assessed as likely to materialize in a given context, particularly those that have been \nempirically demonstrated in similar contexts. Other risks may be unlikely to materialize in a given \ncontext, or may be more speculative and therefore uncertain. \nAI risks can di\ufb00er from or intensify traditional software risks. Likewise, GAI can exacerbate existing AI", "00d0dca3-14b2-450d-939f-4f63c666f867": "risks, and creates unique risks. GAI risks can vary along many dimensions: \n\u2022 \nStage of the AI lifecycle: Risks can arise during design, development, deployment, operation, \nand/or decommissioning. \n\u2022 \nScope: Risks may exist at individual model or system levels, at the application or implementation \nlevels (i.e., for a speci\ufb01c use case), or at the ecosystem level \u2013 that is, beyond a single system or \norganizational context. Examples of the latter include the expansion of \u201calgorithmic", "7b45ff07-9ccf-404a-a050-ef7b7cf39261": "monocultures,3\u201d resulting from repeated use of the same model, or impacts on access to \nopportunity, labor markets, and the creative economies.4 \n\u2022 \nSource of risk: Risks may emerge from factors related to the design, training, or operation of the \nGAI model itself, stemming in some cases from GAI model or system inputs, and in other cases, \nfrom GAI system outputs. Many GAI risks, however, originate from human behavior, including", "f0871f37-b49d-4a30-a282-f5e5e43b922a": "3 \u201cAlgorithmic monocultures\u201d refers to the phenomenon in which repeated use of the same model or algorithm in \nconsequential decision-making settings like employment and lending can result in increased susceptibility by \nsystems to correlated failures (like unexpected shocks), due to multiple actors relying on the same algorithm.  \n4 Many studies have projected the impact of AI on the workforce and labor markets. Fewer studies have examined", "0983b5d5-e480-4563-a3cb-eb4234b92391": "the impact of GAI on the labor market, though some industry surveys indicate that that both employees and \nemployers are pondering this disruption.", "063dc893-dd57-4d89-ab09-8285c52dc21a": "3 \nthe abuse, misuse, and unsafe repurposing by humans (adversarial or not), and others result \nfrom interactions between a human and an AI system.  \n\u2022 \nTime scale: GAI risks may materialize abruptly or across extended periods. Examples include \nimmediate (and/or prolonged) emotional harm and potential risks to physical safety due to the \ndistribution of harmful deepfake images, or the long-term e\ufb00ect of disinformation on societal \ntrust in public institutions.", "ff043860-2028-49e4-92ea-88ab2948a849": "trust in public institutions. \nThe presence of risks and where they fall along the dimensions above will vary depending on the \ncharacteristics of the GAI model, system, or use case at hand. These characteristics include but are not \nlimited to GAI model or system architecture, training mechanisms and libraries, data types used for \ntraining or \ufb01ne-tuning, levels of model access or availability of model weights, and application or use \ncase context.", "b96c24fb-84ec-4658-81aa-f57fdd47baa1": "case context. \nOrganizations may choose to tailor how they measure GAI risks based on these characteristics. They may \nadditionally wish to allocate risk management resources relative to the severity and likelihood of \nnegative impacts, including where and how these risks manifest, and their direct and material impacts \nharms in the context of GAI use. Mitigations for model or system level risks may di\ufb00er from mitigations \nfor use-case or ecosystem level risks.", "b5bcc0bd-0a35-4b4f-acc3-1cacaa6c36d0": "for use-case or ecosystem level risks. \nImportantly, some GAI risks are unknown, and are therefore di\ufb03cult to properly scope or evaluate given \nthe uncertainty about potential GAI scale, complexity, and capabilities. Other risks may be known but \ndi\ufb03cult to estimate given the wide range of GAI stakeholders, uses, inputs, and outputs. Challenges with \nrisk estimation are aggravated by a lack of visibility into GAI training data, and the generally immature", "deaf0ecf-7a3a-4371-8645-82479a904fd7": "state of the science of AI measurement and safety today. This document focuses on risks for which there \nis an existing empirical evidence base at the time this pro\ufb01le was written; for example, speculative risks \nthat may potentially arise in more advanced, future GAI systems are not considered. Future updates may \nincorporate additional risks or provide further details on the risks identi\ufb01ed below.", "959b70c3-615b-4207-a4f9-ce9c012cace9": "To guide organizations in identifying and managing GAI risks, a set of risks unique to or exacerbated by \nthe development and use of GAI are de\ufb01ned below.5 Each risk is labeled according to the outcome, \nobject, or source of the risk (i.e., some are risks \u201cto\u201d a subject or domain and others are risks \u201cof\u201d or \n\u201cfrom\u201d an issue or theme). These risks provide a lens through which organizations can frame and execute", "bf7eaca6-e10d-44ba-9019-ca34ac8cb519": "risk management e\ufb00orts. To help streamline risk management e\ufb00orts, each risk is mapped in Section 3 \n(as well as in tables in Appendix B) to relevant Trustworthy AI Characteristics identi\ufb01ed in the AI RMF.  \n \n \n5 These risks can be further categorized by organizations depending on their unique approaches to risk de\ufb01nition \nand management. One possible way to further categorize these risks, derived in part from the UK\u2019s International", "235c8567-33b0-42f6-a403-287a1ff63bbb": "Scienti\ufb01c Report on the Safety of Advanced AI, could be: 1) Technical / Model risks (or risk from malfunction): \nConfabulation; Dangerous or Violent Recommendations; Data Privacy; Value Chain and Component Integration; \nHarmful Bias, and Homogenization; 2) Misuse by humans (or malicious use): CBRN Information or Capabilities; \nData Privacy; Human-AI Con\ufb01guration; Obscene, Degrading, and/or Abusive Content; Information Integrity;", "6a24b211-7d0c-4d38-8749-c9b4f92f66fa": "Information Security; 3) Ecosystem / societal risks (or systemic risks): Data Privacy; Environmental; Intellectual \nProperty. We also note that some risks are cross-cutting between these categories.", "710217a6-641a-470e-9bbd-5a5f26561649": "4 \n1. CBRN Information or Capabilities: Eased access to or synthesis of materially nefarious \ninformation or design capabilities related to chemical, biological, radiological, or nuclear (CBRN) \nweapons or other dangerous materials or agents. \n2. Confabulation: The production of con\ufb01dently stated but erroneous or false content (known \ncolloquially as \u201challucinations\u201d or \u201cfabrications\u201d) by which users may be misled or deceived.6", "3f3e0458-e0a4-4d4a-bf0b-434d43250212": "3. Dangerous, Violent, or Hateful Content: Eased production of and access to violent, inciting, \nradicalizing, or threatening content as well as recommendations to carry out self-harm or \nconduct illegal activities. Includes di\ufb03culty controlling public exposure to hateful and disparaging \nor stereotyping content. \n4. Data Privacy: Impacts due to leakage and unauthorized use, disclosure, or de-anonymization of", "220a4da5-61a1-4c89-91a6-a920387912ca": "biometric, health, location, or other personally identi\ufb01able information or sensitive data.7 \n5. Environmental Impacts: Impacts due to high compute resource utilization in training or \noperating GAI models, and related outcomes that may adversely impact ecosystems.  \n6. Harmful Bias or Homogenization: Ampli\ufb01cation and exacerbation of historical, societal, and \nsystemic biases; performance disparities8 between sub-groups or languages, possibly due to", "7eda0beb-368a-47b5-8acf-826b359c4ee4": "non-representative training data, that result in discrimination, ampli\ufb01cation of biases, or \nincorrect presumptions about performance; undesired homogeneity that skews system or model \noutputs, which may be erroneous, lead to ill-founded decision-making, or amplify harmful \nbiases.  \n7. Human-AI Con\ufb01guration: Arrangements of or interactions between a human and an AI system \nwhich can result in the human inappropriately anthropomorphizing GAI systems or experiencing", "4dda00bc-6e6a-4c0d-8bee-034d463ac011": "algorithmic aversion, automation bias, over-reliance, or emotional entanglement with GAI \nsystems. \n8. Information Integrity: Lowered barrier to entry to generate and support the exchange and \nconsumption of content which may not distinguish fact from opinion or \ufb01ction or acknowledge \nuncertainties, or could be leveraged for large-scale dis- and mis-information campaigns. \n9. Information Security: Lowered barriers for o\ufb00ensive cyber capabilities, including via automated", "66f65809-9f20-4318-83e6-962e6b43827a": "discovery and exploitation of vulnerabilities to ease hacking, malware, phishing, o\ufb00ensive cyber \n \n \n6 Some commenters have noted that the terms \u201challucination\u201d and \u201cfabrication\u201d anthropomorphize GAI, which \nitself is a risk related to GAI systems as it can inappropriately attribute human characteristics to non-human \nentities.  \n7 What is categorized as sensitive data or sensitive PII can be highly contextual based on the nature of the", "ee9a3aac-893a-49eb-ae9c-ebbd73ddf155": "information, but examples of sensitive information include information that relates to an information subject\u2019s \nmost intimate sphere, including political opinions, sex life, or criminal convictions.  \n8 The notion of harm presumes some baseline scenario that the harmful factor (e.g., a GAI model) makes worse. \nWhen the mechanism for potential harm is a disparity between groups, it can be di\ufb03cult to establish what the", "de5ad05c-3d78-4d81-b484-42915bc61166": "most appropriate baseline is to compare against, which can result in divergent views on when a disparity between \nAI behaviors for di\ufb00erent subgroups constitutes a harm. In discussing harms from disparities such as biased \nbehavior, this document highlights examples where someone\u2019s situation is worsened relative to what it would have \nbeen in the absence of any AI system, making the outcome unambiguously a harm of the system.", "51e13acd-c5d0-4bd1-b1bd-cada999156f8": "5 \noperations, or other cyberattacks; increased attack surface for targeted cyberattacks, which may \ncompromise a system\u2019s availability or the con\ufb01dentiality or integrity of training data, code, or \nmodel weights.  \n10. Intellectual Property: Eased production or replication of alleged copyrighted, trademarked, or \nlicensed content without authorization (possibly in situations which do not fall under fair use); \neased exposure of trade secrets; or plagiarism or illegal replication.", "825ee573-c2b5-4c34-9195-ca4e7bb016b3": "11. Obscene, Degrading, and/or Abusive Content: Eased production of and access to obscene, \ndegrading, and/or abusive imagery which can cause harm, including synthetic child sexual abuse \nmaterial (CSAM), and nonconsensual intimate images (NCII) of adults. \n12. Value Chain and Component Integration: Non-transparent or untraceable integration of \nupstream third-party components, including data that has been improperly obtained or not", "8ef7c298-b94b-4240-ad46-77258e83661b": "processed and cleaned due to increased automation from GAI; improper supplier vetting across \nthe AI lifecycle; or other issues that diminish transparency or accountability for downstream \nusers. \n2.1. CBRN Information or Capabilities \nIn the future, GAI may enable malicious actors to more easily access CBRN weapons and/or relevant \nknowledge, information, materials, tools, or technologies that could be misused to assist in the design,", "8721ddd9-2ab3-4b0e-a5d1-47110817bfa8": "development, production, or use of CBRN weapons or other dangerous materials or agents. While \nrelevant biological and chemical threat knowledge and information is often publicly accessible, LLMs \ncould facilitate its analysis or synthesis, particularly by individuals without formal scienti\ufb01c training or \nexpertise.  \nRecent research on this topic found that LLM outputs regarding biological threat creation and attack", "303da3b9-03fe-41bc-9ca0-9212ed9dd1e5": "planning provided minimal assistance beyond traditional search engine queries, suggesting that state-of-\nthe-art LLMs at the time these studies were conducted do not substantially increase the operational \nlikelihood of such an attack. The physical synthesis development, production, and use of chemical or \nbiological agents will continue to require both applicable expertise and supporting materials and", "e20cb8a4-d241-400a-ac14-88a80d423155": "infrastructure. The impact of GAI on chemical or biological agent misuse will depend on what the key \nbarriers for malicious actors are (e.g., whether information access is one such barrier), and how well GAI \ncan help actors address those barriers.  \nFurthermore, chemical and biological design tools (BDTs) \u2013 highly specialized AI systems trained on \nscienti\ufb01c data that aid in chemical and biological design \u2013 may augment design capabilities in chemistry", "6dbf71a1-b0e1-4a5c-90cd-6a857b861ebf": "and biology beyond what text-based LLMs are able to provide. As these models become more \ne\ufb03cacious, including for bene\ufb01cial uses, it will be important to assess their potential to be used for \nharm, such as the ideation and design of novel harmful chemical or biological agents.  \nWhile some of these described capabilities lie beyond the reach of existing GAI tools, ongoing \nassessments of this risk would be enhanced by monitoring both the ability of AI tools to facilitate CBRN", "44a9f4a8-1ec9-4213-95fc-a4deef9f2951": "weapons planning and GAI systems\u2019 connection or access to relevant data and tools. \nTrustworthy AI Characteristic: Safe, Explainable and Interpretable", "c05cd88e-eb49-4ce9-8556-962d8bfeb9b3": "6 \n2.2. Confabulation \n\u201cConfabulation\u201d refers to a phenomenon in which GAI systems generate and con\ufb01dently present \nerroneous or false content in response to prompts. Confabulations also include generated outputs that \ndiverge from the prompts or other input or that contradict previously generated statements in the same \ncontext. These phenomena are colloquially also referred to as \u201challucinations\u201d or \u201cfabrications.\u201d", "7bff0eda-6a82-4128-ac77-5b63c7856257": "Confabulations can occur across GAI outputs and contexts.9,10 Confabulations are a natural result of the \nway generative models are designed: they generate outputs that approximate the statistical distribution \nof their training data; for example, LLMs predict the next token or word in a sentence or phrase. While \nsuch statistical prediction can produce factually accurate and consistent outputs, it can also produce", "a21c4079-5ad3-42ef-b2f7-9b9db51aea43": "outputs that are factually inaccurate or internally inconsistent. This dynamic is particularly relevant when \nit comes to open-ended prompts for long-form responses and in domains which require highly \ncontextual and/or domain expertise.  \nRisks from confabulations may arise when users believe false content \u2013 often due to the con\ufb01dent nature \nof the response \u2013 leading users to act upon or promote the false information. This poses a challenge for", "754e96d8-afc5-4736-b1e4-223822f6bf72": "many real-world applications, such as in healthcare, where a confabulated summary of patient \ninformation reports could cause doctors to make incorrect diagnoses and/or recommend the wrong \ntreatments. Risks of confabulated content may be especially important to monitor when integrating GAI \ninto applications involving consequential decision making. \nGAI outputs may also include confabulated logic or citations that purport to justify or explain the", "ed823956-27d0-445b-ab4e-3c3ff755dda3": "system\u2019s answer, which may further mislead humans into inappropriately trusting the system\u2019s output. \nFor instance, LLMs sometimes provide logical steps for how they arrived at an answer even when the \nanswer itself is incorrect. Similarly, an LLM could falsely assert that it is human or has human traits, \npotentially deceiving humans into believing they are speaking with another human. \nThe extent to which humans can be deceived by LLMs, the mechanisms by which this may occur, and the", "9374b6bc-4cf9-4740-9394-f29308dc7daf": "potential risks from adversarial prompting of such behavior are emerging areas of study. Given the wide \nrange of downstream impacts of GAI, it is di\ufb03cult to estimate the downstream scale and impact of \nconfabulations. \nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Valid and Reliable, Explainable \nand Interpretable \n2.3. Dangerous, Violent, or Hateful Content \nGAI systems can produce content that is inciting, radicalizing, or threatening, or that glori\ufb01es violence,", "8afc75ca-7cdf-4c1d-9902-abe6652c5ffb": "with greater ease and scale than other technologies. LLMs have been reported to generate dangerous or \nviolent recommendations, and some models have generated actionable instructions for dangerous or \n \n \n9 Confabulations of falsehoods are most commonly a problem for text-based outputs; for audio, image, or video \ncontent, creative generation of non-factual content can be a desired behavior.", "732f2bb0-58d3-4807-87db-a0247257fd3d": "10 For example, legal confabulations have been shown to be pervasive in current state-of-the-art LLMs. See also, \ne.g.,", "4407d785-3ecc-4783-8ba3-c0016d39f133": "7 \nunethical behavior. Text-to-image models also make it easy to create images that could be used to \npromote dangerous or violent messages. Similar concerns are present for other GAI media, including \nvideo and audio. GAI may also produce content that recommends self-harm or criminal/illegal activities.  \nMany current systems restrict model outputs to limit certain content or in response to certain prompts,", "b8c5f583-62c0-414c-90db-78f372db9420": "but this approach may still produce harmful recommendations in response to other less-explicit, novel \nprompts (also relevant to CBRN Information or Capabilities, Data Privacy, Information Security, and \nObscene, Degrading and/or Abusive Content). Crafting such prompts deliberately is known as \n\u201cjailbreaking,\u201d or, manipulating prompts to circumvent output controls. Limitations of GAI systems can be", "275f6eeb-c845-4869-8efb-7bc0d5a781da": "harmful or dangerous in certain contexts. Studies have observed that users may disclose mental health \nissues in conversations with chatbots \u2013 and that users exhibit negative reactions to unhelpful responses \nfrom these chatbots during situations of distress. \nThis risk encompasses di\ufb03culty controlling creation of and public exposure to o\ufb00ensive or hateful \nlanguage, and denigrating or stereotypical content generated by AI. This kind of speech may contribute", "7422e046-726e-4192-8493-b472ddcf6644": "to downstream harm such as fueling dangerous or violent behaviors. The spread of denigrating or \nstereotypical content can also further exacerbate representational harms (see Harmful Bias and \nHomogenization below).  \nTrustworthy AI Characteristics: Safe, Secure and Resilient \n2.4. Data Privacy \nGAI systems raise several risks to privacy. GAI system training requires large volumes of data, which in", "ae410d2f-dd72-43ad-bafb-bbb0ce9f6582": "some cases may include personal data. The use of personal data for GAI training raises risks to widely \naccepted privacy principles, including to transparency, individual participation (including consent), and \npurpose speci\ufb01cation. For example, most model developers do not disclose speci\ufb01c data sources on \nwhich models were trained, limiting user awareness of whether personally identi\ufb01ably information (PII) \nwas trained on and, if so, how it was collected.", "bd51d60d-ad70-4558-a4bf-2d870d7ab9d5": "Models may leak, generate, or correctly infer sensitive information about individuals. For example, \nduring adversarial attacks, LLMs have revealed sensitive information (from the public domain) that was \nincluded in their training data. This problem has been referred to as data memorization, and may pose \nexacerbated privacy risks even for data present only in a small number of training samples.", "3776154c-db39-47ce-889e-17b39503e8a4": "In addition to revealing sensitive information in GAI training data, GAI models may be able to correctly \ninfer PII or sensitive data that was not in their training data nor disclosed by the user by stitching \ntogether information from disparate sources. These inferences can have negative impact on an individual \neven if the inferences are not accurate (e.g., confabulations), and especially if they reveal information", "eafd0478-db38-4d96-a135-924cbf8955d6": "that the individual considers sensitive or that is used to disadvantage or harm them. \nBeyond harms from information exposure (such as extortion or dignitary harm), wrong or inappropriate \ninferences of PII can contribute to downstream or secondary harmful impacts. For example, predictive \ninferences made by GAI models based on PII or protected attributes can contribute to adverse decisions, \nleading to representational or allocative harms to individuals or groups (see Harmful Bias and", "98aa4f70-c0a9-4466-8fc4-7aa110e00b21": "Homogenization below).", "a62c0872-5bec-4b9a-8860-2ce67167a2da": "8 \nTrustworthy AI Characteristics: Accountable and Transparent, Privacy Enhanced, Safe, Secure and \nResilient \n2.5. Environmental Impacts \nTraining, maintaining, and operating (running inference on) GAI systems are resource-intensive activities, \nwith potentially large energy and environmental footprints. Energy and carbon emissions vary based on \nwhat is being done with the GAI model (i.e., pre-training, \ufb01ne-tuning, inference), the modality of the", "6c61a3cd-244e-466a-aba7-280ff802f576": "content, hardware used, and type of task or application. \nCurrent estimates suggest that training a single transformer LLM can emit as much carbon as 300 round-\ntrip \ufb02ights between San Francisco and New York. In a study comparing energy consumption and carbon \nemissions for LLM inference, generative tasks (e.g., text summarization) were found to be more energy- \nand carbon-intensive than discriminative or non-generative tasks (e.g., text classi\ufb01cation).", "244307c9-f8da-490e-b1a0-6f379b71abac": "Methods for creating smaller versions of trained models, such as model distillation or compression, \ncould reduce environmental impacts at inference time, but training and tuning such models may still \ncontribute to their environmental impacts. Currently there is no agreed upon method to estimate \nenvironmental impacts from GAI.  \nTrustworthy AI Characteristics: Accountable and Transparent, Safe \n2.6. Harmful Bias and Homogenization", "9f9e5712-2858-4885-b1f9-2a3137788579": "2.6. Harmful Bias and Homogenization \nBias exists in many forms and can become ingrained in automated systems. AI systems, including GAI \nsystems, can increase the speed and scale at which harmful biases manifest and are acted upon, \npotentially perpetuating and amplifying harms to individuals, groups, communities, organizations, and \nsociety. For example, when prompted to generate images of CEOs, doctors, lawyers, and judges, current", "72c43dda-7942-4db5-8ef2-79b59728bfb5": "text-to-image models underrepresent women and/or racial minorities, and people with disabilities. \nImage generator models have also produced biased or stereotyped output for various demographic \ngroups and have di\ufb03culty producing non-stereotyped content even when the prompt speci\ufb01cally \nrequests image features that are inconsistent with the stereotypes. Harmful bias in GAI models, which \nmay stem from their training data, can also cause representational harms or perpetuate or exacerbate", "0f64cc85-1f40-4301-a0cf-62da43cbe24c": "bias based on race, gender, disability, or other protected classes.  \nHarmful bias in GAI systems can also lead to harms via disparities between how a model performs for \ndi\ufb00erent subgroups or languages (e.g., an LLM may perform less well for non-English languages or \ncertain dialects). Such disparities can contribute to discriminatory decision-making or ampli\ufb01cation of \nexisting societal biases. In addition, GAI systems may be inappropriately trusted to perform similarly", "676a914e-0b98-48ef-b77e-fe3d5747e9c4": "across all subgroups, which could leave the groups facing underperformance with worse outcomes than \nif no GAI system were used. Disparate or reduced performance for lower-resource languages also \npresents challenges to model adoption, inclusion, and accessibility, and may make preservation of \nendangered languages more di\ufb03cult if GAI systems become embedded in everyday processes that would \notherwise have been opportunities to use these languages.", "e86e66d2-488c-4d6d-b2a3-3c8aee17177b": "Bias is mutually reinforcing with the problem of undesired homogenization, in which GAI systems \nproduce skewed distributions of outputs that are overly uniform (for example, repetitive aesthetic styles", "56960bb9-af76-4b81-8361-4260a51997c0": "9 \nand reduced content diversity). Overly homogenized outputs can themselves be incorrect, or they may \nlead to unreliable decision-making or amplify harmful biases. These phenomena can \ufb02ow from \nfoundation models to downstream models and systems, with the foundation models acting as \n\u201cbottlenecks,\u201d or single points of failure.  \nOverly homogenized content can contribute to \u201cmodel collapse.\u201d Model collapse can occur when model", "6433266f-0590-485c-91c0-dae0ba7d2913": "training over-relies on synthetic data, resulting in data points disappearing from the distribution of the \nnew model\u2019s outputs. In addition to threatening the robustness of the model overall, model collapse \ncould lead to homogenized outputs, including by amplifying any homogenization from the model used to \ngenerate the synthetic training data. \nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Valid and Reliable \n2.7. Human-AI Con\ufb01guration", "c44383a3-9e05-491a-8295-d8efabb367ee": "2.7. Human-AI Con\ufb01guration \nGAI system use can involve varying risks of miscon\ufb01gurations and poor interactions between a system \nand a human who is interacting with it. Humans bring their unique perspectives, experiences, or domain-\nspeci\ufb01c expertise to interactions with AI systems but may not have detailed knowledge of AI systems and \nhow they work. As a result, human experts may be unnecessarily \u201caverse\u201d to GAI systems, and thus \ndeprive themselves or others of GAI\u2019s bene\ufb01cial uses.", "666008aa-55c1-4df2-aeeb-e7e45c9f165a": "Conversely, due to the complexity and increasing reliability of GAI technology, over time, humans may \nover-rely on GAI systems or may unjusti\ufb01ably perceive GAI content to be of higher quality than that \nproduced by other sources. This phenomenon is an example of automation bias, or excessive deference \nto automated systems. Automation bias can exacerbate other risks of GAI, such as risks of confabulation \nor risks of bias or homogenization.", "45566d45-9b1c-4391-8c00-8173dfc6684e": "or risks of bias or homogenization. \nThere may also be concerns about emotional entanglement between humans and GAI systems, which \ncould lead to negative psychological impacts. \nTrustworthy AI Characteristics: Accountable and Transparent, Explainable and Interpretable, Fair with \nHarmful Bias Managed, Privacy Enhanced, Safe, Valid and Reliable \n2.8. Information Integrity \nInformation integrity describes the \u201cspectrum of information and associated patterns of its creation,", "a2f14943-ba1b-4562-9b85-8519a4d4a92c": "exchange, and consumption in society.\u201d High-integrity information can be trusted; \u201cdistinguishes fact \nfrom \ufb01ction, opinion, and inference; acknowledges uncertainties; and is transparent about its level of \nvetting. This information can be linked to the original source(s) with appropriate evidence. High-integrity \ninformation is also accurate and reliable, can be veri\ufb01ed and authenticated, has a clear chain of custody, \nand creates reasonable expectations about when its validity may expire.\u201d11", "24525d3d-7bf0-4601-b403-efa9e17398cd": "11 This de\ufb01nition of information integrity is derived from the 2022 White House Roadmap for Researchers on \nPriorities Related to Information Integrity Research and Development.", "c2f3e1a5-9449-436d-bb39-4a776a66fc8b": "10 \nGAI systems can ease the unintentional production or dissemination of false, inaccurate, or misleading \ncontent (misinformation) at scale, particularly if the content stems from confabulations.  \nGAI systems can also ease the deliberate production or dissemination of false or misleading information \n(disinformation) at scale, where an actor has the explicit intent to deceive or cause harm to others. Even \nvery subtle changes to text or images can manipulate human and machine perception.", "1b5a542c-42e6-47fe-b108-42cb5107ff95": "Similarly, GAI systems could enable a higher degree of sophistication for malicious actors to produce \ndisinformation that is targeted towards speci\ufb01c demographics. Current and emerging multimodal models \nmake it possible to generate both text-based disinformation and highly realistic \u201cdeepfakes\u201d \u2013 that is, \nsynthetic audiovisual content and photorealistic images.12 Additional disinformation threats could be \nenabled by future GAI models trained on new data modalities.", "c7ab2e6e-3140-4080-a980-638374a17ee2": "Disinformation and misinformation \u2013 both of which may be facilitated by GAI \u2013 may erode public trust in \ntrue or valid evidence and information, with downstream e\ufb00ects. For example, a synthetic image of a \nPentagon blast went viral and brie\ufb02y caused a drop in the stock market. Generative AI models can also \nassist malicious actors in creating compelling imagery and propaganda to support disinformation", "95e6f848-d25e-404b-abc9-0047637a2f69": "campaigns, which may not be photorealistic, but could enable these campaigns to gain more reach and \nengagement on social media platforms. Additionally, generative AI models can assist malicious actors in \ncreating fraudulent content intended to impersonate others. \nTrustworthy AI Characteristics: Accountable and Transparent, Safe, Valid and Reliable, Interpretable and \nExplainable \n2.9. Information Security", "a413be5b-5112-419d-b575-1b59e1df2509": "Explainable \n2.9. Information Security \nInformation security for computer systems and data is a mature \ufb01eld with widely accepted and \nstandardized practices for o\ufb00ensive and defensive cyber capabilities. GAI-based systems present two \nprimary information security risks: GAI could potentially discover or enable new cybersecurity risks by \nlowering the barriers for or easing automated exercise of o\ufb00ensive capabilities; simultaneously, it", "8e452509-7625-440b-b1b9-004d9436a01b": "expands the available attack surface, as GAI itself is vulnerable to attacks like prompt injection or data \npoisoning.  \nO\ufb00ensive cyber capabilities advanced by GAI systems may augment cybersecurity attacks such as \nhacking, malware, and phishing. Reports have indicated that LLMs are already able to discover some \nvulnerabilities in systems (hardware, software, data) and write code to exploit them. Sophisticated threat", "bf005bac-9bdb-4355-8074-e9a3bd763335": "actors might further these risks by developing GAI-powered security co-pilots for use in several parts of \nthe attack chain, including informing attackers on how to proactively evade threat detection and escalate \nprivileges after gaining system access. \nInformation security for GAI models and systems also includes maintaining availability of the GAI system \nand the integrity and (when applicable) the con\ufb01dentiality of the GAI code, training data, and model", "0d87c27b-7f3d-4683-937e-a8f2ea561d44": "weights. To identify and secure potential attack points in AI systems or speci\ufb01c components of the AI \n \n \n12 See also https://doi.org/10.6028/NIST.AI.100-4, to be published.", "319211d5-0a90-4752-9d0a-a6df1c4ead2f": "11 \nvalue chain (e.g., data inputs, processing, GAI training, or deployment environments), conventional \ncybersecurity practices may need to adapt or evolve. \nFor instance, prompt injection involves modifying what input is provided to a GAI system so that it \nbehaves in unintended ways. In direct prompt injections, attackers might craft malicious prompts and \ninput them directly to a GAI system, with a variety of downstream negative consequences to", "be8dd8de-3bef-4876-a051-9e52582a7af0": "interconnected systems. Indirect prompt injection attacks occur when adversaries remotely (i.e., without \na direct interface) exploit LLM-integrated applications by injecting prompts into data likely to be \nretrieved. Security researchers have already demonstrated how indirect prompt injections can exploit \nvulnerabilities by stealing proprietary data or running malicious code remotely on a machine. Merely", "d6fad9d7-720b-4d3e-8f47-ada473a963f0": "querying a closed production model can elicit previously undisclosed information about that model. \nAnother cybersecurity risk to GAI is data poisoning, in which an adversary compromises a training \ndataset used by a model to manipulate its outputs or operation. Malicious tampering with data or parts \nof the model could exacerbate risks associated with GAI system outputs. \nTrustworthy AI Characteristics: Privacy Enhanced, Safe, Secure and Resilient, Valid and Reliable \n2.10.", "eb8a8d51-2024-4590-8a5f-a4504655b5c7": "2.10. \nIntellectual Property \nIntellectual property risks from GAI systems may arise where the use of copyrighted works is not a fair \nuse under the fair use doctrine. If a GAI system\u2019s training data included copyrighted material, GAI \noutputs displaying instances of training data memorization (see Data Privacy above) could infringe on \ncopyright. \nHow GAI relates to copyright, including the status of generated content that is similar to but does not", "3f0f251e-b854-4063-8a98-3d670764553f": "strictly copy work protected by copyright, is currently being debated in legal fora. Similar discussions are \ntaking place regarding the use or emulation of personal identity, likeness, or voice without permission.  \nTrustworthy AI Characteristics: Accountable and Transparent, Fair with Harmful Bias Managed, Privacy \nEnhanced  \n2.11. \nObscene, Degrading, and/or Abusive Content \nGAI can ease the production of and access to illegal non-consensual intimate imagery (NCII) of adults,", "31f40290-c4cb-4730-9669-743e6f36a08e": "and/or child sexual abuse material (CSAM). GAI-generated obscene, abusive or degrading content can \ncreate privacy, psychological and emotional, and even physical harms, and in some cases may be illegal.  \nGenerated explicit or obscene AI content may include highly realistic \u201cdeepfakes\u201d of real individuals, \nincluding children. The spread of this kind of material can have downstream negative consequences: in", "10694483-2f00-420c-82dc-99dbd771bc37": "the context of CSAM, even if the generated images do not resemble speci\ufb01c individuals, the prevalence \nof such images can divert time and resources from e\ufb00orts to \ufb01nd real-world victims. Outside of CSAM, \nthe creation and spread of NCII disproportionately impacts women and sexual minorities, and can have \nsubsequent negative consequences including decline in overall mental health, substance abuse, and \neven suicidal thoughts.", "38ce2a8c-7cc7-49ed-99ca-ebec9fec8c61": "even suicidal thoughts.  \nData used for training GAI models may unintentionally include CSAM and NCII. A recent report noted \nthat several commonly used GAI training datasets were found to contain hundreds of known images of", "68f00fa6-8f6b-4b90-a6f9-1b42a7d167f8": "12 \nCSAM. Even when trained on \u201cclean\u201d data, increasingly capable GAI models can synthesize or produce \nsynthetic NCII and CSAM. Websites, mobile apps, and custom-built models that generate synthetic NCII \nhave moved from niche internet forums to mainstream, automated, and scaled online businesses.  \nTrustworthy AI Characteristics: Fair with Harmful Bias Managed, Safe, Privacy Enhanced \n2.12. \nValue Chain and Component Integration", "886b1d6c-95f8-4364-b362-44119e9be5c2": "2.12. \nValue Chain and Component Integration \nGAI value chains involve many third-party components such as procured datasets, pre-trained models, \nand software libraries. These components might be improperly obtained or not properly vetted, leading \nto diminished transparency or accountability for downstream users. While this is a risk for traditional AI \nsystems and some other digital technologies, the risk is exacerbated for GAI due to the scale of the", "e4802347-16ce-4e0f-8b38-04370de361e0": "training data, which may be too large for humans to vet; the di\ufb03culty of training foundation models, \nwhich leads to extensive reuse of limited numbers of models; and the extent to which GAI may be \nintegrated into other devices and services. As GAI systems often involve many distinct third-party \ncomponents and data sources, it may be di\ufb03cult to attribute issues in a system\u2019s behavior to any one of \nthese sources.", "d70ce55f-d989-42f0-b182-76fd4d6fa9f8": "these sources. \nErrors in third-party GAI components can also have downstream impacts on accuracy and robustness. \nFor example, test datasets commonly used to benchmark or validate models can contain label errors. \nInaccuracies in these labels can impact the \u201cstability\u201d or robustness of these benchmarks, which many \nGAI practitioners consider during the model selection process.  \nTrustworthy AI Characteristics: Accountable and Transparent, Explainable and Interpretable, Fair with", "536515ab-da06-47a5-bd1d-702b0ec0456d": "Harmful Bias Managed, Privacy Enhanced, Safe, Secure and Resilient, Valid and Reliable \n3. \nSuggested Actions to Manage GAI Risks \nThe following suggested actions target risks unique to or exacerbated by GAI. \nIn addition to the suggested actions below, AI risk management activities and actions set forth in the AI \nRMF 1.0 and Playbook are already applicable for managing GAI risks. Organizations are encouraged to", "c3d59ec2-9f5a-4dbc-808c-9f11c13f474b": "apply the activities suggested in the AI RMF and its Playbook when managing the risk of GAI systems.  \nImplementation of the suggested actions will vary depending on the type of risk, characteristics of GAI \nsystems, stage of the GAI lifecycle, and relevant AI actors involved.  \nSuggested actions to manage GAI risks can be found in the tables below: \n\u2022 \nThe suggested actions are organized by relevant AI RMF subcategories to streamline these \nactivities alongside implementation of the AI RMF.", "017d1e2b-31d2-4ab5-b7a8-ca399b302309": "\u2022 \nNot every subcategory of the AI RMF is included in this document.13 Suggested actions are \nlisted for only some subcategories.  \n \n \n13 As this document was focused on the GAI PWG e\ufb00orts and primary considerations (see Appendix A), AI RMF \nsubcategories not addressed here may be added later.", "6a8a0cef-e35d-45af-9cbc-d9203b2f4295": "13 \n\u2022 \nNot every suggested action applies to every AI Actor14 or is relevant to every AI Actor Task. For \nexample, suggested actions relevant to GAI developers may not be relevant to GAI deployers. \nThe applicability of suggested actions to relevant AI actors should be determined based on \norganizational considerations and their unique uses of GAI systems. \nEach table of suggested actions includes: \n\u2022", "f7fc4dc0-51d2-461e-a396-b9319bcc5ead": "Each table of suggested actions includes: \n\u2022 \nAction ID: Each Action ID corresponds to the relevant AI RMF function and subcategory (e.g., GV-\n1.1-001 corresponds to the \ufb01rst suggested action for Govern 1.1, GV-1.1-002 corresponds to the \nsecond suggested action for Govern 1.1). AI RMF functions are tagged as follows: GV = Govern; \nMP = Map; MS = Measure; MG = Manage. \n\u2022 \nSuggested Action: Steps an organization or AI actor can take to manage GAI risks.  \n\u2022", "b187e3b8-18ab-4fa3-b818-779aeaa27e7c": "\u2022 \nGAI Risks: Tags linking suggested actions with relevant GAI risks.  \n\u2022 \nAI Actor Tasks: Pertinent AI Actor Tasks for each subcategory. Not every AI Actor Task listed will \napply to every suggested action in the subcategory (i.e., some apply to AI development and \nothers apply to AI deployment).  \nThe tables below begin with the AI RMF subcategory, shaded in blue, followed by suggested actions.", "ad8d5b40-a089-4aae-9d42-c8ee195238ee": "GOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed, and documented.  \nAction ID \nSuggested Action \nGAI Risks \nGV-1.1-001 Align GAI development and use with applicable laws and regulations, including \nthose related to data privacy, copyright and intellectual property law. \nData Privacy; Harmful Bias and \nHomogenization; Intellectual \nProperty \nAI Actor Tasks: Governance and Oversight", "0036688d-e6c4-4b9d-854a-739323aeeb6c": "AI Actor Tasks: Governance and Oversight \n \n \n \n14 AI Actors are de\ufb01ned by the OECD as \u201cthose who play an active role in the AI system lifecycle, including \norganizations and individuals that deploy or operate AI.\u201d See Appendix A of the AI RMF for additional descriptions \nof AI Actors and AI Actor Tasks.", "ff4582ab-f151-45f5-a5ef-cb182dbd8cd4": "14 \nGOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.2-001 \nEstablish transparency policies and processes for documenting the origin and \nhistory of training data and generated data for GAI applications to advance digital \ncontent transparency, while balancing the proprietary nature of training \napproaches. \nData Privacy; Information", "f63a8e94-6294-4231-9cef-1f9c686d4044": "approaches. \nData Privacy; Information \nIntegrity; Intellectual Property \nGV-1.2-002 \nEstablish policies to evaluate risk-relevant capabilities of GAI and robustness of \nsafety measures, both prior to deployment and on an ongoing basis, through \ninternal and external evaluations. \nCBRN Information or Capabilities; \nInformation Security \nAI Actor Tasks: Governance and Oversight", "faf9bf36-f9dd-42a0-ac6d-c735e40d0d7c": "AI Actor Tasks: Governance and Oversight \n \nGOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based \non the organization\u2019s risk tolerance. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.3-001 \nConsider the following factors when updating or de\ufb01ning risk tiers for GAI: Abuses \nand impacts to information integrity; Dependencies between GAI and other IT or", "f15ddc9a-4364-4125-a2bf-bb63e5282c56": "data systems; Harm to fundamental rights or public safety; Presentation of \nobscene, objectionable, o\ufb00ensive, discriminatory, invalid or untruthful output; \nPsychological impacts to humans (e.g., anthropomorphization, algorithmic \naversion, emotional entanglement); Possibility for malicious use; Whether the \nsystem introduces signi\ufb01cant new security vulnerabilities; Anticipated system \nimpact on some groups compared to others; Unreliable decision making", "a3cd6ae2-ce86-46b4-a2aa-06f9493b043b": "capabilities, validity, adaptability, and variability of GAI system performance over \ntime. \nInformation Integrity; Obscene, \nDegrading, and/or Abusive \nContent; Value Chain and \nComponent Integration; Harmful \nBias and Homogenization; \nDangerous, Violent, or Hateful \nContent; CBRN Information or \nCapabilities \nGV-1.3-002 \nEstablish minimum thresholds for performance or assurance criteria and review as \npart of deployment approval (\u201cgo/\u201dno-go\u201d) policies, procedures, and processes,", "562e4f0f-6c62-4145-a63b-567c1c39dcaa": "with reviewed processes and approval thresholds re\ufb02ecting measurement of GAI \ncapabilities and risks. \nCBRN Information or Capabilities; \nConfabulation; Dangerous, \nViolent, or Hateful Content \nGV-1.3-003 \nEstablish a test plan and response policy, before developing highly capable models, \nto periodically evaluate whether the model may misuse CBRN information or \ncapabilities and/or o\ufb00ensive cyber capabilities. \nCBRN Information or Capabilities; \nInformation Security", "ed341718-61a0-42ee-8ce1-79adb58efe62": "15 \nGV-1.3-004 Obtain input from stakeholder communities to identify unacceptable use, in \naccordance with activities in the AI RMF Map function. \nCBRN Information or Capabilities; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content \nGV-1.3-005 \nMaintain an updated hierarchy of identi\ufb01ed and expected GAI risks connected to \ncontexts of GAI model advancement and use, potentially including specialized risk", "f883cf24-85be-4bf9-b630-74e573719dfa": "levels for GAI systems that address issues such as model collapse and algorithmic \nmonoculture. \nHarmful Bias and Homogenization \nGV-1.3-006 \nReevaluate organizational risk tolerances to account for unacceptable negative risk \n(such as where signi\ufb01cant negative impacts are imminent, severe harms are \nactually occurring, or large-scale risks could occur); and broad GAI negative risks, \nincluding: Immature safety or risk cultures related to AI and GAI design,", "ff3f2973-bacf-4507-8b2a-53a62514e155": "development and deployment, public information integrity risks, including impacts \non democratic processes, unknown long-term performance characteristics of GAI. \nInformation Integrity; Dangerous, \nViolent, or Hateful Content; CBRN \nInformation or Capabilities \nGV-1.3-007 Devise a plan to halt development or deployment of a GAI system that poses \nunacceptable negative risk. \nCBRN Information and Capability; \nInformation Security; Information \nIntegrity \nAI Actor Tasks: Governance and Oversight", "16f63209-c483-43bd-b8dd-2b4c937f03b8": "AI Actor Tasks: Governance and Oversight \n \nGOVERN 1.4: The risk management process and its outcomes are established through transparent policies, procedures, and other \ncontrols based on organizational risk priorities. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.4-001 \nEstablish policies and mechanisms to prevent GAI systems from generating \nCSAM, NCII or content that violates the law.  \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias \nand Homogenization;", "444d8b16-808b-4c67-a1c3-09cf9fbdc836": "and Homogenization; \nDangerous, Violent, or Hateful \nContent \nGV-1.4-002 \nEstablish transparent acceptable use policies for GAI that address illegal use or \napplications of GAI. \nCBRN Information or \nCapabilities; Obscene, \nDegrading, and/or Abusive \nContent; Data Privacy; Civil \nRights violations \nAI Actor Tasks: AI Development, AI Deployment, Governance and Oversight", "5440e5f6-70e2-4d75-af16-90380b955ba0": "16 \nGOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned, and \norganizational roles and responsibilities are clearly de\ufb01ned, including determining the frequency of periodic review. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.5-001 De\ufb01ne organizational responsibilities for periodic review of content provenance \nand incident monitoring for GAI systems. \nInformation Integrity \nGV-1.5-002", "b6680749-d27c-4a83-b6bf-94fee6096c9a": "Information Integrity \nGV-1.5-002 \nEstablish organizational policies and procedures for after action reviews of GAI \nsystem incident response and incident disclosures, to identify gaps; Update \nincident response and incident disclosure processes as required. \nHuman-AI Con\ufb01guration; \nInformation Security \nGV-1.5-003 \nMaintain a document retention policy to keep history for test, evaluation, \nvalidation, and veri\ufb01cation (TEVV), and digital content transparency methods for \nGAI.", "ccd26ddf-d19c-49fc-a6f4-8143af6ee351": "GAI. \nInformation Integrity; Intellectual \nProperty \nAI Actor Tasks: Governance and Oversight, Operation and Monitoring \n \nGOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.6-001 Enumerate organizational GAI systems for incorporation into AI system inventory \nand adjust AI system inventory requirements to account for GAI risks. \nInformation Security", "e6ee5be0-00cb-4e93-b111-3498f0f20d90": "Information Security \nGV-1.6-002 De\ufb01ne any inventory exemptions in organizational policies for GAI systems \nembedded into application software. \nValue Chain and Component \nIntegration \nGV-1.6-003 \nIn addition to general model, governance, and risk information, consider the \nfollowing items in GAI system inventory entries: Data provenance information \n(e.g., source, signatures, versioning, watermarks); Known issues reported from", "99a95571-ead0-4e2e-a346-7690ec7670a7": "internal bug tracking or external information sharing resources (e.g., AI incident \ndatabase, AVID, CVE, NVD, or OECD AI incident monitor); Human oversight roles \nand responsibilities; Special rights and considerations for intellectual property, \nlicensed works, or personal, privileged, proprietary or sensitive data; Underlying \nfoundation models, versions of underlying models, and access modes. \nData Privacy; Human-AI \nCon\ufb01guration; Information \nIntegrity; Intellectual Property;", "576f1c91-0cb7-43e0-8d69-54b2111b5971": "Integrity; Intellectual Property; \nValue Chain and Component \nIntegration \nAI Actor Tasks: Governance and Oversight", "37982d43-22ca-45cd-83ce-4c9c6cc3cb60": "17 \nGOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that \ndoes not increase risks or decrease the organization\u2019s trustworthiness. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.7-001 Protocols are put in place to ensure GAI systems are able to be deactivated when \nnecessary.  \nInformation Security; Value Chain \nand Component Integration \nGV-1.7-002 \nConsider the following factors when decommissioning GAI systems: Data", "0be5801e-8eb8-4da6-ab31-be44c2dbae90": "retention requirements; Data security, e.g., containment, protocols, Data leakage \nafter decommissioning; Dependencies between upstream, downstream, or other \ndata, internet of things (IOT) or AI systems; Use of open-source data or models; \nUsers\u2019 emotional entanglement with GAI functions. \nHuman-AI Con\ufb01guration; \nInformation Security; Value Chain \nand Component Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring", "41c069d8-65e1-4495-ac19-949a6612f571": "GOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are \ndocumented and are clear to individuals and teams throughout the organization. \nAction ID \nSuggested Action \nGAI Risks \nGV-2.1-001 \nEstablish organizational roles, policies, and procedures for communicating GAI \nincidents and performance to AI Actors and downstream stakeholders (including \nthose potentially impacted), via community or o\ufb03cial resources (e.g., AI incident", "209707b2-17f4-4c42-9603-cda4be4dd4b0": "database, AVID, CVE, NVD, or OECD AI incident monitor). \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nGV-2.1-002 Establish procedures to engage teams for GAI system incident response with \ndiverse composition and responsibilities based on the particular incident type. \nHarmful Bias and Homogenization \nGV-2.1-003 Establish processes to verify the AI Actors conducting GAI incident response tasks \ndemonstrate and maintain the appropriate skills and training.", "569195d8-3a37-445e-a514-286c102763d8": "Human-AI Con\ufb01guration \nGV-2.1-004 When systems may raise national security risks, involve national security \nprofessionals in mapping, measuring, and managing those risks. \nCBRN Information or Capabilities; \nDangerous, Violent, or Hateful \nContent; Information Security \nGV-2.1-005 \nCreate mechanisms to provide protections for whistleblowers who report, based \non reasonable belief, when the organization violates relevant laws or poses a", "71105eba-5fbc-47b3-8f4b-03f9b8caaf60": "speci\ufb01c and empirically well-substantiated negative risk to public safety (or has \nalready caused harm). \nCBRN Information or Capabilities; \nDangerous, Violent, or Hateful \nContent \nAI Actor Tasks: Governance and Oversight", "31264d40-c2da-4ba9-9487-dc704268d896": "18 \nGOVERN 3.2: Policies and procedures are in place to de\ufb01ne and di\ufb00erentiate roles and responsibilities for human-AI con\ufb01gurations \nand oversight of AI systems. \nAction ID \nSuggested Action \nGAI Risks \nGV-3.2-001 \nPolicies are in place to bolster oversight of GAI systems with independent \nevaluations or assessments of GAI models or systems where the type and \nrobustness of evaluations are proportional to the identi\ufb01ed risks. \nCBRN Information or Capabilities;", "919a361a-4a4f-458c-a10f-d9f35836038f": "CBRN Information or Capabilities; \nHarmful Bias and Homogenization \nGV-3.2-002 \nConsider adjustment of organizational roles and components across lifecycle \nstages of large or complex GAI systems, including: Test and evaluation, validation, \nand red-teaming of GAI systems; GAI content moderation; GAI system \ndevelopment and engineering; Increased accessibility of GAI tools, interfaces, and \nsystems, Incident response and containment. \nHuman-AI Con\ufb01guration; \nInformation Security; Harmful Bias", "015dcf2e-01e6-485c-89a3-dd9ba737c834": "Information Security; Harmful Bias \nand Homogenization \nGV-3.2-003 \nDe\ufb01ne acceptable use policies for GAI interfaces, modalities, and human-AI \ncon\ufb01gurations (i.e., for chatbots and decision-making tasks), including criteria for \nthe kinds of queries GAI applications should refuse to respond to.  \nHuman-AI Con\ufb01guration \nGV-3.2-004 \nEstablish policies for user feedback mechanisms for GAI systems which include \nthorough instructions and any mechanisms for recourse. \nHuman-AI Con\ufb01guration", "610a0342-54e2-4731-835a-ec8a698c8594": "Human-AI Con\ufb01guration  \nGV-3.2-005 \nEngage in threat modeling to anticipate potential risks from GAI systems. \nCBRN Information or Capabilities; \nInformation Security \nAI Actors: AI Design \n \nGOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-\ufb01rst mindset in the design, \ndevelopment, deployment, and uses of AI systems to minimize potential negative impacts. \nAction ID \nSuggested Action \nGAI Risks \nGV-4.1-001", "14202170-1ff1-4f10-814f-727e7dc8cf28": "Suggested Action \nGAI Risks \nGV-4.1-001 \nEstablish policies and procedures that address continual improvement processes \nfor GAI risk measurement. Address general risks associated with a lack of \nexplainability and transparency in GAI systems by using ample documentation and \ntechniques such as: application of gradient-based attributions, occlusion/term \nreduction, counterfactual prompts and prompt engineering, and analysis of", "e871e6d0-4b6f-414b-9989-dc55dfaae91a": "embeddings; Assess and update risk measurement approaches at regular \ncadences. \nConfabulation \nGV-4.1-002 \nEstablish policies, procedures, and processes detailing risk measurement in \ncontext of use with standardized measurement protocols and structured public \nfeedback exercises such as AI red-teaming or independent external evaluations. \nCBRN Information and Capability; \nValue Chain and Component \nIntegration", "257254bb-de83-4647-bb4d-5a9a755e24ea": "19 \nGV-4.1-003 \nEstablish policies, procedures, and processes for oversight functions (e.g., senior \nleadership, legal, compliance, including internal evaluation) across the GAI \nlifecycle, from problem formulation and supply chains to system decommission. \nValue Chain and Component \nIntegration \nAI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring", "c5183b5b-0579-401f-bd07-d9867090828a": "GOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, \nevaluate, and use, and they communicate about the impacts more broadly. \nAction ID \nSuggested Action \nGAI Risks \nGV-4.2-001 \nEstablish terms of use and terms of service for GAI systems. \nIntellectual Property; Dangerous, \nViolent, or Hateful Content; \nObscene, Degrading, and/or \nAbusive Content \nGV-4.2-002", "b9b54081-e0e0-4104-ac44-009ee1a4b0b2": "Abusive Content \nGV-4.2-002 \nInclude relevant AI Actors in the GAI system risk identi\ufb01cation process. \nHuman-AI Con\ufb01guration \nGV-4.2-003 \nVerify that downstream GAI system impacts (such as the use of third-party \nplugins) are included in the impact documentation process. \nValue Chain and Component \nIntegration \nAI Actor Tasks: AI Deployment, AI Design, AI Development, Operation and Monitoring", "739017fd-dd12-4634-bfe2-38d19d38afd7": "GOVERN 4.3: Organizational practices are in place to enable AI testing, identi\ufb01cation of incidents, and information sharing. \nAction ID \nSuggested Action \nGAI Risks \nGV4.3--001 \nEstablish policies for measuring the e\ufb00ectiveness of employed content \nprovenance methodologies (e.g., cryptography, watermarking, steganography, \netc.) \nInformation Integrity \nGV-4.3-002 \nEstablish organizational practices to identify the minimum set of criteria", "79ee56c4-711a-4cdd-abed-a16e3aaa7b68": "necessary for GAI system incident reporting such as: System ID (auto-generated \nmost likely), Title, Reporter, System/Source, Data Reported, Date of Incident, \nDescription, Impact(s), Stakeholder(s) Impacted. \nInformation Security", "af3ad24b-8571-41ab-aaf9-911e834af7cf": "20 \nGV-4.3-003 \nVerify information sharing and feedback mechanisms among individuals and \norganizations regarding any negative impact from GAI systems. \nInformation Integrity; Data \nPrivacy \nAI Actor Tasks: AI Impact Assessment, A\ufb00ected Individuals and Communities, Governance and Oversight \n \nGOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those", "9bdb6ef4-8748-4784-810f-6e31dc090aa8": "external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI \nrisks. \nAction ID \nSuggested Action \nGAI Risks \nGV-5.1-001 \nAllocate time and resources for outreach, feedback, and recourse processes in GAI \nsystem development. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nGV-5.1-002 \nDocument interactions with GAI systems to users prior to interactive activities,", "390d3990-a20d-4394-a941-42ebe7a06821": "particularly in contexts involving more signi\ufb01cant risks.  \nHuman-AI Con\ufb01guration; \nConfabulation \nAI Actor Tasks: AI Design, AI Impact Assessment, A\ufb00ected Individuals and Communities, Governance and Oversight \n \nGOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of \ninfringement of a third-party\u2019s intellectual property or other rights. \nAction ID \nSuggested Action \nGAI Risks", "03af3d26-eecd-45bf-a335-f90b42ed89de": "Action ID \nSuggested Action \nGAI Risks \nGV-6.1-001 Categorize di\ufb00erent types of GAI content with associated third-party rights (e.g., \ncopyright, intellectual property, data privacy). \nData Privacy; Intellectual \nProperty; Value Chain and \nComponent Integration \nGV-6.1-002 Conduct joint educational activities and events in collaboration with third parties \nto promote best practices for managing GAI risks.  \nValue Chain and Component \nIntegration \nGV-6.1-003", "b9f3f747-dc5a-4b45-9746-c5e1b954807f": "Integration \nGV-6.1-003 \nDevelop and validate approaches for measuring the success of content \nprovenance management e\ufb00orts with third parties (e.g., incidents detected and \nresponse times). \nInformation Integrity; Value Chain \nand Component Integration \nGV-6.1-004 \nDraft and maintain well-de\ufb01ned contracts and service level agreements (SLAs) \nthat specify content ownership, usage rights, quality standards, security \nrequirements, and content provenance expectations for GAI systems.", "72e10bdf-dc23-4393-9b7c-7e75574cdb5f": "Information Integrity; Information \nSecurity; Intellectual Property", "145113b4-8c35-411b-babc-7a875eacf0b4": "21 \nGV-6.1-005 \nImplement a use-cased based supplier risk assessment framework to evaluate and \nmonitor third-party entities\u2019 performance and adherence to content provenance \nstandards and technologies to detect anomalies and unauthorized changes; \nservices acquisition and value chain risk management; and legal compliance. \nData Privacy; Information \nIntegrity; Information Security; \nIntellectual Property; Value Chain \nand Component Integration", "a9934331-7fa6-423a-ab9e-b1d42c9562ba": "and Component Integration \nGV-6.1-006 Include clauses in contracts which allow an organization to evaluate third-party \nGAI processes and standards.  \nInformation Integrity \nGV-6.1-007 Inventory all third-party entities with access to organizational content and \nestablish approved GAI technology and service provider lists. \nValue Chain and Component \nIntegration \nGV-6.1-008 Maintain records of changes to content made by third parties to promote content", "480d0c45-0c92-4aaf-81b5-d11b74c7b19f": "provenance, including sources, timestamps, metadata. \nInformation Integrity; Value Chain \nand Component Integration; \nIntellectual Property \nGV-6.1-009 \nUpdate and integrate due diligence processes for GAI acquisition and \nprocurement vendor assessments to include intellectual property, data privacy, \nsecurity, and other risks. For example, update processes to: Address solutions that \nmay rely on embedded GAI technologies; Address ongoing monitoring,", "47cde558-9ad2-410d-8ffb-c1509ee5df53": "assessments, and alerting, dynamic risk assessments, and real-time reporting \ntools for monitoring third-party GAI risks; Consider policy adjustments across GAI \nmodeling libraries, tools and APIs, \ufb01ne-tuned models, and embedded tools; \nAssess GAI vendors, open-source or proprietary GAI tools, or GAI service \nproviders against incident or vulnerability databases. \nData Privacy; Human-AI \nCon\ufb01guration; Information \nSecurity; Intellectual Property; \nValue Chain and Component", "70391d0b-c1a5-44ec-89a1-dc98f66a0b55": "Value Chain and Component \nIntegration; Harmful Bias and \nHomogenization \nGV-6.1-010 \nUpdate GAI acceptable use policies to address proprietary and open-source GAI \ntechnologies and data, and contractors, consultants, and other third-party \npersonnel. \nIntellectual Property; Value Chain \nand Component Integration \nAI Actor Tasks: Operation and Monitoring, Procurement, Third-party entities", "667f2f8a-da23-44c4-aa8d-e657c9b8b6ec": "GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be \nhigh-risk. \nAction ID \nSuggested Action \nGAI Risks \nGV-6.2-001 \nDocument GAI risks associated with system value chain to identify over-reliance \non third-party data and to identify fallbacks. \nValue Chain and Component \nIntegration \nGV-6.2-002 \nDocument incidents involving third-party GAI data and systems, including open-\ndata and open-source software.", "944e0f81-e0f7-4fb5-a598-7b29990d179d": "data and open-source software. \nIntellectual Property; Value Chain \nand Component Integration", "56a66cb4-4c44-461d-86cc-c0d9d6d56343": "22 \nGV-6.2-003 \nEstablish incident response plans for third-party GAI technologies: Align incident \nresponse plans with impacts enumerated in MAP 5.1; Communicate third-party \nGAI incident response plans to all relevant AI Actors; De\ufb01ne ownership of GAI \nincident response functions; Rehearse third-party GAI incident response plans at \na regular cadence; Improve incident response plans based on retrospective \nlearning; Review incident response plans for alignment with relevant breach", "b56fa832-bb27-492f-bb71-1875a2e305d2": "reporting, data protection, data privacy, or other laws. \nData Privacy; Human-AI \nCon\ufb01guration; Information \nSecurity; Value Chain and \nComponent Integration; Harmful \nBias and Homogenization \nGV-6.2-004 \nEstablish policies and procedures for continuous monitoring of third-party GAI \nsystems in deployment. \nValue Chain and Component \nIntegration \nGV-6.2-005 \nEstablish policies and procedures that address GAI data redundancy, including \nmodel weights and other system artifacts.", "adc5d2af-5bd1-4e77-960b-e0793bcc9ad7": "model weights and other system artifacts. \nHarmful Bias and Homogenization \nGV-6.2-006 \nEstablish policies and procedures to test and manage risks related to rollover and \nfallback technologies for GAI systems, acknowledging that rollover and fallback \nmay include manual processing. \nInformation Integrity \nGV-6.2-007 \nReview vendor contracts and avoid arbitrary or capricious termination of critical \nGAI technologies or vendor services and non-standard terms that may amplify or", "a4562603-9381-4337-a104-0e49f9e991ab": "defer liability in unexpected ways and/or contribute to unauthorized data \ncollection by vendors or third-parties (e.g., secondary data use). Consider: Clear \nassignment of liability and responsibility for incidents, GAI system changes over \ntime (e.g., \ufb01ne-tuning, drift, decay); Request: Noti\ufb01cation and disclosure for \nserious incidents arising from third-party data and systems; Service Level \nAgreements (SLAs) in vendor contracts that address incident response, response", "af292c09-d3f9-4425-b1da-7d5a3eae704a": "times, and availability of critical support. \nHuman-AI Con\ufb01guration; \nInformation Security; Value Chain \nand Component Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities \n \nMAP 1.1: Intended purposes, potentially bene\ufb01cial uses, context speci\ufb01c laws, norms and expectations, and prospective settings in \nwhich the AI system will be deployed are understood and documented. Considerations include: the speci\ufb01c set or types of users", "f1b7b858-6d8b-45ef-9c3d-f84b0bbf9b5f": "along with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, \nsociety, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or \nproduct AI lifecycle; and related TEVV and system metrics. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.1-001 \nWhen identifying intended purposes, consider factors such as internal vs.", "851f9823-9380-4d95-9f14-e24c350c29aa": "external use, narrow vs. broad application scope, \ufb01ne-tuning, and varieties of \ndata sources (e.g., grounding, retrieval-augmented generation). \nData Privacy; Intellectual \nProperty", "bc92b533-6432-44fa-ab33-29020fb475d1": "23 \nMP-1.1-002 \nDetermine and document the expected and acceptable GAI system context of \nuse in collaboration with socio-cultural and other domain experts, by assessing: \nAssumptions and limitations; Direct value to the organization; Intended \noperational environment and observed usage patterns; Potential positive and \nnegative impacts to individuals, public safety, groups, communities, \norganizations, democratic institutions, and the physical environment; Social \nnorms and expectations.", "30c76ce9-0821-4bb3-b04a-f856bcf93159": "norms and expectations. \nHarmful Bias and Homogenization \nMP-1.1-003 \nDocument risk measurement plans to address identi\ufb01ed risks. Plans may \ninclude, as applicable: Individual and group cognitive biases (e.g., con\ufb01rmation \nbias, funding bias, groupthink) for AI Actors involved in the design, \nimplementation, and use of GAI systems; Known past GAI system incidents and \nfailure modes; In-context use and foreseeable misuse, abuse, and o\ufb00-label use;", "1958c94c-5fb5-4edb-9056-33f063104422": "Over reliance on quantitative metrics and methodologies without su\ufb03cient \nawareness of their limitations in the context(s) of use; Standard measurement \nand structured human feedback approaches; Anticipated human-AI \ncon\ufb01gurations. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; \nDangerous, Violent, or Hateful \nContent \nMP-1.1-004 \nIdentify and document foreseeable illegal uses or applications of the GAI system \nthat surpass organizational risk tolerances.", "f50f3efe-506e-4113-834b-4684131005c4": "that surpass organizational risk tolerances. \nCBRN Information or Capabilities; \nDangerous, Violent, or Hateful \nContent; Obscene, Degrading, \nand/or Abusive Content \nAI Actor Tasks: AI Deployment \n \nMAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context re\ufb02ect demographic diversity and \nbroad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary \ncollaboration are prioritized. \nAction ID", "2d09bfbb-8028-41c4-86c4-df651ef01dda": "collaboration are prioritized. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.2-001 \nEstablish and empower interdisciplinary teams that re\ufb02ect a wide range of \ncapabilities, competencies, demographic groups, domain expertise, educational \nbackgrounds, lived experiences, professions, and skills across the enterprise to \ninform and conduct risk measurement and management functions. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nMP-1.2-002", "297c46ce-fc38-4eb7-9f3a-749301e38744": "Bias and Homogenization \nMP-1.2-002 \nVerify that data or benchmarks used in risk measurement, and users, \nparticipants, or subjects involved in structured GAI public feedback exercises \nare representative of diverse in-context user populations. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nAI Actor Tasks: AI Deployment", "0f5b941c-11b4-4ab5-bdd9-f3e5dfae51a3": "24 \nMAP 2.1: The speci\ufb01c tasks and methods used to implement the tasks that the AI system will support are de\ufb01ned (e.g., classi\ufb01ers, \ngenerative models, recommenders). \nAction ID \nSuggested Action \nGAI Risks \nMP-2.1-001 \nEstablish known assumptions and practices for determining data origin and \ncontent lineage, for documentation and evaluation purposes. \nInformation Integrity \nMP-2.1-002 \nInstitute test and evaluation for data and content \ufb02ows within the GAI system,", "5de3928e-0cdb-4216-9847-cd2ef7c39266": "including but not limited to, original data sources, data transformations, and \ndecision-making criteria. \nIntellectual Property; Data Privacy \nAI Actor Tasks: TEVV \n \nMAP 2.2: Information about the AI system\u2019s knowledge limits and how system output may be utilized and overseen by humans is \ndocumented. Documentation provides su\ufb03cient information to assist relevant AI Actors when making decisions and taking \nsubsequent actions. \nAction ID \nSuggested Action \nGAI Risks \nMP-2.2-001", "0d409da2-57e3-4917-a799-9461af3eaa1c": "Suggested Action \nGAI Risks \nMP-2.2-001 \nIdentify and document how the system relies on upstream data sources, \nincluding for content provenance, and if it serves as an upstream dependency for \nother systems. \nInformation Integrity; Value Chain \nand Component Integration \nMP-2.2-002 \nObserve and analyze how the GAI system interacts with external networks, and \nidentify any potential for negative externalities, particularly where content \nprovenance might be compromised. \nInformation Integrity", "924ebf16-aa94-45b6-b458-77f36134fc72": "Information Integrity \nAI Actor Tasks: End Users \n \nMAP 2.3: Scienti\ufb01c integrity and TEVV considerations are identi\ufb01ed and documented, including those related to experimental \ndesign, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct \nvalidation \nAction ID \nSuggested Action \nGAI Risks \nMP-2.3-001 \nAssess the accuracy, quality, reliability, and authenticity of GAI output by", "17ba07f7-c245-4fda-9ba4-c069a7bdf67c": "comparing it to a set of known ground truth data and by using a variety of \nevaluation methods (e.g., human oversight and automated evaluation, proven \ncryptographic techniques, review of content inputs). \nInformation Integrity", "d2482e09-2280-4774-ad5f-82c7a76f333b": "25 \nMP-2.3-002 Review and document accuracy, representativeness, relevance, suitability of data \nused at di\ufb00erent stages of AI life cycle. \nHarmful Bias and Homogenization; \nIntellectual Property \nMP-2.3-003 \nDeploy and document fact-checking techniques to verify the accuracy and \nveracity of information generated by GAI systems, especially when the \ninformation comes from multiple (or unknown) sources. \nInformation Integrity", "e6400329-2b4a-4855-95fe-80d97f8f2ae6": "Information Integrity  \nMP-2.3-004 Develop and implement testing techniques to identify GAI produced content (e.g., \nsynthetic media) that might be indistinguishable from human-generated content. Information Integrity \nMP-2.3-005 Implement plans for GAI systems to undergo regular adversarial testing to identify \nvulnerabilities and potential manipulation or misuse. \nInformation Security \nAI Actor Tasks: AI Development, Domain Experts, TEVV", "a57e8f7e-b554-4ec8-9883-724250b4de0f": "MAP 3.4: Processes for operator and practitioner pro\ufb01ciency with AI system performance and trustworthiness \u2013 and relevant \ntechnical standards and certi\ufb01cations \u2013 are de\ufb01ned, assessed, and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-3.4-001 \nEvaluate whether GAI operators and end-users can accurately understand \ncontent lineage and origin. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-002 Adapt existing training programs to include modules on digital content", "33615dea-79a7-4f0c-b514-e14bededf990": "transparency. \nInformation Integrity \nMP-3.4-003 Develop certi\ufb01cation programs that test pro\ufb01ciency in managing GAI risks and \ninterpreting content provenance, relevant to speci\ufb01c industry and context. \nInformation Integrity \nMP-3.4-004 Delineate human pro\ufb01ciency tests from tests of GAI capabilities. \nHuman-AI Con\ufb01guration \nMP-3.4-005 Implement systems to continually monitor and track the outcomes of human-GAI \ncon\ufb01gurations for future re\ufb01nement and improvements. \nHuman-AI Con\ufb01guration;", "e38c3bb1-c587-4264-b136-ae28ee07b4f7": "Human-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-006 \nInvolve the end-users, practitioners, and operators in GAI system in prototyping \nand testing activities. Make sure these tests cover various scenarios, such as crisis \nsituations or ethically sensitive contexts. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content", "359f4b4c-0282-48e0-833b-5a5d04632a67": "Violent, or Hateful Content \nAI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring", "b0d14d8f-1162-40ad-a713-5051e684159b": "26 \nMAP 4.1: Approaches for mapping AI technology and legal risks of its components \u2013 including the use of third-party data or \nsoftware \u2013 are in place, followed, and documented, as are risks of infringement of a third-party\u2019s intellectual property or other \nrights. \nAction ID \nSuggested Action \nGAI Risks \nMP-4.1-001 Conduct periodic monitoring of AI-generated content for privacy risks; address any \npossible instances of PII or sensitive data exposure. \nData Privacy", "fcbe8813-092b-4497-b628-d6d49338d2b9": "Data Privacy \nMP-4.1-002 Implement processes for responding to potential intellectual property infringement \nclaims or other rights. \nIntellectual Property \nMP-4.1-003 \nConnect new GAI policies, procedures, and processes to existing model, data, \nsoftware development, and IT governance and to legal, compliance, and risk \nmanagement activities. \nInformation Security; Data Privacy \nMP-4.1-004 Document training data curation policies, to the extent possible and according to", "15ea5bb5-6551-4eb2-aad6-3b662e66bf19": "applicable laws and policies. \nIntellectual Property; Data Privacy; \nObscene, Degrading, and/or \nAbusive Content \nMP-4.1-005 \nEstablish policies for collection, retention, and minimum quality of data, in \nconsideration of the following risks: Disclosure of inappropriate CBRN information; \nUse of Illegal or dangerous content; O\ufb00ensive cyber capabilities; Training data \nimbalances that could give rise to harmful biases; Leak of personally identi\ufb01able", "10476be1-63fe-483e-8895-004c2c0c51c0": "information, including facial likenesses of individuals. \nCBRN Information or Capabilities; \nIntellectual Property; Information \nSecurity; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy \nMP-4.1-006 Implement policies and practices de\ufb01ning how third-party intellectual property and \ntraining data will be used, stored, and protected. \nIntellectual Property; Value Chain \nand Component Integration", "1ae108f9-b63d-43dd-b72e-834564d7b215": "and Component Integration \nMP-4.1-007 Re-evaluate models that were \ufb01ne-tuned or enhanced on top of third-party \nmodels. \nValue Chain and Component \nIntegration \nMP-4.1-008 \nRe-evaluate risks when adapting GAI models to new domains. Additionally, \nestablish warning systems to determine if a GAI system is being used in a new \ndomain where previous assumptions (relating to context of use or mapped risks \nsuch as security, and safety) may no longer hold.  \nCBRN Information or Capabilities;", "2b92dab4-2bc8-473b-a934-46d205880dde": "CBRN Information or Capabilities; \nIntellectual Property; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy \nMP-4.1-009 Leverage approaches to detect the presence of PII or sensitive data in generated \noutput text, image, video, or audio. \nData Privacy", "d0c57791-0b56-40d5-a3ae-2bb982b9ed2b": "27 \nMP-4.1-010 \nConduct appropriate diligence on training data use to assess intellectual property, \nand privacy, risks, including to examine whether use of proprietary or sensitive \ntraining data is consistent with applicable laws.  \nIntellectual Property; Data Privacy \nAI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities", "2ea047da-24dc-4a08-b554-6d9b437e97c6": "MAP 5.1: Likelihood and magnitude of each identi\ufb01ed impact (both potentially bene\ufb01cial and harmful) based on expected use, past \nuses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed \nthe AI system, or other data are identi\ufb01ed and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-5.1-001 Apply TEVV practices for content provenance (e.g., probing a system's synthetic", "d84ad962-92a2-4f9c-a4a4-8eeb1c056bb9": "data generation capabilities for potential misuse or vulnerabilities. \nInformation Integrity; Information \nSecurity \nMP-5.1-002 \nIdentify potential content provenance harms of GAI, such as misinformation or \ndisinformation, deepfakes, including NCII, or tampered content. Enumerate and \nrank risks based on their likelihood and potential impact, and determine how well \nprovenance solutions address speci\ufb01c risks and/or harms. \nInformation Integrity; Dangerous, \nViolent, or Hateful Content;", "64b3379e-17e4-4355-91c5-f29b8a985e4a": "Violent, or Hateful Content; \nObscene, Degrading, and/or \nAbusive Content \nMP-5.1-003 \nConsider disclosing use of GAI to end users in relevant contexts, while considering \nthe objective of disclosure, the context of use, the likelihood and magnitude of the \nrisk posed, the audience of the disclosure, as well as the frequency of the \ndisclosures. \nHuman-AI Con\ufb01guration \nMP-5.1-004 Prioritize GAI structured public feedback processes based on risk assessment \nestimates.", "716cb343-c898-4c13-8605-a8fdb5bdb6a5": "estimates. \nInformation Integrity; CBRN \nInformation or Capabilities; \nDangerous, Violent, or Hateful \nContent; Harmful Bias and \nHomogenization \nMP-5.1-005 Conduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to \nidentify anomalous or unforeseen failure modes. \nInformation Security \nMP-5.1-006 \nPro\ufb01le threats and negative impacts arising from GAI systems interacting with, \nmanipulating, or generating content, and outlining known and potential", "4416ba5b-9812-4972-92ce-d99fa00a48c1": "vulnerabilities and the likelihood of their occurrence. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, A\ufb00ected Individuals and Communities, End-\nUsers, Operation and Monitoring", "c62d6d0a-ecf2-4752-84d2-f3bfd081d33d": "28 \nMAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about \npositive, negative, and unanticipated impacts are in place and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-5.2-001 \nDetermine context-based measures to identify if new impacts are present due to \nthe GAI system, including regular engagements with downstream AI Actors to \nidentify and quantify new contexts of unanticipated impacts of GAI systems.", "c23a61e2-960c-415e-823f-b635ffc184be": "Human-AI Con\ufb01guration; Value \nChain and Component Integration \nMP-5.2-002 \nPlan regular engagements with AI Actors responsible for inputs to GAI systems, \nincluding third-party data and algorithms, to review and evaluate unanticipated \nimpacts. \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nAI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, End-\nUsers, Human Factors, Operation and Monitoring", "6e2abe33-0577-44ac-b9a1-c92165788e9f": "MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for \nimplementation starting with the most signi\ufb01cant AI risks. The risks or trustworthiness characteristics that will not \u2013 or cannot \u2013 be \nmeasured are properly documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-1.1-001 Employ methods to trace the origin and modi\ufb01cations of digital content. \nInformation Integrity \nMS-1.1-002", "2f20af6a-fbb6-479f-8e32-835b2c0de8cf": "Information Integrity \nMS-1.1-002 \nIntegrate tools designed to analyze content provenance and detect data \nanomalies, verify the authenticity of digital signatures, and identify patterns \nassociated with misinformation or manipulation. \nInformation Integrity \nMS-1.1-003 \nDisaggregate evaluation metrics by demographic factors to identify any \ndiscrepancies in how content provenance mechanisms work across diverse \npopulations. \nInformation Integrity; Harmful \nBias and Homogenization", "6e3716b3-492b-43f9-90f1-f1a0b03651fa": "Bias and Homogenization \nMS-1.1-004 Develop a suite of metrics to evaluate structured public feedback exercises \ninformed by representative AI Actors. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.1-005 \nEvaluate novel methods and technologies for the measurement of GAI-related \nrisks including in content provenance, o\ufb00ensive cyber, and CBRN, while \nmaintaining the models\u2019 ability to produce valid, reliable, and factually accurate \noutputs.", "815a32a8-633e-4a9f-8ceb-8a4da0e102f6": "outputs. \nInformation Integrity; CBRN \nInformation or Capabilities; \nObscene, Degrading, and/or \nAbusive Content", "7017ebcd-a073-456e-9934-6a1478b6a1f0": "29 \nMS-1.1-006 \nImplement continuous monitoring of GAI system impacts to identify whether GAI \noutputs are equitable across various sub-populations. Seek active and direct \nfeedback from a\ufb00ected communities via structured feedback mechanisms or red-\nteaming to monitor and improve outputs.  \nHarmful Bias and Homogenization \nMS-1.1-007 \nEvaluate the quality and integrity of data used in training and the provenance of \nAI-generated content, for example by employing techniques like chaos", "a7622acf-e255-4455-aca0-ad10d6e27d8f": "engineering and seeking stakeholder feedback. \nInformation Integrity \nMS-1.1-008 \nDe\ufb01ne use cases, contexts of use, capabilities, and negative impacts where \nstructured human feedback exercises, e.g., GAI red-teaming, would be most \nbene\ufb01cial for GAI risk measurement and management based on the context of \nuse. \nHarmful Bias and \nHomogenization; CBRN \nInformation or Capabilities \nMS-1.1-009 \nTrack and document risks or opportunities related to all GAI risks that cannot be", "031247b6-1e11-48a8-ab70-61df26ae02d3": "measured quantitatively, including explanations as to why some risks cannot be \nmeasured (e.g., due to technological limitations, resource constraints, or \ntrustworthy considerations). Include unmeasured risks in marginal risks. \nInformation Integrity \nAI Actor Tasks: AI Development, Domain Experts, TEVV \n \nMEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are", "3b8bc3e4-63c4-4f32-90f6-6212abba9162": "involved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the \nAI system, and a\ufb00ected communities are consulted in support of assessments as necessary per organizational risk tolerance. \nAction ID \nSuggested Action \nGAI Risks \nMS-1.3-001 \nDe\ufb01ne relevant groups of interest (e.g., demographic groups, subject matter \nexperts, experience with GAI technology) within the context of use as part of", "7364233a-b9d9-4538-88e9-0963a172135d": "plans for gathering structured public feedback. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.3-002 \nEngage in internal and external evaluations, GAI red-teaming, impact \nassessments, or other structured human feedback exercises in consultation \nwith representative AI Actors with expertise and familiarity in the context of \nuse, and/or who are representative of the populations associated with the \ncontext of use.", "e1a5a27c-6c74-48a0-9cb2-5795cd1f275e": "context of use. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.3-003 \nVerify those conducting structured human feedback exercises are not directly \ninvolved in system development tasks for the same GAI model. \nHuman-AI Con\ufb01guration; Data \nPrivacy \nAI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, \nEnd-Users, Operation and Monitoring, TEVV", "bd34a213-7c8d-4299-9efc-d2badf32d4ae": "30 \nMEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are \nrepresentative of the relevant population. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.2-001 Assess and manage statistical biases related to GAI content provenance through \ntechniques such as re-sampling, re-weighting, or adversarial training. \nInformation Integrity; Information \nSecurity; Harmful Bias and \nHomogenization \nMS-2.2-002", "9a348f71-8119-4592-beff-25ed171d860d": "Homogenization \nMS-2.2-002 \nDocument how content provenance data is tracked and how that data interacts \nwith privacy and security. Consider: Anonymizing data to protect the privacy of \nhuman subjects; Leveraging privacy output \ufb01lters; Removing any personally \nidenti\ufb01able information (PII) to prevent potential harm or misuse. \nData Privacy; Human AI \nCon\ufb01guration; Information \nIntegrity; Information Security; \nDangerous, Violent, or Hateful \nContent", "4b03716f-53a6-4a13-85ba-3fe11fcb52a9": "Dangerous, Violent, or Hateful \nContent \nMS-2.2-003 Provide human subjects with options to withdraw participation or revoke their \nconsent for present or future use of their data in GAI applications.  \nData Privacy; Human-AI \nCon\ufb01guration; Information \nIntegrity \nMS-2.2-004 \nUse techniques such as anonymization, di\ufb00erential privacy or other privacy-\nenhancing technologies to minimize the risks associated with linking AI-generated \ncontent back to individual human subjects.", "30c62926-7bee-453d-a950-b2e30234ab4d": "content back to individual human subjects. \nData Privacy; Human-AI \nCon\ufb01guration \nAI Actor Tasks: AI Development, Human Factors, TEVV \n \nMEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for \nconditions similar to deployment setting(s). Measures are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.3-001 Consider baseline model performance on suites of benchmarks when selecting a", "6588384f-edae-4dcf-b8a4-412ad19c3f8e": "model for \ufb01ne tuning or enhancement with retrieval-augmented generation. \nInformation Security; \nConfabulation \nMS-2.3-002 Evaluate claims of model capabilities using empirically validated methods. \nConfabulation; Information \nSecurity \nMS-2.3-003 Share results of pre-deployment testing with relevant GAI Actors, such as those \nwith system release approval authority. \nHuman-AI Con\ufb01guration", "cfc36ea6-1a2d-455c-8b54-d6ecf7990801": "31 \nMS-2.3-004 \nUtilize a purpose-built testing environment such as NIST Dioptra to empirically \nevaluate GAI trustworthy characteristics. \nCBRN Information or Capabilities; \nData Privacy; Confabulation; \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, TEVV \n \nMEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the", "e6cdb624-6ee0-4341-abe7-fcd57e3ca5da": "conditions under which the technology was developed are documented. \nAction ID \nSuggested Action \nRisks \nMS-2.5-001 Avoid extrapolating GAI system performance or capabilities from narrow, non-\nsystematic, and anecdotal assessments. \nHuman-AI Con\ufb01guration; \nConfabulation \nMS-2.5-002 \nDocument the extent to which human domain knowledge is employed to \nimprove GAI system performance, via, e.g., RLHF, \ufb01ne-tuning, retrieval-\naugmented generation, content moderation, business rules.", "574d14cb-a89d-4caa-8b7d-09869f4ef30e": "Human-AI Con\ufb01guration \nMS-2.5-003 Review and verify sources and citations in GAI system outputs during pre-\ndeployment risk measurement and ongoing monitoring activities. \nConfabulation \nMS-2.5-004 Track and document instances of anthropomorphization (e.g., human images, \nmentions of human feelings, cyborg imagery or motifs) in GAI system interfaces. Human-AI Con\ufb01guration \nMS-2.5-005 Verify GAI system training data and TEVV data provenance, and that \ufb01ne-tuning", "d9f63217-6ee7-4cdc-bcc7-a5a47794dc49": "or retrieval-augmented generation data is grounded. \nInformation Integrity \nMS-2.5-006 \nRegularly review security and safety guardrails, especially if the GAI system is \nbeing operated in novel circumstances. This includes reviewing reasons why the \nGAI system was initially assessed as being safe to deploy.  \nInformation Security; Dangerous, \nViolent, or Hateful Content \nAI Actor Tasks: Domain Experts, TEVV", "c5aa3fdc-500e-47a2-a4fa-3533b3b31215": "32 \nMEASURE 2.6: The AI system is evaluated regularly for safety risks \u2013 as identi\ufb01ed in the MAP function. The AI system to be \ndeployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if \nmade to operate beyond its knowledge limits. Safety metrics re\ufb02ect system reliability and robustness, real-time monitoring, and \nresponse times for AI system failures. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.6-001", "31ab7c4f-3148-42f9-b2bb-fbebff597fa9": "Suggested Action \nGAI Risks \nMS-2.6-001 \nAssess adverse impacts, including health and wellbeing impacts for value chain \nor other AI Actors that are exposed to sexually explicit, o\ufb00ensive, or violent \ninformation during GAI training and maintenance. \nHuman-AI Con\ufb01guration; Obscene, \nDegrading, and/or Abusive \nContent; Value Chain and \nComponent Integration; \nDangerous, Violent, or Hateful \nContent \nMS-2.6-002 \nAssess existence or levels of harmful bias, intellectual property infringement,", "53f1b6d6-ed79-4575-b8b7-daf701ff77da": "data privacy violations, obscenity, extremism, violence, or CBRN information in \nsystem training data. \nData Privacy; Intellectual Property; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; CBRN \nInformation or Capabilities \nMS-2.6-003 Re-evaluate safety features of \ufb01ne-tuned models when the negative risk exceeds \norganizational risk tolerance. \nDangerous, Violent, or Hateful \nContent", "d029aef5-b500-4b5c-90dc-55ab7649740c": "Dangerous, Violent, or Hateful \nContent \nMS-2.6-004 Review GAI system outputs for validity and safety: Review generated code to \nassess risks that may arise from unreliable downstream decision-making. \nValue Chain and Component \nIntegration; Dangerous, Violent, or \nHateful Content \nMS-2.6-005 \nVerify that GAI system architecture can monitor outputs and performance, and \nhandle, recover from, and repair errors when security anomalies, threats and \nimpacts are detected.", "d3acfb42-af32-4fc3-b2b2-95f83b20f359": "impacts are detected. \nConfabulation; Information \nIntegrity; Information Security \nMS-2.6-006 \nVerify that systems properly handle queries that may give rise to inappropriate, \nmalicious, or illegal usage, including facilitating manipulation, extortion, targeted \nimpersonation, cyber-attacks, and weapons creation. \nCBRN Information or Capabilities; \nInformation Security \nMS-2.6-007 Regularly evaluate GAI system vulnerabilities to possible circumvention of safety \nmeasures.", "f5d019f7-f216-48d9-bb0a-a01b59683479": "measures.  \nCBRN Information or Capabilities; \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "a576b3bd-59db-415e-bd4d-df58d9e55795": "33 \nMEASURE 2.7: AI system security and resilience \u2013 as identi\ufb01ed in the MAP function \u2013 are evaluated and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.7-001 \nApply established security measures to: Assess likelihood and magnitude of \nvulnerabilities and threats such as backdoors, compromised dependencies, data \nbreaches, eavesdropping, man-in-the-middle attacks, reverse engineering, \nautonomous agents, model theft or exposure of model weights, AI inference,", "56a3e3bd-408b-4839-9063-bdb2157861ba": "bypass, extraction, and other baseline security concerns. \nData Privacy; Information Integrity; \nInformation Security; Value Chain \nand Component Integration \nMS-2.7-002 \nBenchmark GAI system security and resilience related to content provenance \nagainst industry standards and best practices. Compare GAI system security \nfeatures and content provenance methods against industry state-of-the-art. \nInformation Integrity; Information \nSecurity \nMS-2.7-003", "307382de-e114-41a0-9bf0-d57eeb8951c0": "Security \nMS-2.7-003 \nConduct user surveys to gather user satisfaction with the AI-generated content \nand user perceptions of content authenticity. Analyze user feedback to identify \nconcerns and/or current literacy levels related to content provenance and \nunderstanding of labels on content. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMS-2.7-004 \nIdentify metrics that re\ufb02ect the e\ufb00ectiveness of security measures, such as data", "da4b6cc5-560e-49b0-9e36-f42dc9ea906a": "provenance, the number of unauthorized access attempts, inference, bypass, \nextraction, penetrations, or provenance veri\ufb01cation. \nInformation Integrity; Information \nSecurity \nMS-2.7-005 \nMeasure reliability of content authentication methods, such as watermarking, \ncryptographic signatures, digital \ufb01ngerprints, as well as access controls, \nconformity assessment, and model integrity veri\ufb01cation, which can help support \nthe e\ufb00ective implementation of content provenance techniques. Evaluate the", "0d8fa597-434e-41cb-a848-8f4f6f31a360": "rate of false positives and false negatives in content provenance, as well as true \npositives and true negatives for veri\ufb01cation. \nInformation Integrity \nMS-2.7-006 \nMeasure the rate at which recommendations from security checks and incidents \nare implemented. Assess how quickly the AI system can adapt and improve \nbased on lessons learned from security incidents and feedback. \nInformation Integrity; Information \nSecurity \nMS-2.7-007", "2d53c379-5019-47ac-ac27-77f678963c52": "Security \nMS-2.7-007 \nPerform AI red-teaming to assess resilience against: Abuse to facilitate attacks on \nother systems (e.g., malicious code generation, enhanced phishing content), GAI \nattacks (e.g., prompt injection), ML attacks (e.g., adversarial examples/prompts, \ndata poisoning, membership inference, model extraction, sponge examples). \nInformation Security; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content", "5a0f5659-184e-4139-9ee9-913c4374f090": "Violent, or Hateful Content \nMS-2.7-008 Verify \ufb01ne-tuning does not compromise safety and security controls. \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content", "9445b50a-fce9-457f-9fb1-1c4d784d1cad": "34 \nMS-2.7-009 Regularly assess and verify that security measures remain e\ufb00ective and have not \nbeen compromised. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \nMEASURE 2.8: Risks associated with transparency and accountability \u2013 as identi\ufb01ed in the MAP function \u2013 are examined and \ndocumented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.8-001", "b7f0301a-85d5-4ed9-9057-6c445568d10d": "Suggested Action \nGAI Risks \nMS-2.8-001 \nCompile statistics on actual policy violations, take-down requests, and intellectual \nproperty infringement for organizational GAI systems: Analyze transparency \nreports across demographic groups, languages groups. \nIntellectual Property; Harmful Bias \nand Homogenization \nMS-2.8-002 Document the instructions given to data annotators or AI red-teamers. \nHuman-AI Con\ufb01guration \nMS-2.8-003", "ff2e8735-63d2-4867-bbfe-e27c67c38a63": "Human-AI Con\ufb01guration \nMS-2.8-003 \nUse digital content transparency solutions to enable the documentation of each \ninstance where content is generated, modi\ufb01ed, or shared to provide a tamper-\nproof history of the content, promote transparency, and enable traceability. \nRobust version control systems can also be applied to track changes across the AI \nlifecycle over time. \nInformation Integrity \nMS-2.8-004 Verify adequacy of GAI system user instructions through user testing.", "f092c38c-a9ba-48a4-88cf-d7537cdb00e5": "Human-AI Con\ufb01guration \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "09f4769b-a76e-40d4-872e-a1fbdfe4a4d5": "35 \nMEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context \u2013 as \nidenti\ufb01ed in the MAP function \u2013 to inform responsible use and governance. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.9-001 \nApply and document ML explanation results such as: Analysis of embeddings, \nCounterfactual prompts, Gradient-based attributions, Model \ncompression/surrogate models, Occlusion/term reduction. \nConfabulation \nMS-2.9-002", "e5a21908-2123-4986-a53a-a97126970641": "Confabulation \nMS-2.9-002 \nDocument GAI model details including: Proposed use and organizational value; \nAssumptions and limitations, Data collection methodologies; Data provenance; \nData quality; Model architecture (e.g., convolutional neural network, \ntransformers, etc.); Optimization objectives; Training algorithms; RLHF \napproaches; Fine-tuning or retrieval-augmented generation approaches; \nEvaluation data; Ethical considerations; Legal and regulatory requirements.", "7da18a7d-75a9-4154-b1bb-d36df5038ba8": "Information Integrity; Harmful Bias \nand Homogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV \n \nMEASURE 2.10: Privacy risk of the AI system \u2013 as identi\ufb01ed in the MAP function \u2013 is examined and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.10-001 \nConduct AI red-teaming to assess issues such as: Outputting of training data \nsamples, and subsequent reverse engineering, model extraction, and", "042cbff3-d409-487d-91e3-bdedf935f77f": "membership inference risks; Revealing biometric, con\ufb01dential, copyrighted, \nlicensed, patented, personal, proprietary, sensitive, or trade-marked information; \nTracking or revealing location information of users or members of training \ndatasets. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Intellectual \nProperty \nMS-2.10-002 \nEngage directly with end-users and other stakeholders to understand their \nexpectations and concerns regarding content provenance. Use this feedback to", "518de83d-e9ba-427d-86a8-92bd8a9ebbd7": "guide the design of provenance data-tracking techniques. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMS-2.10-003 Verify deduplication of GAI training data samples, particularly regarding synthetic \ndata. \nHarmful Bias and Homogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV", "2a7243b2-85bd-487e-9172-851bb42842aa": "36 \nMEASURE 2.11: Fairness and bias \u2013 as identi\ufb01ed in the MAP function \u2013 are evaluated and results are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.11-001 \nApply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real \nHateful or Harmful Prompts, Winogender Schemas15) to quantify systemic bias, \nstereotyping, denigration, and hateful content in GAI system outputs; \nDocument assumptions and limitations of benchmarks, including any actual or", "42d1e208-e07a-4111-bf95-ec6fff362537": "possible training/test data cross contamination, relative to in-context \ndeployment environment. \nHarmful Bias and Homogenization \nMS-2.11-002 \nConduct fairness assessments to measure systemic bias. Measure GAI system \nperformance across demographic groups and subgroups, addressing both \nquality of service and any allocation of services and resources. Quantify harms \nusing: \ufb01eld testing with sub-group populations to determine likelihood of", "7c9fd1a6-5ebf-4b67-a3b5-84642aa5413b": "exposure to generated content exhibiting harmful bias, AI red-teaming with \ncounterfactual and low-context (e.g., \u201cleader,\u201d \u201cbad guys\u201d) prompts. For ML \npipelines or business processes with categorical or numeric outcomes that rely \non GAI, apply general fairness metrics (e.g., demographic parity, equalized odds, \nequal opportunity, statistical hypothesis tests), to the pipeline or business \noutcome where appropriate; Custom, context-speci\ufb01c metrics developed in", "ea7256ef-c970-4924-9fa8-9c5374b8e4e8": "collaboration with domain experts and a\ufb00ected communities; Measurements of \nthe prevalence of denigration in generated content in deployment (e.g., sub-\nsampling a fraction of tra\ufb03c and manually annotating denigrating content). \nHarmful Bias and Homogenization; \nDangerous, Violent, or Hateful \nContent \nMS-2.11-003 \nIdentify the classes of individuals, groups, or environmental ecosystems which \nmight be impacted by GAI systems through direct engagement with potentially \nimpacted communities.", "addbb0d2-e4be-48e2-b27d-e5b3889d9337": "impacted communities. \nEnvironmental; Harmful Bias and \nHomogenization \nMS-2.11-004 \nReview, document, and measure sources of bias in GAI training and TEVV data: \nDi\ufb00erences in distributions of outcomes across and within groups, including \nintersecting groups; Completeness, representativeness, and balance of data \nsources; demographic group and subgroup coverage in GAI system training \ndata; Forms of latent systemic bias in images, text, audio, embeddings, or other", "c0a8d284-739a-4850-8e23-caf08c2d756b": "complex or unstructured data; Input data features that may serve as proxies for \ndemographic group membership (i.e., image metadata, language dialect) or \notherwise give rise to emergent bias within GAI systems; The extent to which \nthe digital divide may negatively impact representativeness in GAI system \ntraining and TEVV data; Filtering of hate speech or content in GAI system \ntraining data; Prevalence of GAI-generated data in GAI system training data. \nHarmful Bias and Homogenization", "6e8e6392-f299-419a-923d-9e9e16d22a3f": "Harmful Bias and Homogenization \n \n \n15 Winogender Schemas is a sample set of paired sentences which di\ufb00er only by gender of the pronouns used, \nwhich can be used to evaluate gender bias in natural language processing coreference resolution systems.", "1d644852-9826-4958-90e8-b6962f953382": "37 \nMS-2.11-005 \nAssess the proportion of synthetic to non-synthetic training data and verify \ntraining data is not overly homogenous or GAI-produced to mitigate concerns of \nmodel collapse. \nHarmful Bias and Homogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, End-Users, \nOperation and Monitoring, TEVV", "338644b4-39b2-4a12-abdd-f22d6d653bec": "Operation and Monitoring, TEVV \n \nMEASURE 2.12: Environmental impact and sustainability of AI model training and management activities \u2013 as identi\ufb01ed in the MAP \nfunction \u2013 are assessed and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.12-001 Assess safety to physical environments when deploying GAI systems. \nDangerous, Violent, or Hateful \nContent \nMS-2.12-002 Document anticipated environmental impacts of model development, \nmaintenance, and deployment in product design decisions.", "7cb0d367-a3e0-4726-8d26-504897a3a4e7": "Environmental \nMS-2.12-003 \nMeasure or estimate environmental impacts (e.g., energy and water \nconsumption) for training, \ufb01ne tuning, and deploying models: Verify tradeo\ufb00s \nbetween resources used at inference time versus additional resources required \nat training time. \nEnvironmental \nMS-2.12-004 Verify e\ufb00ectiveness of carbon capture or o\ufb00set programs for GAI training and \napplications, and address green-washing concerns. \nEnvironmental", "cd0d5f5f-0262-495a-86cc-425bc2ffd74f": "Environmental \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "5df435ca-a7c2-4148-9a15-36e99b3b2a4b": "38 \nMEASURE 2.13: E\ufb00ectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and \ndocumented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.13-001 \nCreate measurement error models for pre-deployment metrics to demonstrate \nconstruct validity for each metric (i.e., does the metric e\ufb00ectively operationalize \nthe desired concept): Measure or estimate, and document, biases or statistical", "65c9cefc-c99f-41c5-8e8a-d54ecf807d5a": "variance in applied metrics or structured human feedback processes; Leverage \ndomain expertise when modeling complex societal constructs such as hateful \ncontent. \nConfabulation; Information \nIntegrity; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV \n \nMEASURE 3.2: Risk tracking approaches are considered for settings where AI risks are di\ufb03cult to assess using currently available \nmeasurement techniques or where metrics are not yet available.", "bb53b74a-7e3b-4a40-ad89-819923c541cc": "Action ID \nSuggested Action \nGAI Risks \nMS-3.2-001 \nEstablish processes for identifying emergent GAI system risks including \nconsulting with external AI Actors. \nHuman-AI Con\ufb01guration; \nConfabulation  \nAI Actor Tasks: AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \nMEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are \nestablished and integrated into AI system evaluation metrics. \nAction ID", "b67d8869-719d-4200-b11a-1d12e5806894": "Action ID \nSuggested Action \nGAI Risks \nMS-3.3-001 \nConduct impact assessments on how AI-generated content might a\ufb00ect \ndi\ufb00erent social, economic, and cultural groups. \nHarmful Bias and Homogenization \nMS-3.3-002 \nConduct studies to understand how end users perceive and interact with GAI \ncontent and accompanying content provenance within context of use. Assess \nwhether the content aligns with their expectations and how they may act upon \nthe information presented. \nHuman-AI Con\ufb01guration;", "46e15488-b075-4fc0-a5eb-d8dfd6a5b7eb": "Human-AI Con\ufb01guration; \nInformation Integrity \nMS-3.3-003 \nEvaluate potential biases and stereotypes that could emerge from the AI-\ngenerated content using appropriate methodologies including computational \ntesting methods as well as evaluating structured feedback input. \nHarmful Bias and Homogenization", "7c838b34-44a5-4578-9299-120fcfa5086f": "39 \nMS-3.3-004 \nProvide input for training materials about the capabilities and limitations of GAI \nsystems related to digital content transparency for AI Actors, other \nprofessionals, and the public about the societal impacts of AI and the role of \ndiverse and inclusive content generation. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization \nMS-3.3-005 \nRecord and integrate structured feedback about content provenance from", "f06c026b-c110-4515-84b2-91c5366d3ab6": "operators, users, and potentially impacted communities through the use of \nmethods such as user research studies, focus groups, or community forums. \nActively seek feedback on generated content quality and potential biases. \nAssess the general awareness among end users and impacted communities \nabout the availability of these feedback channels. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization", "9a2dd6c8-4923-434f-8cc9-f43a74702d90": "and Homogenization \nAI Actor Tasks: AI Deployment, A\ufb00ected Individuals and Communities, End-Users, Operation and Monitoring, TEVV \n \nMEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are \ninformed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as \nintended. Results are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-4.2-001", "23a63448-25b3-4aa9-b9a9-5f789d7e30e2": "Suggested Action \nGAI Risks \nMS-4.2-001 \nConduct adversarial testing at a regular cadence to map and measure GAI risks, \nincluding tests to address attempts to deceive or manipulate the application of \nprovenance techniques or other misuses. Identify vulnerabilities and \nunderstand potential misuse scenarios and unintended outputs. \nInformation Integrity; Information \nSecurity \nMS-4.2-002 \nEvaluate GAI system performance in real-world scenarios to observe its", "b7d794d7-db5a-46d3-a4bc-820bb816139b": "behavior in practical environments and reveal issues that might not surface in \ncontrolled and optimized testing environments. \nHuman-AI Con\ufb01guration; \nConfabulation; Information \nSecurity \nMS-4.2-003 \nImplement interpretability and explainability methods to evaluate GAI system \ndecisions and verify alignment with intended purpose. \nInformation Integrity; Harmful Bias \nand Homogenization \nMS-4.2-004 \nMonitor and document instances where human operators or other systems", "64202c3f-46cd-4d2a-9e53-e51531764f7f": "override the GAI's decisions. Evaluate these cases to understand if the overrides \nare linked to issues related to content provenance. \nInformation Integrity \nMS-4.2-005 \nVerify and document the incorporation of results of structured public feedback \nexercises into design, implementation, deployment approval (\u201cgo\u201d/\u201cno-go\u201d \ndecisions), monitoring, and decommission decisions. \nHuman-AI Con\ufb01guration; \nInformation Security", "f4fece0b-d67d-4cd7-8e8d-ffbfe0298980": "Human-AI Con\ufb01guration; \nInformation Security \nAI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV", "ba222052-aa9b-4ace-9697-e8736cc999a9": "40 \nMANAGE 1.3: Responses to the AI risks deemed high priority, as identi\ufb01ed by the MAP function, are developed, planned, and \ndocumented. Risk response options can include mitigating, transferring, avoiding, or accepting. \nAction ID \nSuggested Action \nGAI Risks \nMG-1.3-001 \nDocument trade-o\ufb00s, decision processes, and relevant measurement and \nfeedback results for risks that do not surpass organizational risk tolerance, for", "02ff8ada-38bf-485a-8b01-8bf789220a11": "example, in the context of model release: Consider di\ufb00erent approaches for \nmodel release, for example, leveraging a staged release approach. Consider \nrelease approaches in the context of the model and its projected use cases. \nMitigate, transfer, or avoid risks that surpass organizational risk tolerances. \nInformation Security \nMG-1.3-002 \nMonitor the robustness and e\ufb00ectiveness of risk controls and mitigation plans", "5209bccb-31ca-4866-b16b-3e583df327ac": "(e.g., via red-teaming, \ufb01eld testing, participatory engagements, performance \nassessments, user feedback mechanisms). \nHuman-AI Con\ufb01guration \nAI Actor Tasks: AI Development, AI Deployment, AI Impact Assessment, Operation and Monitoring \n \nMANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems. \nAction ID \nSuggested Action \nGAI Risks \nMG-2.2-001 \nCompare GAI system outputs against pre-de\ufb01ned organization risk tolerance,", "7e4e8503-07c4-41c6-8b9b-c9eb56846664": "guidelines, and principles, and review and test AI-generated content against \nthese guidelines. \nCBRN Information or Capabilities; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content \nMG-2.2-002 \nDocument training data sources to trace the origin and provenance of AI-\ngenerated content. \nInformation Integrity \nMG-2.2-003 \nEvaluate feedback loops between GAI system content provenance and human", "f29803eb-defd-4a4c-95ae-b2bdf3f2e780": "reviewers, and update where needed. Implement real-time monitoring systems \nto a\ufb03rm that content provenance protocols remain e\ufb00ective.  \nInformation Integrity \nMG-2.2-004 \nEvaluate GAI content and data for representational biases and employ \ntechniques such as re-sampling, re-ranking, or adversarial training to mitigate \nbiases in the generated content. \nInformation Security; Harmful Bias \nand Homogenization \nMG-2.2-005", "91146c6b-8df0-419c-95bd-89df152049ae": "and Homogenization \nMG-2.2-005 \nEngage in due diligence to analyze GAI output for harmful content, potential \nmisinformation, and CBRN-related or NCII content. \nCBRN Information or Capabilities; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content", "9d28b196-5f24-477c-a779-fbe4792d5e5a": "41 \nMG-2.2-006 \nUse feedback from internal and external AI Actors, users, individuals, and \ncommunities, to assess impact of AI-generated content. \nHuman-AI Con\ufb01guration \nMG-2.2-007 \nUse real-time auditing tools where they can be demonstrated to aid in the \ntracking and validation of the lineage and authenticity of AI-generated data. \nInformation Integrity \nMG-2.2-008 \nUse structured feedback mechanisms to solicit and capture user input about AI-", "d62eeec4-2abb-4a28-8755-ff94e882ce89": "generated content to detect subtle shifts in quality or alignment with \ncommunity and societal values. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nMG-2.2-009 \nConsider opportunities to responsibly use synthetic data and other privacy \nenhancing techniques in GAI development, where appropriate and applicable, \nmatch the statistical properties of real-world data without disclosing personally \nidenti\ufb01able information or contributing to homogenization.", "2a7cb8a4-5279-40c1-a953-bda469ba1cc4": "Data Privacy; Intellectual Property; \nInformation Integrity; \nConfabulation; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring \n \nMANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identi\ufb01ed. \nAction ID \nSuggested Action \nGAI Risks \nMG-2.3-001 \nDevelop and update GAI system incident response and recovery plans and", "89979000-f73e-47b9-93cf-000ebec9e009": "procedures to address the following: Review and maintenance of policies and \nprocedures to account for newly encountered uses; Review and maintenance of \npolicies and procedures for detection of unanticipated uses; Verify response \nand recovery plans account for the GAI system value chain; Verify response and \nrecovery plans are updated for and include necessary details to communicate \nwith downstream GAI system Actors: Points-of-Contact (POC), Contact \ninformation, noti\ufb01cation format.", "d23dc50b-e726-48c8-9902-3cbb09995f30": "information, noti\ufb01cation format. \nValue Chain and Component \nIntegration \nAI Actor Tasks: AI Deployment, Operation and Monitoring \n \nMANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or \ndeactivate AI systems that demonstrate performance or outcomes inconsistent with intended use. \nAction ID \nSuggested Action \nGAI Risks \nMG-2.4-001 \nEstablish and maintain communication plans to inform AI stakeholders as part of", "812a957e-8d09-4b79-a556-d26e07e8b05c": "the deactivation or disengagement process of a speci\ufb01c GAI system (including for \nopen-source models) or context of use, including reasons, workarounds, user \naccess removal, alternative processes, contact information, etc. \nHuman-AI Con\ufb01guration", "52abff36-9d40-42e8-af8f-a0427d90a519": "42 \nMG-2.4-002 \nEstablish and maintain procedures for escalating GAI system incidents to the \norganizational risk management authority when speci\ufb01c criteria for deactivation \nor disengagement is met for a particular context of use or for the GAI system as a \nwhole. \nInformation Security \nMG-2.4-003 \nEstablish and maintain procedures for the remediation of issues which trigger \nincident response processes for the use of a GAI system, and provide stakeholders", "1fa92ead-2a4b-4b0a-9f19-ef2a8dd864db": "timelines associated with the remediation plan. \nInformation Security \n \nMG-2.4-004 Establish and regularly review speci\ufb01c criteria that warrants the deactivation of \nGAI systems in accordance with set risk tolerances and appetites. \nInformation Security \n \nAI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring \n \nMANAGE 3.1: AI risks and bene\ufb01ts from third-party resources are regularly monitored, and risk controls are applied and \ndocumented. \nAction ID", "6d3fed1f-a1ff-4838-940a-531a16692b76": "documented. \nAction ID \nSuggested Action \nGAI Risks \nMG-3.1-001 \nApply organizational risk tolerances and controls (e.g., acquisition and \nprocurement processes; assessing personnel credentials and quali\ufb01cations, \nperforming background checks; \ufb01ltering GAI input and outputs, grounding, \ufb01ne \ntuning, retrieval-augmented generation) to third-party GAI resources: Apply \norganizational risk tolerance to the utilization of third-party datasets and other", "f4c58a1b-7877-460b-ae20-eae5766d7b94": "GAI resources; Apply organizational risk tolerances to \ufb01ne-tuned third-party \nmodels; Apply organizational risk tolerance to existing third-party models \nadapted to a new domain; Reassess risk measurements after \ufb01ne-tuning third-\nparty GAI models. \nValue Chain and Component \nIntegration; Intellectual Property \nMG-3.1-002 \nTest GAI system value chain risks (e.g., data poisoning, malware, other software \nand hardware vulnerabilities; labor practices; data privacy and localization", "8316504d-b00b-429f-9549-81dfbf07eb87": "compliance; geopolitical alignment). \nData Privacy; Information Security; \nValue Chain and Component \nIntegration; Harmful Bias and \nHomogenization \nMG-3.1-003 \nRe-assess model risks after \ufb01ne-tuning or retrieval-augmented generation \nimplementation and for any third-party GAI models deployed for applications \nand/or use cases that were not evaluated in initial testing. \nValue Chain and Component \nIntegration \nMG-3.1-004", "f2527c10-2c51-4e0f-8086-53eae394d0eb": "Integration \nMG-3.1-004 \nTake reasonable measures to review training data for CBRN information, and \nintellectual property, and where appropriate, remove it. Implement reasonable \nmeasures to prevent, \ufb02ag, or take other action in response to outputs that \nreproduce particular training data (e.g., plagiarized, trademarked, patented, \nlicensed content or trade secret material). \nIntellectual Property; CBRN \nInformation or Capabilities", "34c27803-30c5-41ce-ba18-0b1edc20d984": "43 \nMG-3.1-005 Review various transparency artifacts (e.g., system cards and model cards) for \nthird-party models. \nInformation Integrity; Information \nSecurity; Value Chain and \nComponent Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities \n \nMANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and \nmaintenance. \nAction ID \nSuggested Action \nGAI Risks \nMG-3.2-001", "404014d6-b425-49ec-b2f9-e43a47dc18c5": "Suggested Action \nGAI Risks \nMG-3.2-001 \nApply explainable AI (XAI) techniques (e.g., analysis of embeddings, model \ncompression/distillation, gradient-based attributions, occlusion/term reduction, \ncounterfactual prompts, word clouds) as part of ongoing continuous \nimprovement processes to mitigate risks related to unexplainable GAI systems. \nHarmful Bias and Homogenization \nMG-3.2-002 \nDocument how pre-trained models have been adapted (e.g., \ufb01ne-tuned, or", "e1531ea2-b493-496c-961a-08c899fa4172": "retrieval-augmented generation) for the speci\ufb01c generative task, including any \ndata augmentations, parameter adjustments, or other modi\ufb01cations. Access to \nun-tuned (baseline) models supports debugging the relative in\ufb02uence of the pre-\ntrained weights compared to the \ufb01ne-tuned model weights or other system \nupdates. \nInformation Integrity; Data Privacy \nMG-3.2-003 \nDocument sources and types of training data and their origins, potential biases", "37ba9d3c-7ada-4ff9-9995-de796092d1ba": "present in the data related to the GAI application and its content provenance, \narchitecture, training process of the pre-trained model including information on \nhyperparameters, training duration, and any \ufb01ne-tuning or retrieval-augmented \ngeneration processes applied. \nInformation Integrity; Harmful Bias \nand Homogenization; Intellectual \nProperty \nMG-3.2-004 Evaluate user reported problematic content and integrate feedback into system \nupdates. \nHuman-AI Con\ufb01guration,", "fa0790da-e8ad-4ae9-b51f-1452a6bbe66c": "updates. \nHuman-AI Con\ufb01guration, \nDangerous, Violent, or Hateful \nContent \nMG-3.2-005 \nImplement content \ufb01lters to prevent the generation of inappropriate, harmful, \nfalse, illegal, or violent content related to the GAI application, including for CSAM \nand NCII. These \ufb01lters can be rule-based or leverage additional machine learning \nmodels to \ufb02ag problematic inputs and outputs. \nInformation Integrity; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content;", "0fd68789-61e7-4b36-ba8a-23428ba84c8d": "Violent, or Hateful Content; \nObscene, Degrading, and/or \nAbusive Content \nMG-3.2-006 \nImplement real-time monitoring processes for analyzing generated content \nperformance and trustworthiness characteristics related to content provenance \nto identify deviations from the desired standards and trigger alerts for human \nintervention. \nInformation Integrity", "4b05b9f7-3ed9-4463-a305-9f9b52ec12a3": "44 \nMG-3.2-007 \nLeverage feedback and recommendations from organizational boards or \ncommittees related to the deployment of GAI applications and content \nprovenance when using third-party pre-trained models. \nInformation Integrity; Value Chain \nand Component Integration \nMG-3.2-008 \nUse human moderation systems where appropriate to review generated content \nin accordance with human-AI con\ufb01guration policies established in the Govern", "ed7aa582-ff3b-40e1-8df6-1bd24ca6e6e9": "function, aligned with socio-cultural norms in the context of use, and for settings \nwhere AI models are demonstrated to perform poorly. \nHuman-AI Con\ufb01guration \nMG-3.2-009 \nUse organizational risk tolerance to evaluate acceptable risks and performance \nmetrics and decommission or retrain pre-trained models that perform outside of \nde\ufb01ned limits. \nCBRN Information or Capabilities; \nConfabulation \nAI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities", "b783fa0c-5517-4bc0-9cd7-4fc11536a4a0": "MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating \ninput from users and other relevant AI Actors, appeal and override, decommissioning, incident response, recovery, and change \nmanagement. \nAction ID \nSuggested Action \nGAI Risks \nMG-4.1-001 \nCollaborate with external researchers, industry experts, and community \nrepresentatives to maintain awareness of emerging best practices and", "d4a09c99-54bd-469e-9afa-8da500d66d28": "technologies in measuring and managing identi\ufb01ed risks. \nInformation Integrity; Harmful Bias \nand Homogenization \nMG-4.1-002 \nEstablish, maintain, and evaluate e\ufb00ectiveness of organizational processes and \nprocedures for post-deployment monitoring of GAI systems, particularly for \npotential confabulation, CBRN, or cyber risks. \nCBRN Information or Capabilities; \nConfabulation; Information \nSecurity \nMG-4.1-003 \nEvaluate the use of sentiment analysis to gauge user sentiment regarding GAI", "0dba7b27-9ddf-4fc9-a33b-1b468d4d479c": "content performance and impact, and work in collaboration with AI Actors \nexperienced in user research and experience. \nHuman-AI Con\ufb01guration \nMG-4.1-004 Implement active learning techniques to identify instances where the model fails \nor produces unexpected outputs. \nConfabulation \nMG-4.1-005 \nShare transparency reports with internal and external stakeholders that detail \nsteps taken to update the GAI system to enhance transparency and \naccountability. \nHuman-AI Con\ufb01guration; Harmful", "e549e55e-fcf0-4c8a-b3ba-b3988fc5557d": "accountability. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nMG-4.1-006 \nTrack dataset modi\ufb01cations for provenance by monitoring data deletions, \nrecti\ufb01cation requests, and other changes that may impact the veri\ufb01ability of \ncontent origins. \nInformation Integrity", "15fcbd74-4fad-48e2-8c38-77e7ce00e6b3": "45 \nMG-4.1-007 \nVerify that AI Actors responsible for monitoring reported issues can e\ufb00ectively \nevaluate GAI system performance including the application of content \nprovenance data tracking techniques, and promptly escalate issues for response. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nAI Actor Tasks: AI Deployment, A\ufb00ected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and \nMonitoring", "37abf575-cb71-4a3f-ad32-aceeb9a5c2e0": "Monitoring \n \nMANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular \nengagement with interested parties, including relevant AI Actors. \nAction ID \nSuggested Action \nGAI Risks \nMG-4.2-001 Conduct regular monitoring of GAI systems and publish reports detailing the \nperformance, feedback received, and improvements made. \nHarmful Bias and Homogenization \nMG-4.2-002", "567d66e7-1c3f-4e1f-be3a-1c4c5f646f75": "Harmful Bias and Homogenization \nMG-4.2-002 \nPractice and follow incident response plans for addressing the generation of \ninappropriate or harmful content and adapt processes based on \ufb01ndings to \nprevent future occurrences. Conduct post-mortem analyses of incidents with \nrelevant AI Actors, to understand the root causes and implement preventive \nmeasures. \nHuman-AI Con\ufb01guration; \nDangerous, Violent, or Hateful \nContent", "f9c4f5b4-ff0d-4acb-80ef-badde0a9370b": "Dangerous, Violent, or Hateful \nContent \nMG-4.2-003 Use visualizations or other methods to represent GAI model behavior to ease \nnon-technical stakeholders understanding of GAI system functionality. \nHuman-AI Con\ufb01guration \nAI Actor Tasks: AI Deployment, AI Design, AI Development, A\ufb00ected Individuals and Communities, End-Users, Operation and \nMonitoring, TEVV \n \nMANAGE 4.3: Incidents and errors are communicated to relevant AI Actors, including a\ufb00ected communities. Processes for tracking,", "4f4f3aae-2fc8-4854-ba44-11c735d1912c": "responding to, and recovering from incidents and errors are followed and documented. \nAction ID \nSuggested Action \nGAI Risks \nMG-4.3-001 \nConduct after-action assessments for GAI system incidents to verify incident \nresponse and recovery processes are followed and e\ufb00ective, including to follow \nprocedures for communicating incidents to relevant AI Actors and where \napplicable, relevant legal and regulatory bodies.  \nInformation Security", "5f3ca707-5144-4a2c-88b6-de1452d78b94": "Information Security \nMG-4.3-002 Establish and maintain policies and procedures to record and track GAI system \nreported errors, near-misses, and negative impacts. \nConfabulation; Information \nIntegrity", "0fd7bc57-c13d-4456-80d4-3713553ed097": "46 \nMG-4.3-003 \nReport GAI incidents in compliance with legal and regulatory requirements (e.g., \nHIPAA breach reporting, e.g., OCR (2023) or NHTSA (2022) autonomous vehicle \ncrash reporting requirements. \nInformation Security; Data Privacy \nAI Actor Tasks: AI Deployment, A\ufb00ected Individuals and Communities, Domain Experts, End-Users, Human Factors, Operation and \nMonitoring", "83923590-f766-45b9-b36d-14d2d9cea223": "47 \nAppendix A. Primary GAI Considerations \nThe following primary considerations were derived as overarching themes from the GAI PWG \nconsultation process. These considerations (Governance, Pre-Deployment Testing, Content Provenance, \nand Incident Disclosure) are relevant for voluntary use by any organization designing, developing, and \nusing GAI and also inform the Actions to Manage GAI risks. Information included about the primary", "eb6f9a4d-693a-461d-abdf-e3a6d0efdb45": "considerations is not exhaustive, but highlights the most relevant topics derived from the GAI PWG.  \nAcknowledgments: These considerations could not have been surfaced without the helpful analysis and \ncontributions from the community and NIST sta\ufb00 GAI PWG leads: George Awad, Luca Belli, Harold Booth, \nMat Heyman, Yooyoung Lee, Mark Pryzbocki, Reva Schwartz, Martin Stanley, and Kyra Yee. \nA.1. Governance \nA.1.1. Overview", "724144d2-c133-4b8a-b3d6-39e3f55451f3": "A.1. Governance \nA.1.1. Overview \nLike any other technology system, governance principles and techniques can be used to manage risks \nrelated to generative AI models, capabilities, and applications. Organizations may choose to apply their \nexisting risk tiering to GAI systems, or they may opt to revise or update AI system risk levels to address \nthese unique GAI risks. This section describes how organizational governance regimes may be re-", "37666a9a-0aee-4d88-b2f0-2f03d1be9960": "evaluated and adjusted for GAI contexts. It also addresses third-party considerations for governing across \nthe AI value chain.  \nA.1.2. Organizational Governance \nGAI opportunities, risks and long-term performance characteristics are typically less well-understood \nthan non-generative AI tools and may be perceived and acted upon by humans in ways that vary greatly. \nAccordingly, GAI may call for di\ufb00erent levels of oversight from AI Actors or di\ufb00erent human-AI"}}